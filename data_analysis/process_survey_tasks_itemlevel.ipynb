{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfc545a9",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "Starting point:\n",
    "- 848 datasets (18 tasks per model (minus the NON_IDEAL_OUTPUTS)) with all logprobs for all answer alternatives of each subtask for all ~1.500 participants. \n",
    "\n",
    "What does this script do\n",
    "- Read all survey data sets\n",
    "- normalise log-prob scores so that they are probabilities that sum up to 1 over all answer options\n",
    "- filter out the probability that the LLm assigned to the answer option which the participant actually chose (for each item)\n",
    "- flip back answers where scale was flipped to cope with prompt sensitivity issues\n",
    "- weigh probabiliies with human answers and divide by all probabilities for that item, to have one number (in the realm if not exact the number of the answer alternatives) per item per model\n",
    "- second weighing strategy, where score of model per item is only weighed with top n most likely probabilities that model assigned\n",
    "- for some scales: add subcategories (each item belongs to a subcategory)\n",
    "- for some tasks, but unsure, reverse back some scores that are asked on a reverse scale due to the nature of the task\n",
    "- concat the itemwise scores for each task per model all together in one `all_data` final data frame and save it.\n",
    "\n",
    "Specials:\n",
    "- for every scale I compared the frey materials quest_raw.csv and quest_proc.csv and tried to trace back how they got from one to the other. Then I did the same transformations\n",
    "- therefore, for AUDIT and FTND and some more the scores are mapped onto a different scale (point system depending on given answer) on the `human_number` level (before mapped to LLM assigned probabilities)\n",
    "- ! for other scales the scores might have to be transfered into another point system as well!\n",
    "- ! SSSV must be reversed in some items, I think, but resluts are awful when done!?!?!?!\n",
    "\n",
    "Goal:\n",
    "- first have one value per item per model\n",
    "- then transform those values in \"outcomes\" for each subscale (like Frey did)\n",
    "- Have 36 values per model! (one per (sub-) scale)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2ebc19",
   "metadata": {},
   "source": [
    "## Packages & Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fef727d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import load_dataframes, filter_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "69d790d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------\n",
    "# Pro Modell × Item die Zähler und Nenner berechnen\n",
    "# ----------------------------------------------------------------------------------------------\n",
    "# - Zähler = Summe von (Antwort * Wahrscheinlichkeit)\n",
    "# - Nenner = Summe von (Wahrscheinlichkeiten)\n",
    "\n",
    "def compute_weighted_score(group):\n",
    "    numerator = (group[\"human_number\"] * group[\"prob_pred\"]).sum()\n",
    "    denominator = group[\"prob_pred\"].sum()\n",
    "    return numerator / denominator if denominator > 0 else None\n",
    "\n",
    "\n",
    "# Funktion für Top-n gewichteten Score\n",
    "def compute_top_n_weighted_score(group, n = 100):\n",
    "    # Sortiere die Zeilen nach Wahrscheinlichkeit absteigend\n",
    "    top_n = group.sort_values(\"prob_pred\", ascending=False).head(n)\n",
    "    # Numerator = Summe von (Antwort * Wahrscheinlichkeit)\n",
    "    numerator = (top_n[\"human_number\"] * top_n[\"prob_pred\"]).sum()\n",
    "    # Denominator = Summe von Wahrscheinlichkeiten der Top n\n",
    "    denominator = top_n[\"prob_pred\"].sum()\n",
    "    return numerator / denominator if denominator > 0 else None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# produce df with one value per model per item --------------------------------------------------\n",
    "# more compact version (that runs faster)\n",
    "# def get_LLM_value_per_item(data):\n",
    "#     grouped = data.groupby([\"experiment\", \"model\", \"item\"])\n",
    "#     score = (grouped[\"human_number\"].apply(lambda x: (x * data.loc[x.index, \"prob_pred\"]).sum())\n",
    "#              / grouped[\"prob_pred\"].sum())\n",
    "#     return score.reset_index(name=\"score\")\n",
    "\n",
    "def get_LLM_value_per_item(data):\n",
    "    \"\"\"\n",
    "    Compute expected value from LLM's probability distribution without using human answers.\n",
    "    \n",
    "    For each (model, item):\n",
    "        1. Get LLM's probability distribution over all answer options\n",
    "        2. Compute E[X] = Σ(answer_value × P(answer))\n",
    "    \n",
    "    This averages across participants to get a single probability distribution\n",
    "    per model per item, then computes the expected value.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for (exp, model, item), group in data.groupby([\"experiment\", \"model\", \"item\"]):\n",
    "        # Find probability columns (e.g., prob_0, prob_1, prob_2, ...)\n",
    "        prob_cols = sorted([c for c in group.columns \n",
    "                           if c.startswith('prob_') and c.split('_')[1].isdigit()],\n",
    "                          key=lambda x: int(x.split('_')[1]))\n",
    "        \n",
    "        if len(prob_cols) < 2:\n",
    "            continue\n",
    "        \n",
    "        # Extract answer values from column names\n",
    "        answer_values = [int(c.split('_')[1]) for c in prob_cols]\n",
    "        \n",
    "        # Average LLM probabilities across all participants who saw this item\n",
    "        # This gives us the \"typical\" LLM probability distribution for this item\n",
    "        avg_probs = group[prob_cols].mean()\n",
    "        \n",
    "        # Renormalize to ensure probabilities sum to 1\n",
    "        prob_sum = avg_probs.sum()\n",
    "        if prob_sum > 0:\n",
    "            avg_probs = avg_probs / prob_sum\n",
    "        \n",
    "        # Compute expected value\n",
    "        expected_value = sum(answer_values[i] * avg_probs.iloc[i] \n",
    "                            for i in range(len(answer_values)))\n",
    "        \n",
    "        results.append({\n",
    "            'experiment': exp,\n",
    "            'model': model,\n",
    "            'item': item,\n",
    "            'score': expected_value\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# produce df with one value per model per item for top n version --------------------------------------------------\n",
    "# def get_LLM_value_per_item_top_n(data):\n",
    "#     new_df = (\n",
    "#     data.groupby([\"experiment\", \"model\", \"item\"])[[\"human_number\", \"prob_pred\"]]\n",
    "#       .apply(compute_top_n_weighted_score)\n",
    "#       .reset_index(name=\"score_top_n\")\n",
    "#     )\n",
    "#     return(new_df)\n",
    "\n",
    "def get_LLM_value_per_item_top_n(data):\n",
    "    \"\"\"\n",
    "    Get the most probable answer for each (model, item).\n",
    "    This is the argmax approach - simpler than expected value.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for (exp, model, item), group in data.groupby([\"experiment\", \"model\", \"item\"]):\n",
    "        prob_cols = sorted([c for c in group.columns \n",
    "                           if c.startswith('prob_') and c.split('_')[1].isdigit()],\n",
    "                          key=lambda x: int(x.split('_')[1]))\n",
    "        \n",
    "        if len(prob_cols) < 2:\n",
    "            continue\n",
    "        \n",
    "        answer_values = [int(c.split('_')[1]) for c in prob_cols]\n",
    "        avg_probs = group[prob_cols].mean()\n",
    "        \n",
    "        # Find answer with maximum probability\n",
    "        max_idx = avg_probs.argmax()\n",
    "        most_probable_answer = answer_values[max_idx]\n",
    "        \n",
    "        results.append({\n",
    "            'experiment': exp,\n",
    "            'model': model,\n",
    "            'item': item,\n",
    "            'score_top_n': most_probable_answer\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eece353e",
   "metadata": {},
   "source": [
    "## AUDIT SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "65a51faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (712264, 11)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "AUDIT_data = load_dataframes(task_name=\"AUDIT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fd081b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one (tun so als hätten wir sehr guten Prompt, dann würde LLM nur zwischen möglichen Antwortalternativen aussuchen, da simulieren wir dadurch)\n",
    "mask = (AUDIT_data[\"item\"] == 1)\n",
    "AUDIT_data.loc[mask, \"prob_1\"] = np.exp(AUDIT_data.loc[mask, \"1\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]))\n",
    "AUDIT_data.loc[mask, \"prob_2\"] = np.exp(AUDIT_data.loc[mask, \"2\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]))\n",
    "\n",
    "mask = (AUDIT_data[\"item\"].isin([10, 11]))\n",
    "AUDIT_data.loc[mask, \"prob_1\"] = np.exp(AUDIT_data.loc[mask, \"1\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]))\n",
    "AUDIT_data.loc[mask, \"prob_2\"] = np.exp(AUDIT_data.loc[mask, \"2\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]))\n",
    "AUDIT_data.loc[mask, \"prob_3\"] = np.exp(AUDIT_data.loc[mask, \"3\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]))\n",
    "\n",
    "\n",
    "mask = (AUDIT_data[\"item\"].isin([2, 3, 4, 5, 6, 7, 8, 9]))\n",
    "AUDIT_data.loc[mask, \"prob_1\"] = np.exp(AUDIT_data.loc[mask, \"1\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]) + np.exp(AUDIT_data.loc[mask, \"4\"]) + np.exp(AUDIT_data.loc[mask, \"5\"]))\n",
    "AUDIT_data.loc[mask, \"prob_2\"] = np.exp(AUDIT_data.loc[mask, \"2\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]) + np.exp(AUDIT_data.loc[mask, \"4\"]) + np.exp(AUDIT_data.loc[mask, \"5\"]))\n",
    "AUDIT_data.loc[mask, \"prob_3\"] = np.exp(AUDIT_data.loc[mask, \"3\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]) + np.exp(AUDIT_data.loc[mask, \"4\"]) + np.exp(AUDIT_data.loc[mask, \"5\"]))\n",
    "AUDIT_data.loc[mask, \"prob_4\"] = np.exp(AUDIT_data.loc[mask, \"4\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]) + np.exp(AUDIT_data.loc[mask, \"4\"]) + np.exp(AUDIT_data.loc[mask, \"5\"]))\n",
    "AUDIT_data.loc[mask, \"prob_5\"] = np.exp(AUDIT_data.loc[mask, \"5\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]) + np.exp(AUDIT_data.loc[mask, \"4\"]) + np.exp(AUDIT_data.loc[mask, \"5\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8b52a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "AUDIT_data=filter_pred_prob(AUDIT_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1421f934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (AUDIT_data[\"flipped\"] == \"yes\") & (AUDIT_data[\"item\"] == 1)\n",
    "AUDIT_data.loc[mask, \"human_number\"] = 3 - AUDIT_data.loc[mask, \"human_number\"]\n",
    "mask = (AUDIT_data[\"flipped\"] == \"yes\") & (AUDIT_data[\"item\"].isin([10, 11]))\n",
    "AUDIT_data.loc[mask, \"human_number\"] = 4 - AUDIT_data.loc[mask, \"human_number\"]\n",
    "mask = (AUDIT_data[\"flipped\"] == \"yes\") & (AUDIT_data[\"item\"].isin([2, 3, 4, 5, 6, 7, 8, 9]))\n",
    "AUDIT_data.loc[mask, \"human_number\"] = 6 - AUDIT_data.loc[mask, \"human_number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7a81387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mappings for each AUDIT question:\n",
    "audit_maps = {\n",
    "    1: {1: 1, 2: 0},                            # AlcSplit\n",
    "    2: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4},          # AUDIT_1 (in proc data Frey)\n",
    "    3: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4},          # AUDIT_2 (in proc data Frey)\n",
    "    4: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4},          # AUDIT_3 (in proc data Frey)\n",
    "    5: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4},          # AUDIT_4 (in proc data Frey)\n",
    "    6: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4},          # AUDIT_5 (in proc data Frey)\n",
    "    7: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4},          # AUDIT_6 (in proc data Frey)\n",
    "    8: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4},          # AUDIT_7 (in proc data Frey)\n",
    "    9: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4},          # AUDIT_8 (in proc data Frey)\n",
    "    10: {1: 0, 2: 2, 3: 4},                     # AUDIT_10 (in proc data Frey)\n",
    "    11: {1: 0, 2: 2, 3: 4},                     # AUDIT_11 (in proc data Frey)\n",
    "\n",
    "}\n",
    "\n",
    "# Apply mapping row-wise based on item number\n",
    "def recode_audit(row):\n",
    "    mapping = audit_maps.get(row[\"item\"])\n",
    "    if mapping is not None:\n",
    "        return mapping.get(row[\"human_number\"], None)  # None if invalid code\n",
    "    return row[\"human_number\"]  \n",
    "\n",
    "AUDIT_data[\"human_number\"] = AUDIT_data.apply(recode_audit, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f0d05126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_AUDIT = get_LLM_value_per_item(AUDIT_data)\n",
    "model_item_scores_AUDIT_top_n = get_LLM_value_per_item_top_n(AUDIT_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_AUDIT = model_item_scores_AUDIT.merge(\n",
    "    model_item_scores_AUDIT_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d65688",
   "metadata": {},
   "source": [
    "## BARRAT SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cc730c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (2082420, 10)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "BARRAT_data = load_dataframes(task_name=\"BARRAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4b88e1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one\n",
    "BARRAT_data[\"prob_1\"] = np.exp(BARRAT_data[\"1\"])/(np.exp(BARRAT_data[\"1\"]) + np.exp(BARRAT_data[\"2\"]) + np.exp(BARRAT_data[\"3\"]) + np.exp(BARRAT_data[\"4\"]))\n",
    "BARRAT_data[\"prob_2\"] = np.exp(BARRAT_data[\"2\"])/(np.exp(BARRAT_data[\"1\"]) + np.exp(BARRAT_data[\"2\"]) + np.exp(BARRAT_data[\"3\"]) + np.exp(BARRAT_data[\"4\"]))\n",
    "BARRAT_data[\"prob_3\"] = np.exp(BARRAT_data[\"3\"])/(np.exp(BARRAT_data[\"1\"]) + np.exp(BARRAT_data[\"2\"]) + np.exp(BARRAT_data[\"3\"]) + np.exp(BARRAT_data[\"4\"]))\n",
    "BARRAT_data[\"prob_4\"] = np.exp(BARRAT_data[\"4\"])/(np.exp(BARRAT_data[\"1\"]) + np.exp(BARRAT_data[\"2\"]) + np.exp(BARRAT_data[\"3\"]) + np.exp(BARRAT_data[\"4\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9945c979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "BARRAT_data=filter_pred_prob(BARRAT_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "29d02886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (BARRAT_data[\"flipped\"] == True)\n",
    "BARRAT_data.loc[mask, \"human_number\"] = 5 - BARRAT_data.loc[mask, \"human_number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3100efef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_BARRAT = get_LLM_value_per_item(BARRAT_data)\n",
    "model_item_scores_BARRAT_top_n = get_LLM_value_per_item_top_n(BARRAT_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_BARRAT = model_item_scores_BARRAT.merge(\n",
    "    model_item_scores_BARRAT_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "38eda3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding task specific categories to save in all data\n",
    "\n",
    "# add item categories\n",
    "item_to_category = {\n",
    "    1: \"BISn\", 2: \"BISm\", 3: \"BISm\",  4: \"BISm\", 5: \"BISa\",  6: \"BISa\",  7: \"BISn\",  8: \"BISn\",  9: \"BISa\",  10: \"BISn\",\n",
    "    11: \"BISa\", 12: \"BISn\", 13: \"BISn\",  14: \"BISn\", 15: \"BISn\",  16: \"BISm\",  17: \"BISm\",  18: \"BISn\",  19: \"BISm\",  20: \"BISa\",\n",
    "    21: \"BISm\", 22: \"BISm\", 23: \"BISm\",  24: \"BISa\", 25: \"BISm\",  26: \"BISa\",  27: \"BISn\",  28: \"BISa\",  29: \"BISn\",  30: \"BISm\"\n",
    "}\n",
    "# add whether item was reverse coded\n",
    "reverse_coded = {\n",
    "    1: True, 2: False, 3: False,  4: False, 5: False,  6: False,  7: True,  8: True,  9: True,  10: True,\n",
    "    11: False, 12: True, 13: True,  14: False, 15: True,  16: False,  17: False,  18: False,  19: False,  20: True,\n",
    "    21: False, 22: False, 23: False,  24: False, 25: False,  26: False,  27: False,  28: False,  29: True,  30: True\n",
    "    }\n",
    "\n",
    "model_item_scores_BARRAT[\"category\"] = model_item_scores_BARRAT[\"item\"].map(item_to_category)\n",
    "model_item_scores_BARRAT[\"reverse_coded\"] = model_item_scores_BARRAT[\"item\"].map(reverse_coded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "65e25fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back answers that where reverse coded\n",
    "mask = (model_item_scores_BARRAT[\"reverse_coded\"] == True)\n",
    "model_item_scores_BARRAT.loc[mask, \"score\"] = 5 - model_item_scores_BARRAT.loc[mask, \"score\"]\n",
    "model_item_scores_BARRAT.loc[mask, \"score_top_n\"] = 5 - model_item_scores_BARRAT.loc[mask, \"score_top_n\"]\n",
    "# drop reverse-coded column (not needed in final data)\n",
    "model_item_scores_BARRAT = model_item_scores_BARRAT.drop(columns=[\"reverse_coded\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7ddb9972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([model_item_scores_AUDIT, model_item_scores_BARRAT], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0226ac",
   "metadata": {},
   "source": [
    "## CARE TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f1491661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (1320614, 106)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "CARE_data = load_dataframes(task_name=\"CARE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d59c8fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probabilities out of log-probabilities\n",
    "\n",
    "cols = [str(i) for i in range(0, 100)]\n",
    "# Compute normalized probabilities\n",
    "exp_vals = np.exp(CARE_data[cols])\n",
    "prob_vals = exp_vals.div(exp_vals.sum(axis=1), axis=0)\n",
    "\n",
    "# Rename columns all at once\n",
    "prob_vals.columns = [f\"prob_{i}\" for i in range(0, 100)]\n",
    "\n",
    "# Join to original dataframe in one step\n",
    "CARE_data = pd.concat([CARE_data, prob_vals], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a389bebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "CARE_data=filter_pred_prob(CARE_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "914d1030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_CARE = get_LLM_value_per_item(CARE_data)\n",
    "model_item_scores_CARE_top_n = get_LLM_value_per_item_top_n(CARE_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_CARE = model_item_scores_CARE.merge(\n",
    "    model_item_scores_CARE_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4a344c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding task specific categories to save in all data\n",
    "# add item categories\n",
    "item_to_category = {\n",
    "    1: \"CAREa\", 2: \"CAREa\", 3: \"CAREa\",  4: \"CAREa\", 5: \"CAREa\",  6: \"CAREa\",  7: \"CAREa\",  8: \"CAREa\",  9: \"CAREa\",  10: \"CAREs\",\n",
    "    11: \"CAREs\", 12: \"CAREs\", 13: \"CAREs\",  14: \"CAREs\", 15: \"CAREs\",  16: \"CAREw\",  17: \"CAREw\",  18: \"CAREw\",  19: \"CAREw\"\n",
    "}\n",
    "\n",
    "model_item_scores_CARE[\"category\"] = model_item_scores_CARE[\"item\"].map(item_to_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b8720af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([all_data, model_item_scores_CARE], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1623f7ae",
   "metadata": {},
   "source": [
    "## DAST SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a1e720e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (1391040, 8)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "DAST_data = load_dataframes(task_name=\"DAST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "acf31561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one \n",
    "DAST_data[\"prob_1\"] = np.exp(DAST_data[\"1\"])/(np.exp(DAST_data[\"1\"]) + np.exp(DAST_data[\"2\"]))\n",
    "DAST_data[\"prob_2\"] = np.exp(DAST_data[\"2\"])/(np.exp(DAST_data[\"1\"]) + np.exp(DAST_data[\"2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6833d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "DAST_data=filter_pred_prob(DAST_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4d9b749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (DAST_data[\"flipped\"] == True) \n",
    "DAST_data.loc[mask, \"human_number\"] = 3 - DAST_data.loc[mask, \"human_number\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "79db3eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mappings for each DAST question:\n",
    "dast_maps = {\n",
    "    1: {1: 1, 2: 0},                           \n",
    "    2: {1: 1, 2: 0},\n",
    "    3: {1: 1, 2: 0},\n",
    "    4: {1: 0, 2: 1},\n",
    "    5: {1: 0, 2: 1},\n",
    "    6: {1: 1, 2: 0},\n",
    "    7: {1: 1, 2: 0},\n",
    "    8: {1: 1, 2: 0},\n",
    "    9: {1: 1, 2: 0},\n",
    "    10: {1: 1, 2: 0},\n",
    "    11: {1: 1, 2: 0},\n",
    "    12: {1: 1, 2: 0},\n",
    "    13: {1: 1, 2: 0},\n",
    "    14: {1: 1, 2: 0},\n",
    "    15: {1: 1, 2: 0},\n",
    "    16: {1: 1, 2: 0},\n",
    "    17: {1: 1, 2: 0},\n",
    "    18: {1: 1, 2: 0},\n",
    "    19: {1: 1, 2: 0},\n",
    "    20: {1: 1, 2: 0}\n",
    "}\n",
    "\n",
    "# Apply mapping row-wise based on item number\n",
    "def recode_dast(row):\n",
    "    mapping = dast_maps.get(row[\"item\"])\n",
    "    if mapping is not None:\n",
    "        return mapping.get(row[\"human_number\"], None)  # None if invalid code\n",
    "    return row[\"human_number\"]  \n",
    "\n",
    "DAST_data[\"human_number\"] = DAST_data.apply(recode_dast, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "806cd5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_DAST = get_LLM_value_per_item(DAST_data)\n",
    "model_item_scores_DAST_top_n = get_LLM_value_per_item_top_n(DAST_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_DAST = model_item_scores_DAST.merge(\n",
    "    model_item_scores_DAST_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "54525c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_DAST], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a376a9e9",
   "metadata": {},
   "source": [
    "## DM SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a50dd425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (1318866, 10)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "DM_data = load_dataframes(task_name=\"DM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f8a1b71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one\n",
    "DM_data[\"prob_1\"] = np.exp(DM_data[\"1\"])/(np.exp(DM_data[\"1\"]) + np.exp(DM_data[\"2\"]) + np.exp(DM_data[\"3\"]) + np.exp(DM_data[\"4\"]))\n",
    "DM_data[\"prob_2\"] = np.exp(DM_data[\"2\"])/(np.exp(DM_data[\"1\"]) + np.exp(DM_data[\"2\"]) + np.exp(DM_data[\"3\"]) + np.exp(DM_data[\"4\"]))\n",
    "DM_data[\"prob_3\"] = np.exp(DM_data[\"3\"])/(np.exp(DM_data[\"1\"]) + np.exp(DM_data[\"2\"]) + np.exp(DM_data[\"3\"]) + np.exp(DM_data[\"4\"]))\n",
    "DM_data[\"prob_4\"] = np.exp(DM_data[\"4\"])/(np.exp(DM_data[\"1\"]) + np.exp(DM_data[\"2\"]) + np.exp(DM_data[\"3\"]) + np.exp(DM_data[\"4\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4b778d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "DM_data=filter_pred_prob(DM_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "22d0cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (DM_data[\"flipped\"] == True) \n",
    "DM_data.loc[mask, \"human_number\"] = 5 - DM_data.loc[mask, \"human_number\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f0d4d183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mappings for DM, so that all 4s are transformed to 1s (like in original Fey dataset):\n",
    "# hier Abweichung von sonst Orientierung an Frey quest_proc df, aber da sonst später Umwandlung, hier gleich zu Scale 0-2\n",
    "mapping = {\n",
    "    4: 1,\n",
    "    3: 2,\n",
    "    2: 1,\n",
    "    1: 0\n",
    "}\n",
    "DM_data[\"human_number\"] = DM_data[\"human_number\"].map(mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cb8e201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_DM = get_LLM_value_per_item(DM_data)\n",
    "model_item_scores_DM_top_n = get_LLM_value_per_item_top_n(DM_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_DM = model_item_scores_DM.merge(\n",
    "    model_item_scores_DM_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "dd2ac9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>model</th>\n",
       "      <th>item</th>\n",
       "      <th>score</th>\n",
       "      <th>score_top_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dm scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>1</td>\n",
       "      <td>2.186655</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dm scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>2</td>\n",
       "      <td>2.151140</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dm scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>3</td>\n",
       "      <td>2.506346</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dm scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>4</td>\n",
       "      <td>2.011654</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dm scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>5</td>\n",
       "      <td>1.962582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>Dm scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>15</td>\n",
       "      <td>1.264512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>Dm scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>16</td>\n",
       "      <td>1.315541</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>Dm scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>17</td>\n",
       "      <td>1.421758</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>Dm scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>18</td>\n",
       "      <td>1.251913</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>Dm scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>19</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>874 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    experiment                      model  item     score  score_top_n\n",
       "0     Dm scale  Apertus-70B-Instruct-2509     1  2.186655            2\n",
       "1     Dm scale  Apertus-70B-Instruct-2509     2  2.151140            2\n",
       "2     Dm scale  Apertus-70B-Instruct-2509     3  2.506346            2\n",
       "3     Dm scale  Apertus-70B-Instruct-2509     4  2.011654            2\n",
       "4     Dm scale  Apertus-70B-Instruct-2509     5  1.962582            2\n",
       "..         ...                        ...   ...       ...          ...\n",
       "869   Dm scale             zephyr-7b-beta    15  1.264512            1\n",
       "870   Dm scale             zephyr-7b-beta    16  1.315541            1\n",
       "871   Dm scale             zephyr-7b-beta    17  1.421758            1\n",
       "872   Dm scale             zephyr-7b-beta    18  1.251913            1\n",
       "873   Dm scale             zephyr-7b-beta    19  2.500000            1\n",
       "\n",
       "[874 rows x 5 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_item_scores_DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "125ae7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_DM], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf36e830",
   "metadata": {},
   "source": [
    "## DOSPERT SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4828b1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (2780240, 11)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "DOSPERT_data = load_dataframes(task_name=\"DOSPERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "df6de3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one\n",
    "DOSPERT_data[\"prob_1\"] = np.exp(DOSPERT_data[\"1\"])/(np.exp(DOSPERT_data[\"1\"]) + np.exp(DOSPERT_data[\"2\"]) + np.exp(DOSPERT_data[\"3\"]) + np.exp(DOSPERT_data[\"4\"]) + np.exp(DOSPERT_data[\"5\"]))\n",
    "DOSPERT_data[\"prob_2\"] = np.exp(DOSPERT_data[\"2\"])/(np.exp(DOSPERT_data[\"1\"]) + np.exp(DOSPERT_data[\"2\"]) + np.exp(DOSPERT_data[\"3\"]) + np.exp(DOSPERT_data[\"4\"]) + np.exp(DOSPERT_data[\"5\"]))\n",
    "DOSPERT_data[\"prob_3\"] = np.exp(DOSPERT_data[\"3\"])/(np.exp(DOSPERT_data[\"1\"]) + np.exp(DOSPERT_data[\"2\"]) + np.exp(DOSPERT_data[\"3\"]) + np.exp(DOSPERT_data[\"4\"]) + np.exp(DOSPERT_data[\"5\"]))\n",
    "DOSPERT_data[\"prob_4\"] = np.exp(DOSPERT_data[\"4\"])/(np.exp(DOSPERT_data[\"1\"]) + np.exp(DOSPERT_data[\"2\"]) + np.exp(DOSPERT_data[\"3\"]) + np.exp(DOSPERT_data[\"4\"]) + np.exp(DOSPERT_data[\"5\"]))\n",
    "DOSPERT_data[\"prob_5\"] = np.exp(DOSPERT_data[\"5\"])/(np.exp(DOSPERT_data[\"1\"]) + np.exp(DOSPERT_data[\"2\"]) + np.exp(DOSPERT_data[\"3\"]) + np.exp(DOSPERT_data[\"4\"]) + np.exp(DOSPERT_data[\"5\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c87c6117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "DOSPERT_data=filter_pred_prob(DOSPERT_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "270ff6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (DOSPERT_data[\"flipped\"] == 'yes') \n",
    "DOSPERT_data.loc[mask, \"human_number\"] = 6 - DOSPERT_data.loc[mask, \"human_number\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a15c7fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_DOSPERT = get_LLM_value_per_item(DOSPERT_data)\n",
    "model_item_scores_DOSPERT_top_n = get_LLM_value_per_item_top_n(DOSPERT_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_DOSPERT = model_item_scores_DOSPERT.merge(\n",
    "    model_item_scores_DOSPERT_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "005799af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding task specific categories to save in all data\n",
    "\n",
    "# add item categories\n",
    "item_to_category = {\n",
    "    1: \"Social\", 10: \"Social\", 16: \"Social\", 19: \"Social\", 23: \"Social\", 26: \"Social\", 34: \"Social\", 35: \"Social\",\n",
    "    2: \"Recreational\", 6: \"Recreational\", 15: \"Recreational\", 17: \"Recreational\", 21: \"Recreational\", 31: \"Recreational\", 37: \"Recreational\", 38: \"Recreational\",\n",
    "    3: \"Gambling\", 11: \"Gambling\", 22: \"Gambling\", 33: \"Gambling\",\n",
    "    4: \"Health\", 8: \"Health\", 27: \"Health\", 29: \"Health\", 32: \"Health\", 36: \"Health\", 39: \"Health\", 40: \"Health\",\n",
    "    5: \"Ethical\", 9: \"Ethical\", 12: \"Ethical\", 13: \"Ethical\", 14: \"Ethical\", 20: \"Ethical\", 25: \"Ethical\", 28: \"Ethical\",\n",
    "    7: \"Investment\", 18: \"Investment\", 24: \"Investment\", 30: \"Investment\"\n",
    "}\n",
    "\n",
    "model_item_scores_DOSPERT[\"category\"] = model_item_scores_DOSPERT[\"item\"].map(item_to_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "eae478ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_DOSPERT], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cbad99",
   "metadata": {},
   "source": [
    "## FTND SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b79895fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (163162, 10)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "FTND_data = load_dataframes(task_name=\"FTND\")\n",
    "# load human daa also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3d512cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one (tun so als hätten wir sehr guten Prompt, dann würde LLM nur zwischen möglichen Antwortalternativen aussuchen, da simulieren wir dadurch)\n",
    "mask = (FTND_data[\"item\"] == 1)\n",
    "FTND_data.loc[mask, \"prob_1\"] = np.exp(FTND_data.loc[mask, \"1\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]) + np.exp(FTND_data.loc[mask, \"3\"]))\n",
    "FTND_data.loc[mask, \"prob_2\"] = np.exp(FTND_data.loc[mask, \"2\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]) + np.exp(FTND_data.loc[mask, \"3\"]))\n",
    "FTND_data.loc[mask, \"prob_3\"] = np.exp(FTND_data.loc[mask, \"3\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]) + np.exp(FTND_data.loc[mask, \"3\"]))\n",
    "\n",
    "mask = (FTND_data[\"item\"].isin([3, 4, 6, 7]))\n",
    "FTND_data.loc[mask, \"prob_1\"] = np.exp(FTND_data.loc[mask, \"1\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]))\n",
    "FTND_data.loc[mask, \"prob_2\"] = np.exp(FTND_data.loc[mask, \"2\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]))\n",
    "\n",
    "mask = (FTND_data[\"item\"].isin([2, 5]))\n",
    "FTND_data.loc[mask, \"prob_1\"] = np.exp(FTND_data.loc[mask, \"1\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]) + np.exp(FTND_data.loc[mask, \"3\"]) + np.exp(FTND_data.loc[mask, \"4\"]))\n",
    "FTND_data.loc[mask, \"prob_2\"] = np.exp(FTND_data.loc[mask, \"2\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]) + np.exp(FTND_data.loc[mask, \"3\"]) + np.exp(FTND_data.loc[mask, \"4\"]))\n",
    "FTND_data.loc[mask, \"prob_3\"] = np.exp(FTND_data.loc[mask, \"3\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]) + np.exp(FTND_data.loc[mask, \"3\"]) + np.exp(FTND_data.loc[mask, \"4\"]))\n",
    "FTND_data.loc[mask, \"prob_4\"] = np.exp(FTND_data.loc[mask, \"4\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]) + np.exp(FTND_data.loc[mask, \"3\"]) + np.exp(FTND_data.loc[mask, \"4\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f407d56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "FTND_data=filter_pred_prob(FTND_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6c3668c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (FTND_data[\"flipped\"] == True) & (FTND_data[\"item\"] == 1)\n",
    "FTND_data.loc[mask, \"human_number\"] = 4 - FTND_data.loc[mask, \"human_number\"]\n",
    "mask = (FTND_data[\"flipped\"] == True) & (FTND_data[\"item\"].isin([3, 4, 6, 7]))\n",
    "FTND_data.loc[mask, \"human_number\"] = 3 - FTND_data.loc[mask, \"human_number\"]\n",
    "mask = (FTND_data[\"flipped\"] == True) & (FTND_data[\"item\"].isin([2, 5]))\n",
    "FTND_data.loc[mask, \"human_number\"] = 5 - FTND_data.loc[mask, \"human_number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "813faab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mappings for each FTND question:\n",
    "ftnd_maps = {\n",
    "    1: {1: 2, 2: 0, 3: 1},             # FTND_1Eingangsfrage: smoke?\n",
    "    2: {1: 3, 2: 2, 3: 1, 4: 0},       # FTND_1: time until first cigarette\n",
    "    3: {1: 1, 2: 0},                   # FTND_2: difficult to refrain\n",
    "    4: {1: 1, 2: 0},                   # FTND_3: which cigarette hardest to give up\n",
    "    5: {1: 0, 2: 1, 3: 2, 4: 3},       # FTND_4: cigarettes per day\n",
    "    6: {1: 1, 2: 0},                   # FTND_5: smoke more frequently in morning\n",
    "    7: {1: 1, 2: 0}                    # FTND_6: smoke when ill\n",
    "}\n",
    "\n",
    "# Apply mapping row-wise based on item number\n",
    "def recode_ftnd(row):\n",
    "    mapping = ftnd_maps.get(row[\"item\"])\n",
    "    if mapping is not None:\n",
    "        return mapping.get(row[\"human_number\"], None) \n",
    "    return row[\"human_number\"]  \n",
    "\n",
    "FTND_data[\"human_number\"] = FTND_data.apply(recode_ftnd, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0bf07e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_FTND = get_LLM_value_per_item(FTND_data)\n",
    "model_item_scores_FTND_top_n = get_LLM_value_per_item_top_n(FTND_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_FTND = model_item_scores_FTND.merge(\n",
    "    model_item_scores_FTND_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ce78b07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_FTND], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54306e48",
   "metadata": {},
   "source": [
    "## GABS SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "dc20119a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (581210, 10)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "GABS_data = load_dataframes(task_name=\"GABS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8cf18026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one\n",
    "\n",
    "# columns representing log-probabilities\n",
    "answer_cols = [\"1\", \"2\", \"3\", \"4\"]\n",
    "\n",
    "# make a copy to avoid SettingWithCopy warnings\n",
    "GABS_data = GABS_data.copy()\n",
    "\n",
    "# case 1: item == 1 → only options 1 and 2\n",
    "mask_item1 = GABS_data[\"item\"] == 1\n",
    "exp_vals_item1 = np.exp(GABS_data.loc[mask_item1, [\"1\", \"2\"]])\n",
    "probs_item1 = exp_vals_item1.div(exp_vals_item1.sum(axis=1), axis=0)\n",
    "probs_item1.columns = [\"prob_1\", \"prob_2\"]\n",
    "\n",
    "# case 2: items 2–17 → options 1–4\n",
    "mask_item2plus = GABS_data[\"item\"].between(2, 17)\n",
    "exp_vals_item2plus = np.exp(GABS_data.loc[mask_item2plus, answer_cols])\n",
    "probs_item2plus = exp_vals_item2plus.div(exp_vals_item2plus.sum(axis=1), axis=0)\n",
    "probs_item2plus.columns = [f\"prob_{c}\" for c in answer_cols]\n",
    "\n",
    "# merge both parts back into original df\n",
    "GABS_data = GABS_data.join(pd.concat([probs_item1, probs_item2plus]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "45796a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "GABS_data=filter_pred_prob(GABS_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "29b40036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (GABS_data[\"flipped\"] == True) & (GABS_data[\"item\"] == 1)\n",
    "GABS_data.loc[mask, \"human_number\"] = 3 - GABS_data.loc[mask, \"human_number\"]\n",
    "mask = (GABS_data[\"flipped\"] == True) & (GABS_data[\"item\"].isin(range(2,17)))\n",
    "GABS_data.loc[mask, \"human_number\"] = 5 - GABS_data.loc[mask, \"human_number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6cb6a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_GABS = get_LLM_value_per_item(GABS_data)\n",
    "model_item_scores_GABS_top_n = get_LLM_value_per_item_top_n(GABS_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_GABS = model_item_scores_GABS.merge(\n",
    "    model_item_scores_GABS_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "abcf63ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_GABS], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed59198",
   "metadata": {},
   "source": [
    "## PG SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e97aa4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (1127322, 13)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "PG_data = load_dataframes(task_name=\"PG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "66851dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one \n",
    "\n",
    "mask = (PG_data[\"item\"].isin([1, 26]))\n",
    "PG_data.loc[mask, \"prob_1\"] = np.exp(PG_data.loc[mask, \"1\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]))\n",
    "PG_data.loc[mask, \"prob_2\"] = np.exp(PG_data.loc[mask, \"2\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]))\n",
    "\n",
    "\n",
    "\n",
    "mask = (PG_data[\"item\"].isin(range(2, 21)))\n",
    "PG_data.loc[mask, \"prob_1\"] = np.exp(PG_data.loc[mask, \"1\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]))\n",
    "PG_data.loc[mask, \"prob_2\"] = np.exp(PG_data.loc[mask, \"2\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]))\n",
    "PG_data.loc[mask, \"prob_3\"] = np.exp(PG_data.loc[mask, \"3\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]))\n",
    "PG_data.loc[mask, \"prob_4\"] = np.exp(PG_data.loc[mask, \"4\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]))\n",
    "PG_data.loc[mask, \"prob_5\"] = np.exp(PG_data.loc[mask, \"5\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]))\n",
    "\n",
    "\n",
    "\n",
    "mask = (PG_data[\"item\"] == 25)\n",
    "PG_data.loc[mask, \"prob_1\"] = np.exp(PG_data.loc[mask, \"1\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]) + np.exp(PG_data.loc[mask, \"6\"]))\n",
    "PG_data.loc[mask, \"prob_2\"] = np.exp(PG_data.loc[mask, \"2\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]) + np.exp(PG_data.loc[mask, \"6\"]))\n",
    "PG_data.loc[mask, \"prob_3\"] = np.exp(PG_data.loc[mask, \"3\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]) + np.exp(PG_data.loc[mask, \"6\"]))\n",
    "PG_data.loc[mask, \"prob_4\"] = np.exp(PG_data.loc[mask, \"4\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]) + np.exp(PG_data.loc[mask, \"6\"]))\n",
    "PG_data.loc[mask, \"prob_5\"] = np.exp(PG_data.loc[mask, \"5\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]) + np.exp(PG_data.loc[mask, \"6\"]))\n",
    "PG_data.loc[mask, \"prob_6\"] = np.exp(PG_data.loc[mask, \"6\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]) + np.exp(PG_data.loc[mask, \"6\"]))\n",
    "\n",
    "\n",
    "mask = (PG_data[\"item\"].isin([21, 22, 23, 24, 27, 28, 29, 30, 31, 32]))\n",
    "PG_data.loc[mask, \"prob_0\"] = np.exp(PG_data.loc[mask, \"0\"])/(np.exp(PG_data.loc[mask, \"0\"]) + np.exp(PG_data.loc[mask, \"1\"]))\n",
    "PG_data.loc[mask, \"prob_1\"] = np.exp(PG_data.loc[mask, \"1\"])/(np.exp(PG_data.loc[mask, \"0\"]) + np.exp(PG_data.loc[mask, \"1\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "dfc61164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "PG_data=filter_pred_prob(PG_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "66d9d25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (PG_data[\"flipped\"] == True) & (PG_data[\"item\"].isin([1, 26]))\n",
    "PG_data.loc[mask, \"human_number\"] = 3 - PG_data.loc[mask, \"human_number\"]\n",
    "\n",
    "mask = (PG_data[\"flipped\"] == True) & (PG_data[\"item\"].isin(range(2, 21)))\n",
    "PG_data.loc[mask, \"human_number\"] = 6 - PG_data.loc[mask, \"human_number\"]\n",
    "\n",
    "mask = (PG_data[\"flipped\"] == True) & (PG_data[\"item\"] == 25)\n",
    "PG_data.loc[mask, \"human_number\"] = 7 - PG_data.loc[mask, \"human_number\"]\n",
    "\n",
    "mask = (PG_data[\"flipped\"] == True) & (PG_data[\"item\"].isin([21, 22, 23, 24, 27, 28, 29, 30, 31, 32]))\n",
    "PG_data.loc[mask, \"human_number\"] = 1 - PG_data.loc[mask, \"human_number\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1d02db9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human_number</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>model</th>\n",
       "      <th>item</th>\n",
       "      <th>...</th>\n",
       "      <th>flipped</th>\n",
       "      <th>experiment</th>\n",
       "      <th>prob_1</th>\n",
       "      <th>prob_2</th>\n",
       "      <th>prob_3</th>\n",
       "      <th>prob_4</th>\n",
       "      <th>prob_5</th>\n",
       "      <th>prob_6</th>\n",
       "      <th>prob_0</th>\n",
       "      <th>prob_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-4.853441</td>\n",
       "      <td>-12.771458</td>\n",
       "      <td>-8.134900</td>\n",
       "      <td>-4.965661</td>\n",
       "      <td>-17.027287</td>\n",
       "      <td>-5.681488</td>\n",
       "      <td>-8.975953</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>9.597985e-03</td>\n",
       "      <td>9.904020e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.904020e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>-17.446447</td>\n",
       "      <td>-9.905339</td>\n",
       "      <td>-17.918111</td>\n",
       "      <td>-15.600988</td>\n",
       "      <td>-11.887881</td>\n",
       "      <td>-11.460297</td>\n",
       "      <td>-15.054214</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>7.393122e-01</td>\n",
       "      <td>2.448641e-04</td>\n",
       "      <td>2.484500e-03</td>\n",
       "      <td>1.018171e-01</td>\n",
       "      <td>1.561414e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.393122e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>-11.609304</td>\n",
       "      <td>-4.760531</td>\n",
       "      <td>-4.507970</td>\n",
       "      <td>-11.475012</td>\n",
       "      <td>-16.475625</td>\n",
       "      <td>-6.549677</td>\n",
       "      <td>-6.463889</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>4.072254e-01</td>\n",
       "      <td>5.242287e-01</td>\n",
       "      <td>4.940521e-04</td>\n",
       "      <td>3.326860e-06</td>\n",
       "      <td>6.804850e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.072254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>-4.413929</td>\n",
       "      <td>-12.572546</td>\n",
       "      <td>-15.973095</td>\n",
       "      <td>-16.890532</td>\n",
       "      <td>-7.668291</td>\n",
       "      <td>-18.878776</td>\n",
       "      <td>-15.435804</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>7.357761e-03</td>\n",
       "      <td>2.454178e-04</td>\n",
       "      <td>9.805464e-05</td>\n",
       "      <td>9.922853e-01</td>\n",
       "      <td>1.342718e-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.357761e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-7.646750</td>\n",
       "      <td>-16.282776</td>\n",
       "      <td>-8.659167</td>\n",
       "      <td>-4.129313</td>\n",
       "      <td>-11.105185</td>\n",
       "      <td>-15.930389</td>\n",
       "      <td>-6.091965</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>5.208995e-06</td>\n",
       "      <td>1.065725e-02</td>\n",
       "      <td>9.884068e-01</td>\n",
       "      <td>9.233223e-04</td>\n",
       "      <td>7.409586e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.208995e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-17.652555</td>\n",
       "      <td>-2.944437</td>\n",
       "      <td>-11.275056</td>\n",
       "      <td>-5.055902</td>\n",
       "      <td>-13.937715</td>\n",
       "      <td>-18.723430</td>\n",
       "      <td>-5.785244</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>8.918073e-01</td>\n",
       "      <td>2.149458e-04</td>\n",
       "      <td>1.079626e-01</td>\n",
       "      <td>1.499516e-05</td>\n",
       "      <td>1.251818e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.918073e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>-6.244376</td>\n",
       "      <td>-9.335480</td>\n",
       "      <td>-5.704062</td>\n",
       "      <td>-14.069850</td>\n",
       "      <td>-9.942442</td>\n",
       "      <td>-9.320021</td>\n",
       "      <td>-15.271280</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>2.479194e-02</td>\n",
       "      <td>9.363003e-01</td>\n",
       "      <td>2.178712e-04</td>\n",
       "      <td>1.351170e-02</td>\n",
       "      <td>2.517817e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.479194e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>-11.514423</td>\n",
       "      <td>-18.936642</td>\n",
       "      <td>-14.655351</td>\n",
       "      <td>-15.391629</td>\n",
       "      <td>-9.498850</td>\n",
       "      <td>-12.824579</td>\n",
       "      <td>-6.779997</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>7.625900e-05</td>\n",
       "      <td>5.516102e-03</td>\n",
       "      <td>2.641621e-03</td>\n",
       "      <td>9.573527e-01</td>\n",
       "      <td>3.441330e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.625900e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>-1.748086</td>\n",
       "      <td>-8.594767</td>\n",
       "      <td>-12.453748</td>\n",
       "      <td>-18.989625</td>\n",
       "      <td>-2.690954</td>\n",
       "      <td>-4.541506</td>\n",
       "      <td>-10.639783</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>2.352730e-03</td>\n",
       "      <td>4.961785e-05</td>\n",
       "      <td>7.196854e-08</td>\n",
       "      <td>8.621157e-01</td>\n",
       "      <td>1.354818e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.352730e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>-12.120269</td>\n",
       "      <td>-2.446993</td>\n",
       "      <td>-9.991626</td>\n",
       "      <td>-15.929289</td>\n",
       "      <td>-15.656009</td>\n",
       "      <td>-8.411653</td>\n",
       "      <td>-10.441589</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>9.969095e-01</td>\n",
       "      <td>5.273069e-04</td>\n",
       "      <td>1.391134e-06</td>\n",
       "      <td>1.828324e-06</td>\n",
       "      <td>2.559981e-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.969095e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>-3.164640</td>\n",
       "      <td>-19.828281</td>\n",
       "      <td>-8.741958</td>\n",
       "      <td>-18.855407</td>\n",
       "      <td>-3.537705</td>\n",
       "      <td>-3.411805</td>\n",
       "      <td>-12.656328</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>3.933213e-08</td>\n",
       "      <td>2.567298e-03</td>\n",
       "      <td>1.040546e-07</td>\n",
       "      <td>4.673635e-01</td>\n",
       "      <td>5.300690e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.933213e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.535474</td>\n",
       "      <td>-13.745568</td>\n",
       "      <td>-11.169644</td>\n",
       "      <td>-12.058271</td>\n",
       "      <td>-18.053246</td>\n",
       "      <td>-9.299375</td>\n",
       "      <td>-18.159373</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>9.536218e-03</td>\n",
       "      <td>1.253389e-01</td>\n",
       "      <td>5.154185e-02</td>\n",
       "      <td>1.284031e-04</td>\n",
       "      <td>8.134546e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.253389e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>-15.939238</td>\n",
       "      <td>-19.897995</td>\n",
       "      <td>-11.346637</td>\n",
       "      <td>-15.220590</td>\n",
       "      <td>-4.047952</td>\n",
       "      <td>-11.073953</td>\n",
       "      <td>-16.335162</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>1.305355e-07</td>\n",
       "      <td>6.753616e-04</td>\n",
       "      <td>1.403136e-05</td>\n",
       "      <td>9.984234e-01</td>\n",
       "      <td>8.870770e-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.305355e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>-14.869076</td>\n",
       "      <td>-7.491480</td>\n",
       "      <td>-6.063466</td>\n",
       "      <td>-13.508606</td>\n",
       "      <td>-11.153680</td>\n",
       "      <td>-6.261993</td>\n",
       "      <td>-7.525839</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>1.160363e-01</td>\n",
       "      <td>4.839185e-01</td>\n",
       "      <td>2.827413e-04</td>\n",
       "      <td>2.979344e-03</td>\n",
       "      <td>3.967831e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.160363e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>-6.013635</td>\n",
       "      <td>-6.891976</td>\n",
       "      <td>-17.720779</td>\n",
       "      <td>-4.483148</td>\n",
       "      <td>-7.861017</td>\n",
       "      <td>-12.272180</td>\n",
       "      <td>-6.399232</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>7.996805e-02</td>\n",
       "      <td>1.584992e-06</td>\n",
       "      <td>8.893183e-01</td>\n",
       "      <td>3.034362e-02</td>\n",
       "      <td>3.684033e-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.996805e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>-3.953839</td>\n",
       "      <td>-6.837452</td>\n",
       "      <td>-6.523226</td>\n",
       "      <td>-10.148383</td>\n",
       "      <td>-9.586574</td>\n",
       "      <td>-3.974807</td>\n",
       "      <td>-8.945127</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>5.005643e-02</td>\n",
       "      <td>6.853726e-02</td>\n",
       "      <td>1.826168e-03</td>\n",
       "      <td>3.202813e-03</td>\n",
       "      <td>8.763773e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.005643e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>-9.966206</td>\n",
       "      <td>-11.212210</td>\n",
       "      <td>-17.889021</td>\n",
       "      <td>-19.972193</td>\n",
       "      <td>-19.692258</td>\n",
       "      <td>-4.270222</td>\n",
       "      <td>-19.197993</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>9.654124e-04</td>\n",
       "      <td>1.216216e-06</td>\n",
       "      <td>1.514609e-07</td>\n",
       "      <td>2.003893e-07</td>\n",
       "      <td>9.990330e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.654124e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>-6.553882</td>\n",
       "      <td>-2.064859</td>\n",
       "      <td>-18.543132</td>\n",
       "      <td>-8.348278</td>\n",
       "      <td>-6.482805</td>\n",
       "      <td>-12.151406</td>\n",
       "      <td>-8.101217</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>9.862247e-01</td>\n",
       "      <td>6.879436e-08</td>\n",
       "      <td>1.841288e-03</td>\n",
       "      <td>1.189286e-02</td>\n",
       "      <td>4.106238e-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.862247e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>-11.599497</td>\n",
       "      <td>-14.736189</td>\n",
       "      <td>-4.059242</td>\n",
       "      <td>-1.042094</td>\n",
       "      <td>-19.359211</td>\n",
       "      <td>-10.050354</td>\n",
       "      <td>-2.487254</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>1.076287e-06</td>\n",
       "      <td>4.665167e-02</td>\n",
       "      <td>9.532306e-01</td>\n",
       "      <td>1.057244e-08</td>\n",
       "      <td>1.166703e-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.076287e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>-17.737183</td>\n",
       "      <td>-3.587985</td>\n",
       "      <td>-3.738148</td>\n",
       "      <td>-6.236663</td>\n",
       "      <td>-8.785897</td>\n",
       "      <td>-18.534610</td>\n",
       "      <td>-8.590058</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>5.163047e-01</td>\n",
       "      <td>4.443151e-01</td>\n",
       "      <td>3.652579e-02</td>\n",
       "      <td>2.854182e-03</td>\n",
       "      <td>1.665978e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.163047e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>-9.046478</td>\n",
       "      <td>-14.296781</td>\n",
       "      <td>-6.231234</td>\n",
       "      <td>-10.928749</td>\n",
       "      <td>-15.950292</td>\n",
       "      <td>-17.530324</td>\n",
       "      <td>-5.551539</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>5.218549e-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.994781</td>\n",
       "      <td>5.218549e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>-9.470537</td>\n",
       "      <td>-5.080055</td>\n",
       "      <td>-4.344243</td>\n",
       "      <td>-19.620429</td>\n",
       "      <td>-18.658758</td>\n",
       "      <td>-12.447744</td>\n",
       "      <td>-4.390555</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>9.877570e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012243</td>\n",
       "      <td>9.877570e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>-14.463921</td>\n",
       "      <td>-8.372520</td>\n",
       "      <td>-18.285833</td>\n",
       "      <td>-5.083320</td>\n",
       "      <td>-15.086711</td>\n",
       "      <td>-12.632132</td>\n",
       "      <td>-1.082217</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>9.977429e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>9.977429e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>-9.740493</td>\n",
       "      <td>-17.498923</td>\n",
       "      <td>-14.538855</td>\n",
       "      <td>-2.422009</td>\n",
       "      <td>-7.921274</td>\n",
       "      <td>-14.927116</td>\n",
       "      <td>-10.058953</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>4.269443e-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999573</td>\n",
       "      <td>9.995731e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>-10.168671</td>\n",
       "      <td>-17.330136</td>\n",
       "      <td>-16.542606</td>\n",
       "      <td>-9.499634</td>\n",
       "      <td>-18.988839</td>\n",
       "      <td>-2.451496</td>\n",
       "      <td>-17.512103</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>3.450731e-07</td>\n",
       "      <td>7.584572e-07</td>\n",
       "      <td>8.682696e-04</td>\n",
       "      <td>6.569701e-08</td>\n",
       "      <td>9.991303e-01</td>\n",
       "      <td>2.876629e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.876629e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>-9.645811</td>\n",
       "      <td>-1.380192</td>\n",
       "      <td>-14.828769</td>\n",
       "      <td>-10.337118</td>\n",
       "      <td>-1.115997</td>\n",
       "      <td>-5.102322</td>\n",
       "      <td>-9.988841</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>9.999986e-01</td>\n",
       "      <td>1.443301e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999986e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>-18.963584</td>\n",
       "      <td>-19.982803</td>\n",
       "      <td>-5.846994</td>\n",
       "      <td>-6.221244</td>\n",
       "      <td>-19.421245</td>\n",
       "      <td>-18.680090</td>\n",
       "      <td>-16.929105</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>2.651794e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.734821</td>\n",
       "      <td>2.651794e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>-6.382387</td>\n",
       "      <td>-9.341503</td>\n",
       "      <td>-8.296966</td>\n",
       "      <td>-11.121670</td>\n",
       "      <td>-15.709461</td>\n",
       "      <td>-7.504852</td>\n",
       "      <td>-18.494748</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>4.930742e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.950693</td>\n",
       "      <td>4.930742e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>-11.277008</td>\n",
       "      <td>-16.251278</td>\n",
       "      <td>-16.861466</td>\n",
       "      <td>-10.117559</td>\n",
       "      <td>-12.487587</td>\n",
       "      <td>-17.472704</td>\n",
       "      <td>-15.625318</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>6.866099e-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993134</td>\n",
       "      <td>6.866099e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>-6.684896</td>\n",
       "      <td>-1.080679</td>\n",
       "      <td>-12.729331</td>\n",
       "      <td>-4.052948</td>\n",
       "      <td>-17.695944</td>\n",
       "      <td>-1.251427</td>\n",
       "      <td>-19.551453</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>9.963312e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003669</td>\n",
       "      <td>9.963312e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>-18.986575</td>\n",
       "      <td>-15.754553</td>\n",
       "      <td>-14.111929</td>\n",
       "      <td>-12.192560</td>\n",
       "      <td>-10.722381</td>\n",
       "      <td>-2.067437</td>\n",
       "      <td>-6.119924</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>9.620217e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.037978</td>\n",
       "      <td>9.620217e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>-5.616224</td>\n",
       "      <td>-2.594684</td>\n",
       "      <td>-19.332469</td>\n",
       "      <td>-13.088525</td>\n",
       "      <td>-3.304962</td>\n",
       "      <td>-13.196802</td>\n",
       "      <td>-9.165189</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>9.535378e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.046462</td>\n",
       "      <td>4.646217e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>-17.568244</td>\n",
       "      <td>-15.769119</td>\n",
       "      <td>-5.120985</td>\n",
       "      <td>-9.115037</td>\n",
       "      <td>-11.549666</td>\n",
       "      <td>-2.912518</td>\n",
       "      <td>-9.627494</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>2.374455e-05</td>\n",
       "      <td>9.999763e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.374455e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>-15.708751</td>\n",
       "      <td>-7.706529</td>\n",
       "      <td>-1.471847</td>\n",
       "      <td>-5.006043</td>\n",
       "      <td>-11.812866</td>\n",
       "      <td>-1.085461</td>\n",
       "      <td>-7.020561</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>1.956417e-03</td>\n",
       "      <td>9.980436e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.980436e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>-4.068078</td>\n",
       "      <td>-9.284718</td>\n",
       "      <td>-9.525142</td>\n",
       "      <td>-13.089569</td>\n",
       "      <td>-14.910239</td>\n",
       "      <td>-3.269237</td>\n",
       "      <td>-5.693149</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>5.598181e-01</td>\n",
       "      <td>4.401819e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.598181e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>-5.143941</td>\n",
       "      <td>-6.356836</td>\n",
       "      <td>-19.443614</td>\n",
       "      <td>-2.666219</td>\n",
       "      <td>-2.198695</td>\n",
       "      <td>-3.783315</td>\n",
       "      <td>-16.693123</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>9.999979e-01</td>\n",
       "      <td>2.072449e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.072449e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5</td>\n",
       "      <td>-14.608436</td>\n",
       "      <td>-12.561386</td>\n",
       "      <td>-19.628997</td>\n",
       "      <td>-10.920126</td>\n",
       "      <td>-9.109434</td>\n",
       "      <td>-19.371646</td>\n",
       "      <td>-11.893658</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>2.650722e-02</td>\n",
       "      <td>2.259123e-05</td>\n",
       "      <td>1.368216e-01</td>\n",
       "      <td>8.366194e-01</td>\n",
       "      <td>2.922173e-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.650722e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5</td>\n",
       "      <td>-14.509232</td>\n",
       "      <td>-1.931259</td>\n",
       "      <td>-5.943549</td>\n",
       "      <td>-8.274400</td>\n",
       "      <td>-11.809697</td>\n",
       "      <td>-3.256570</td>\n",
       "      <td>-7.673552</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>7.778334e-01</td>\n",
       "      <td>1.407250e-02</td>\n",
       "      <td>1.368029e-03</td>\n",
       "      <td>3.987819e-05</td>\n",
       "      <td>2.066862e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.778334e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5</td>\n",
       "      <td>-5.233611</td>\n",
       "      <td>-13.594575</td>\n",
       "      <td>-16.486376</td>\n",
       "      <td>-4.732742</td>\n",
       "      <td>-10.454857</td>\n",
       "      <td>-12.741831</td>\n",
       "      <td>-14.267912</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>1.411650e-04</td>\n",
       "      <td>7.831296e-06</td>\n",
       "      <td>9.962593e-01</td>\n",
       "      <td>3.260539e-03</td>\n",
       "      <td>3.311839e-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.411650e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5</td>\n",
       "      <td>-6.327198</td>\n",
       "      <td>-2.639945</td>\n",
       "      <td>-10.391993</td>\n",
       "      <td>-11.799750</td>\n",
       "      <td>-3.561112</td>\n",
       "      <td>-12.108141</td>\n",
       "      <td>-19.488369</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>7.149666e-01</td>\n",
       "      <td>3.073366e-04</td>\n",
       "      <td>7.520267e-05</td>\n",
       "      <td>2.845956e-01</td>\n",
       "      <td>5.524594e-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.149666e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2</td>\n",
       "      <td>-2.748886</td>\n",
       "      <td>-15.150781</td>\n",
       "      <td>-17.077592</td>\n",
       "      <td>-6.651805</td>\n",
       "      <td>-6.292852</td>\n",
       "      <td>-19.478307</td>\n",
       "      <td>-5.109796</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>8.374647e-05</td>\n",
       "      <td>1.219448e-05</td>\n",
       "      <td>4.111731e-01</td>\n",
       "      <td>5.887298e-01</td>\n",
       "      <td>1.105467e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.887298e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5</td>\n",
       "      <td>-3.896191</td>\n",
       "      <td>-4.110298</td>\n",
       "      <td>-1.231510</td>\n",
       "      <td>-7.906744</td>\n",
       "      <td>-15.754623</td>\n",
       "      <td>-13.890994</td>\n",
       "      <td>-6.510427</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>5.314852e-02</td>\n",
       "      <td>9.456548e-01</td>\n",
       "      <td>1.193206e-03</td>\n",
       "      <td>4.660421e-07</td>\n",
       "      <td>3.004614e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.314852e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5</td>\n",
       "      <td>-15.332476</td>\n",
       "      <td>-12.137419</td>\n",
       "      <td>-19.344030</td>\n",
       "      <td>-19.728639</td>\n",
       "      <td>-14.967679</td>\n",
       "      <td>-3.397757</td>\n",
       "      <td>-12.252119</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>1.600809e-04</td>\n",
       "      <td>1.187266e-07</td>\n",
       "      <td>8.081922e-08</td>\n",
       "      <td>9.444371e-06</td>\n",
       "      <td>9.998303e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.600809e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5</td>\n",
       "      <td>-18.690948</td>\n",
       "      <td>-6.532952</td>\n",
       "      <td>-7.393585</td>\n",
       "      <td>-7.924506</td>\n",
       "      <td>-9.628544</td>\n",
       "      <td>-13.402602</td>\n",
       "      <td>-2.685460</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>5.821162e-01</td>\n",
       "      <td>2.461737e-01</td>\n",
       "      <td>1.447656e-01</td>\n",
       "      <td>2.633973e-02</td>\n",
       "      <td>6.047261e-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.821162e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5</td>\n",
       "      <td>-9.180610</td>\n",
       "      <td>-15.075201</td>\n",
       "      <td>-17.739412</td>\n",
       "      <td>-13.387644</td>\n",
       "      <td>-12.876974</td>\n",
       "      <td>-1.220062</td>\n",
       "      <td>-11.412389</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>9.611318e-07</td>\n",
       "      <td>6.694697e-08</td>\n",
       "      <td>5.196128e-06</td>\n",
       "      <td>8.658862e-06</td>\n",
       "      <td>9.999851e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.611318e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5</td>\n",
       "      <td>-15.383850</td>\n",
       "      <td>-9.155782</td>\n",
       "      <td>-3.358206</td>\n",
       "      <td>-2.340410</td>\n",
       "      <td>-11.775756</td>\n",
       "      <td>-12.190871</td>\n",
       "      <td>-16.413623</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>8.049091e-04</td>\n",
       "      <td>2.652176e-01</td>\n",
       "      <td>7.338802e-01</td>\n",
       "      <td>5.860118e-05</td>\n",
       "      <td>3.869228e-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.049091e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5</td>\n",
       "      <td>-15.624018</td>\n",
       "      <td>-1.738781</td>\n",
       "      <td>-6.715147</td>\n",
       "      <td>-14.303901</td>\n",
       "      <td>-3.494508</td>\n",
       "      <td>-1.787307</td>\n",
       "      <td>-1.934072</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>4.689734e-01</td>\n",
       "      <td>3.235490e-03</td>\n",
       "      <td>1.637518e-06</td>\n",
       "      <td>8.102993e-02</td>\n",
       "      <td>4.467595e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.689734e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5</td>\n",
       "      <td>-4.641403</td>\n",
       "      <td>-6.940540</td>\n",
       "      <td>-7.273940</td>\n",
       "      <td>-6.871971</td>\n",
       "      <td>-19.276900</td>\n",
       "      <td>-10.173308</td>\n",
       "      <td>-13.958478</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>3.537431e-01</td>\n",
       "      <td>2.534509e-01</td>\n",
       "      <td>3.788499e-01</td>\n",
       "      <td>1.552654e-06</td>\n",
       "      <td>1.395451e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.537431e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5</td>\n",
       "      <td>-8.563669</td>\n",
       "      <td>-13.411017</td>\n",
       "      <td>-1.967638</td>\n",
       "      <td>-13.381397</td>\n",
       "      <td>-6.472977</td>\n",
       "      <td>-19.753717</td>\n",
       "      <td>-4.376798</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>1.060283e-05</td>\n",
       "      <td>9.890496e-01</td>\n",
       "      <td>1.092158e-05</td>\n",
       "      <td>1.092884e-02</td>\n",
       "      <td>1.865615e-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.060283e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5</td>\n",
       "      <td>-5.129755</td>\n",
       "      <td>-19.249983</td>\n",
       "      <td>-11.138416</td>\n",
       "      <td>-5.530889</td>\n",
       "      <td>-14.702898</td>\n",
       "      <td>-4.334415</td>\n",
       "      <td>-12.358463</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>2.553722e-07</td>\n",
       "      <td>8.511037e-04</td>\n",
       "      <td>2.318998e-01</td>\n",
       "      <td>2.409615e-05</td>\n",
       "      <td>7.672248e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.553722e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    human_number          0          1          2          3          4  \\\n",
       "0              1  -4.853441 -12.771458  -8.134900  -4.965661 -17.027287   \n",
       "1              5 -17.446447  -9.905339 -17.918111 -15.600988 -11.887881   \n",
       "2              5 -11.609304  -4.760531  -4.507970 -11.475012 -16.475625   \n",
       "3              5  -4.413929 -12.572546 -15.973095 -16.890532  -7.668291   \n",
       "4              5  -7.646750 -16.282776  -8.659167  -4.129313 -11.105185   \n",
       "5              5 -17.652555  -2.944437 -11.275056  -5.055902 -13.937715   \n",
       "6              5  -6.244376  -9.335480  -5.704062 -14.069850  -9.942442   \n",
       "7              5 -11.514423 -18.936642 -14.655351 -15.391629  -9.498850   \n",
       "8              5  -1.748086  -8.594767 -12.453748 -18.989625  -2.690954   \n",
       "9              5 -12.120269  -2.446993  -9.991626 -15.929289 -15.656009   \n",
       "10             5  -3.164640 -19.828281  -8.741958 -18.855407  -3.537705   \n",
       "11             4  -1.535474 -13.745568 -11.169644 -12.058271 -18.053246   \n",
       "12             5 -15.939238 -19.897995 -11.346637 -15.220590  -4.047952   \n",
       "13             5 -14.869076  -7.491480  -6.063466 -13.508606 -11.153680   \n",
       "14             5  -6.013635  -6.891976 -17.720779  -4.483148  -7.861017   \n",
       "15             5  -3.953839  -6.837452  -6.523226 -10.148383  -9.586574   \n",
       "16             5  -9.966206 -11.212210 -17.889021 -19.972193 -19.692258   \n",
       "17             5  -6.553882  -2.064859 -18.543132  -8.348278  -6.482805   \n",
       "18             5 -11.599497 -14.736189  -4.059242  -1.042094 -19.359211   \n",
       "19             5 -17.737183  -3.587985  -3.738148  -6.236663  -8.785897   \n",
       "20             0  -9.046478 -14.296781  -6.231234 -10.928749 -15.950292   \n",
       "21             0  -9.470537  -5.080055  -4.344243 -19.620429 -18.658758   \n",
       "22             0 -14.463921  -8.372520 -18.285833  -5.083320 -15.086711   \n",
       "23             1  -9.740493 -17.498923 -14.538855  -2.422009  -7.921274   \n",
       "24             1 -10.168671 -17.330136 -16.542606  -9.499634 -18.988839   \n",
       "25             2  -9.645811  -1.380192 -14.828769 -10.337118  -1.115997   \n",
       "26             0 -18.963584 -19.982803  -5.846994  -6.221244 -19.421245   \n",
       "27             0  -6.382387  -9.341503  -8.296966 -11.121670 -15.709461   \n",
       "28             0 -11.277008 -16.251278 -16.861466 -10.117559 -12.487587   \n",
       "29             0  -6.684896  -1.080679 -12.729331  -4.052948 -17.695944   \n",
       "30             0 -18.986575 -15.754553 -14.111929 -12.192560 -10.722381   \n",
       "31             1  -5.616224  -2.594684 -19.332469 -13.088525  -3.304962   \n",
       "32             2 -17.568244 -15.769119  -5.120985  -9.115037 -11.549666   \n",
       "33             2 -15.708751  -7.706529  -1.471847  -5.006043 -11.812866   \n",
       "34             2  -4.068078  -9.284718  -9.525142 -13.089569 -14.910239   \n",
       "35             1  -5.143941  -6.356836 -19.443614  -2.666219  -2.198695   \n",
       "36             5 -14.608436 -12.561386 -19.628997 -10.920126  -9.109434   \n",
       "37             5 -14.509232  -1.931259  -5.943549  -8.274400 -11.809697   \n",
       "38             5  -5.233611 -13.594575 -16.486376  -4.732742 -10.454857   \n",
       "39             5  -6.327198  -2.639945 -10.391993 -11.799750  -3.561112   \n",
       "40             2  -2.748886 -15.150781 -17.077592  -6.651805  -6.292852   \n",
       "41             5  -3.896191  -4.110298  -1.231510  -7.906744 -15.754623   \n",
       "42             5 -15.332476 -12.137419 -19.344030 -19.728639 -14.967679   \n",
       "43             5 -18.690948  -6.532952  -7.393585  -7.924506  -9.628544   \n",
       "44             5  -9.180610 -15.075201 -17.739412 -13.387644 -12.876974   \n",
       "45             5 -15.383850  -9.155782  -3.358206  -2.340410 -11.775756   \n",
       "46             5 -15.624018  -1.738781  -6.715147 -14.303901  -3.494508   \n",
       "47             5  -4.641403  -6.940540  -7.273940  -6.871971 -19.276900   \n",
       "48             5  -8.563669 -13.411017  -1.967638 -13.381397  -6.472977   \n",
       "49             5  -5.129755 -19.249983 -11.138416  -5.530889 -14.702898   \n",
       "\n",
       "            5          6       model  item  ...  flipped  experiment  \\\n",
       "0   -5.681488  -8.975953  bloomz-7b1     1  ...     True    PG scale   \n",
       "1  -11.460297 -15.054214  bloomz-7b1     2  ...     True    PG scale   \n",
       "2   -6.549677  -6.463889  bloomz-7b1     3  ...     True    PG scale   \n",
       "3  -18.878776 -15.435804  bloomz-7b1     4  ...     True    PG scale   \n",
       "4  -15.930389  -6.091965  bloomz-7b1     5  ...     True    PG scale   \n",
       "5  -18.723430  -5.785244  bloomz-7b1     6  ...     True    PG scale   \n",
       "6   -9.320021 -15.271280  bloomz-7b1     7  ...     True    PG scale   \n",
       "7  -12.824579  -6.779997  bloomz-7b1     8  ...     True    PG scale   \n",
       "8   -4.541506 -10.639783  bloomz-7b1     9  ...     True    PG scale   \n",
       "9   -8.411653 -10.441589  bloomz-7b1    10  ...     True    PG scale   \n",
       "10  -3.411805 -12.656328  bloomz-7b1    11  ...     True    PG scale   \n",
       "11  -9.299375 -18.159373  bloomz-7b1    12  ...     True    PG scale   \n",
       "12 -11.073953 -16.335162  bloomz-7b1    13  ...     True    PG scale   \n",
       "13  -6.261993  -7.525839  bloomz-7b1    14  ...     True    PG scale   \n",
       "14 -12.272180  -6.399232  bloomz-7b1    15  ...     True    PG scale   \n",
       "15  -3.974807  -8.945127  bloomz-7b1    16  ...     True    PG scale   \n",
       "16  -4.270222 -19.197993  bloomz-7b1    17  ...     True    PG scale   \n",
       "17 -12.151406  -8.101217  bloomz-7b1    18  ...     True    PG scale   \n",
       "18 -10.050354  -2.487254  bloomz-7b1    19  ...     True    PG scale   \n",
       "19 -18.534610  -8.590058  bloomz-7b1    20  ...     True    PG scale   \n",
       "20 -17.530324  -5.551539  bloomz-7b1    21  ...     True    PG scale   \n",
       "21 -12.447744  -4.390555  bloomz-7b1    22  ...     True    PG scale   \n",
       "22 -12.632132  -1.082217  bloomz-7b1    23  ...     True    PG scale   \n",
       "23 -14.927116 -10.058953  bloomz-7b1    24  ...     True    PG scale   \n",
       "24  -2.451496 -17.512103  bloomz-7b1    25  ...     True    PG scale   \n",
       "25  -5.102322  -9.988841  bloomz-7b1    26  ...     True    PG scale   \n",
       "26 -18.680090 -16.929105  bloomz-7b1    27  ...     True    PG scale   \n",
       "27  -7.504852 -18.494748  bloomz-7b1    28  ...     True    PG scale   \n",
       "28 -17.472704 -15.625318  bloomz-7b1    29  ...     True    PG scale   \n",
       "29  -1.251427 -19.551453  bloomz-7b1    30  ...     True    PG scale   \n",
       "30  -2.067437  -6.119924  bloomz-7b1    31  ...     True    PG scale   \n",
       "31 -13.196802  -9.165189  bloomz-7b1    32  ...     True    PG scale   \n",
       "32  -2.912518  -9.627494  bloomz-7b1     1  ...     True    PG scale   \n",
       "33  -1.085461  -7.020561  bloomz-7b1     1  ...    False    PG scale   \n",
       "34  -3.269237  -5.693149  bloomz-7b1     1  ...     True    PG scale   \n",
       "35  -3.783315 -16.693123  bloomz-7b1     1  ...     True    PG scale   \n",
       "36 -19.371646 -11.893658  bloomz-7b1     2  ...     True    PG scale   \n",
       "37  -3.256570  -7.673552  bloomz-7b1     3  ...     True    PG scale   \n",
       "38 -12.741831 -14.267912  bloomz-7b1     4  ...     True    PG scale   \n",
       "39 -12.108141 -19.488369  bloomz-7b1     5  ...     True    PG scale   \n",
       "40 -19.478307  -5.109796  bloomz-7b1     6  ...     True    PG scale   \n",
       "41 -13.890994  -6.510427  bloomz-7b1     7  ...     True    PG scale   \n",
       "42  -3.397757 -12.252119  bloomz-7b1     8  ...     True    PG scale   \n",
       "43 -13.402602  -2.685460  bloomz-7b1     9  ...     True    PG scale   \n",
       "44  -1.220062 -11.412389  bloomz-7b1    10  ...     True    PG scale   \n",
       "45 -12.190871 -16.413623  bloomz-7b1    11  ...     True    PG scale   \n",
       "46  -1.787307  -1.934072  bloomz-7b1    12  ...     True    PG scale   \n",
       "47 -10.173308 -13.958478  bloomz-7b1    13  ...     True    PG scale   \n",
       "48 -19.753717  -4.376798  bloomz-7b1    14  ...     True    PG scale   \n",
       "49  -4.334415 -12.358463  bloomz-7b1    15  ...     True    PG scale   \n",
       "\n",
       "          prob_1        prob_2        prob_3        prob_4        prob_5  \\\n",
       "0   9.597985e-03  9.904020e-01           NaN           NaN           NaN   \n",
       "1   7.393122e-01  2.448641e-04  2.484500e-03  1.018171e-01  1.561414e-01   \n",
       "2   4.072254e-01  5.242287e-01  4.940521e-04  3.326860e-06  6.804850e-02   \n",
       "3   7.357761e-03  2.454178e-04  9.805464e-05  9.922853e-01  1.342718e-05   \n",
       "4   5.208995e-06  1.065725e-02  9.884068e-01  9.233223e-04  7.409586e-06   \n",
       "5   8.918073e-01  2.149458e-04  1.079626e-01  1.499516e-05  1.251818e-07   \n",
       "6   2.479194e-02  9.363003e-01  2.178712e-04  1.351170e-02  2.517817e-02   \n",
       "7   7.625900e-05  5.516102e-03  2.641621e-03  9.573527e-01  3.441330e-02   \n",
       "8   2.352730e-03  4.961785e-05  7.196854e-08  8.621157e-01  1.354818e-01   \n",
       "9   9.969095e-01  5.273069e-04  1.391134e-06  1.828324e-06  2.559981e-03   \n",
       "10  3.933213e-08  2.567298e-03  1.040546e-07  4.673635e-01  5.300690e-01   \n",
       "11  9.536218e-03  1.253389e-01  5.154185e-02  1.284031e-04  8.134546e-01   \n",
       "12  1.305355e-07  6.753616e-04  1.403136e-05  9.984234e-01  8.870770e-04   \n",
       "13  1.160363e-01  4.839185e-01  2.827413e-04  2.979344e-03  3.967831e-01   \n",
       "14  7.996805e-02  1.584992e-06  8.893183e-01  3.034362e-02  3.684033e-04   \n",
       "15  5.005643e-02  6.853726e-02  1.826168e-03  3.202813e-03  8.763773e-01   \n",
       "16  9.654124e-04  1.216216e-06  1.514609e-07  2.003893e-07  9.990330e-01   \n",
       "17  9.862247e-01  6.879436e-08  1.841288e-03  1.189286e-02  4.106238e-05   \n",
       "18  1.076287e-06  4.665167e-02  9.532306e-01  1.057244e-08  1.166703e-04   \n",
       "19  5.163047e-01  4.443151e-01  3.652579e-02  2.854182e-03  1.665978e-07   \n",
       "20  5.218549e-03           NaN           NaN           NaN           NaN   \n",
       "21  9.877570e-01           NaN           NaN           NaN           NaN   \n",
       "22  9.977429e-01           NaN           NaN           NaN           NaN   \n",
       "23  4.269443e-04           NaN           NaN           NaN           NaN   \n",
       "24  3.450731e-07  7.584572e-07  8.682696e-04  6.569701e-08  9.991303e-01   \n",
       "25  9.999986e-01  1.443301e-06           NaN           NaN           NaN   \n",
       "26  2.651794e-01           NaN           NaN           NaN           NaN   \n",
       "27  4.930742e-02           NaN           NaN           NaN           NaN   \n",
       "28  6.866099e-03           NaN           NaN           NaN           NaN   \n",
       "29  9.963312e-01           NaN           NaN           NaN           NaN   \n",
       "30  9.620217e-01           NaN           NaN           NaN           NaN   \n",
       "31  9.535378e-01           NaN           NaN           NaN           NaN   \n",
       "32  2.374455e-05  9.999763e-01           NaN           NaN           NaN   \n",
       "33  1.956417e-03  9.980436e-01           NaN           NaN           NaN   \n",
       "34  5.598181e-01  4.401819e-01           NaN           NaN           NaN   \n",
       "35  9.999979e-01  2.072449e-06           NaN           NaN           NaN   \n",
       "36  2.650722e-02  2.259123e-05  1.368216e-01  8.366194e-01  2.922173e-05   \n",
       "37  7.778334e-01  1.407250e-02  1.368029e-03  3.987819e-05  2.066862e-01   \n",
       "38  1.411650e-04  7.831296e-06  9.962593e-01  3.260539e-03  3.311839e-04   \n",
       "39  7.149666e-01  3.073366e-04  7.520267e-05  2.845956e-01  5.524594e-05   \n",
       "40  8.374647e-05  1.219448e-05  4.111731e-01  5.887298e-01  1.105467e-06   \n",
       "41  5.314852e-02  9.456548e-01  1.193206e-03  4.660421e-07  3.004614e-06   \n",
       "42  1.600809e-04  1.187266e-07  8.081922e-08  9.444371e-06  9.998303e-01   \n",
       "43  5.821162e-01  2.461737e-01  1.447656e-01  2.633973e-02  6.047261e-04   \n",
       "44  9.611318e-07  6.694697e-08  5.196128e-06  8.658862e-06  9.999851e-01   \n",
       "45  8.049091e-04  2.652176e-01  7.338802e-01  5.860118e-05  3.869228e-05   \n",
       "46  4.689734e-01  3.235490e-03  1.637518e-06  8.102993e-02  4.467595e-01   \n",
       "47  3.537431e-01  2.534509e-01  3.788499e-01  1.552654e-06  1.395451e-02   \n",
       "48  1.060283e-05  9.890496e-01  1.092158e-05  1.092884e-02  1.865615e-08   \n",
       "49  2.553722e-07  8.511037e-04  2.318998e-01  2.409615e-05  7.672248e-01   \n",
       "\n",
       "          prob_6    prob_0     prob_pred  \n",
       "0            NaN       NaN  9.904020e-01  \n",
       "1            NaN       NaN  7.393122e-01  \n",
       "2            NaN       NaN  4.072254e-01  \n",
       "3            NaN       NaN  7.357761e-03  \n",
       "4            NaN       NaN  5.208995e-06  \n",
       "5            NaN       NaN  8.918073e-01  \n",
       "6            NaN       NaN  2.479194e-02  \n",
       "7            NaN       NaN  7.625900e-05  \n",
       "8            NaN       NaN  2.352730e-03  \n",
       "9            NaN       NaN  9.969095e-01  \n",
       "10           NaN       NaN  3.933213e-08  \n",
       "11           NaN       NaN  1.253389e-01  \n",
       "12           NaN       NaN  1.305355e-07  \n",
       "13           NaN       NaN  1.160363e-01  \n",
       "14           NaN       NaN  7.996805e-02  \n",
       "15           NaN       NaN  5.005643e-02  \n",
       "16           NaN       NaN  9.654124e-04  \n",
       "17           NaN       NaN  9.862247e-01  \n",
       "18           NaN       NaN  1.076287e-06  \n",
       "19           NaN       NaN  5.163047e-01  \n",
       "20           NaN  0.994781  5.218549e-03  \n",
       "21           NaN  0.012243  9.877570e-01  \n",
       "22           NaN  0.002257  9.977429e-01  \n",
       "23           NaN  0.999573  9.995731e-01  \n",
       "24  2.876629e-07       NaN  2.876629e-07  \n",
       "25           NaN       NaN  9.999986e-01  \n",
       "26           NaN  0.734821  2.651794e-01  \n",
       "27           NaN  0.950693  4.930742e-02  \n",
       "28           NaN  0.993134  6.866099e-03  \n",
       "29           NaN  0.003669  9.963312e-01  \n",
       "30           NaN  0.037978  9.620217e-01  \n",
       "31           NaN  0.046462  4.646217e-02  \n",
       "32           NaN       NaN  2.374455e-05  \n",
       "33           NaN       NaN  9.980436e-01  \n",
       "34           NaN       NaN  5.598181e-01  \n",
       "35           NaN       NaN  2.072449e-06  \n",
       "36           NaN       NaN  2.650722e-02  \n",
       "37           NaN       NaN  7.778334e-01  \n",
       "38           NaN       NaN  1.411650e-04  \n",
       "39           NaN       NaN  7.149666e-01  \n",
       "40           NaN       NaN  5.887298e-01  \n",
       "41           NaN       NaN  5.314852e-02  \n",
       "42           NaN       NaN  1.600809e-04  \n",
       "43           NaN       NaN  5.821162e-01  \n",
       "44           NaN       NaN  9.611318e-07  \n",
       "45           NaN       NaN  8.049091e-04  \n",
       "46           NaN       NaN  4.689734e-01  \n",
       "47           NaN       NaN  3.537431e-01  \n",
       "48           NaN       NaN  1.060283e-05  \n",
       "49           NaN       NaN  2.553722e-07  \n",
       "\n",
       "[50 rows x 21 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PG_data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9508ec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mappings for each GABS question:\n",
    "pg_maps = {     \n",
    "    1: {1: 1, 2: 0},                      \n",
    "    2: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    3: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    4: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    5: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    6: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    7: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    8: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    9: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    10: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    11: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    12: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    13: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    14: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    15: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    16: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    17: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    18: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    19: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    20: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    26: {1: 1, 2: 0}\n",
    "}\n",
    "\n",
    "# Apply mapping row-wise based on item number\n",
    "def recode_pg(row):\n",
    "    mapping = pg_maps.get(row[\"item\"])\n",
    "    if mapping is not None:\n",
    "        return mapping.get(row[\"human_number\"], None)  # None if invalid code\n",
    "    return row[\"human_number\"]  \n",
    "\n",
    "PG_data[\"human_number\"] = PG_data.apply(recode_pg, axis=1)\n",
    "\n",
    "# jetzt ist es konsistent mit Freys df quest_proc (außer an den Items, wo es in der gleichen Skale bei ESS_GABS_ausserh_01-10 plötzlich ?vergessen? wurde bei Frey)\n",
    "# aber meiner Meinung nach müsste man, damit man die Skala in binned factors umwandeln kann, noch alles in die gleiche Richtung bringen,\n",
    "# 1 und 26 sind in falscher Richtung! -> habe ich jetzt gefixt obwohl Abweichung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c5f8e0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_PG = get_LLM_value_per_item(PG_data)\n",
    "model_item_scores_PG_top_n = get_LLM_value_per_item_top_n(PG_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_PG = model_item_scores_PG.merge(\n",
    "    model_item_scores_PG_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5e0c6aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_PG], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b01fef",
   "metadata": {},
   "source": [
    "## PRI SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "80602ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (1110624, 13)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "PRI_data = load_dataframes(task_name=\"PRI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "39ee7b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one \n",
    "\n",
    "mask = (PRI_data[\"item\"].isin([1, 3, 5, 7, 9, 11, 13, 15]))\n",
    "PRI_data.loc[mask, \"prob_1\"] = np.exp(PRI_data.loc[mask, \"1\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]))\n",
    "PRI_data.loc[mask, \"prob_2\"] = np.exp(PRI_data.loc[mask, \"2\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]))\n",
    "\n",
    "\n",
    "\n",
    "mask = (PRI_data[\"item\"].isin([2, 4, 6, 8, 10, 12, 14, 16]))\n",
    "PRI_data.loc[mask, \"prob_1\"] = np.exp(PRI_data.loc[mask, \"1\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]) + np.exp(PRI_data.loc[mask, \"3\"]) + np.exp(PRI_data.loc[mask, \"4\"]) + np.exp(PRI_data.loc[mask, \"5\"]) + np.exp(PRI_data.loc[mask, \"6\"]) + np.exp(PRI_data.loc[mask, \"7\"]))\n",
    "PRI_data.loc[mask, \"prob_2\"] = np.exp(PRI_data.loc[mask, \"2\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]) + np.exp(PRI_data.loc[mask, \"3\"]) + np.exp(PRI_data.loc[mask, \"4\"]) + np.exp(PRI_data.loc[mask, \"5\"]) + np.exp(PRI_data.loc[mask, \"6\"]) + np.exp(PRI_data.loc[mask, \"7\"]))\n",
    "PRI_data.loc[mask, \"prob_3\"] = np.exp(PRI_data.loc[mask, \"3\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]) + np.exp(PRI_data.loc[mask, \"3\"]) + np.exp(PRI_data.loc[mask, \"4\"]) + np.exp(PRI_data.loc[mask, \"5\"]) + np.exp(PRI_data.loc[mask, \"6\"]) + np.exp(PRI_data.loc[mask, \"7\"]))\n",
    "PRI_data.loc[mask, \"prob_4\"] = np.exp(PRI_data.loc[mask, \"4\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]) + np.exp(PRI_data.loc[mask, \"3\"]) + np.exp(PRI_data.loc[mask, \"4\"]) + np.exp(PRI_data.loc[mask, \"5\"]) + np.exp(PRI_data.loc[mask, \"6\"]) + np.exp(PRI_data.loc[mask, \"7\"]))\n",
    "PRI_data.loc[mask, \"prob_5\"] = np.exp(PRI_data.loc[mask, \"5\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]) + np.exp(PRI_data.loc[mask, \"3\"]) + np.exp(PRI_data.loc[mask, \"4\"]) + np.exp(PRI_data.loc[mask, \"5\"]) + np.exp(PRI_data.loc[mask, \"6\"]) + np.exp(PRI_data.loc[mask, \"7\"]))\n",
    "PRI_data.loc[mask, \"prob_6\"] = np.exp(PRI_data.loc[mask, \"6\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]) + np.exp(PRI_data.loc[mask, \"3\"]) + np.exp(PRI_data.loc[mask, \"4\"]) + np.exp(PRI_data.loc[mask, \"5\"]) + np.exp(PRI_data.loc[mask, \"6\"]) + np.exp(PRI_data.loc[mask, \"7\"]))\n",
    "PRI_data.loc[mask, \"prob_7\"] = np.exp(PRI_data.loc[mask, \"7\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]) + np.exp(PRI_data.loc[mask, \"3\"]) + np.exp(PRI_data.loc[mask, \"4\"]) + np.exp(PRI_data.loc[mask, \"5\"]) + np.exp(PRI_data.loc[mask, \"6\"]) + np.exp(PRI_data.loc[mask, \"7\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "fe6591f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "PRI_data=filter_pred_prob(PRI_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0ff04f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (PRI_data[\"flipped\"] == True) & (PRI_data[\"item\"].isin([1, 3, 5, 7, 9, 11, 13, 15]))\n",
    "PRI_data.loc[mask, \"human_number\"] = 3 - PRI_data.loc[mask, \"human_number\"]\n",
    "\n",
    "mask = (PRI_data[\"flipped\"] == True) & (PRI_data[\"item\"].isin([2, 4, 6, 8, 10, 12, 14, 16]))\n",
    "PRI_data.loc[mask, \"human_number\"] = 8 - PRI_data.loc[mask, \"human_number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d354e93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human_number</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>model</th>\n",
       "      <th>item</th>\n",
       "      <th>...</th>\n",
       "      <th>flipped</th>\n",
       "      <th>experiment</th>\n",
       "      <th>prob_1</th>\n",
       "      <th>prob_2</th>\n",
       "      <th>prob_3</th>\n",
       "      <th>prob_4</th>\n",
       "      <th>prob_5</th>\n",
       "      <th>prob_6</th>\n",
       "      <th>prob_7</th>\n",
       "      <th>prob_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.673159</td>\n",
       "      <td>-8.927156</td>\n",
       "      <td>-6.351227</td>\n",
       "      <td>-13.426509</td>\n",
       "      <td>-6.463020</td>\n",
       "      <td>-2.028295</td>\n",
       "      <td>-10.300617</td>\n",
       "      <td>gemma-3-27b-it</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PRI scale</td>\n",
       "      <td>0.999293</td>\n",
       "      <td>7.068416e-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.992932e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>-11.778463</td>\n",
       "      <td>-7.172970</td>\n",
       "      <td>-14.481384</td>\n",
       "      <td>-14.637796</td>\n",
       "      <td>-16.262840</td>\n",
       "      <td>-11.101444</td>\n",
       "      <td>-18.689278</td>\n",
       "      <td>gemma-3-27b-it</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PRI scale</td>\n",
       "      <td>0.009696</td>\n",
       "      <td>9.698982e-01</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>5.556400e-04</td>\n",
       "      <td>1.094072e-04</td>\n",
       "      <td>0.019081</td>\n",
       "      <td>9.666234e-06</td>\n",
       "      <td>9.695859e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-12.116095</td>\n",
       "      <td>-17.705244</td>\n",
       "      <td>-12.270945</td>\n",
       "      <td>-5.040867</td>\n",
       "      <td>-17.331262</td>\n",
       "      <td>-11.550570</td>\n",
       "      <td>-2.495935</td>\n",
       "      <td>gemma-3-27b-it</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PRI scale</td>\n",
       "      <td>0.996276</td>\n",
       "      <td>3.724283e-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.962757e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-2.549023</td>\n",
       "      <td>-9.531290</td>\n",
       "      <td>-2.248499</td>\n",
       "      <td>-15.409730</td>\n",
       "      <td>-3.927116</td>\n",
       "      <td>-10.289861</td>\n",
       "      <td>-12.538290</td>\n",
       "      <td>gemma-3-27b-it</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PRI scale</td>\n",
       "      <td>0.384019</td>\n",
       "      <td>3.564452e-04</td>\n",
       "      <td>0.518643</td>\n",
       "      <td>9.977432e-07</td>\n",
       "      <td>9.679542e-02</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>1.762258e-05</td>\n",
       "      <td>9.679542e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-6.773948</td>\n",
       "      <td>-13.436984</td>\n",
       "      <td>-9.910970</td>\n",
       "      <td>-12.314688</td>\n",
       "      <td>-19.389068</td>\n",
       "      <td>-7.484261</td>\n",
       "      <td>-8.330785</td>\n",
       "      <td>gemma-3-27b-it</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PRI scale</td>\n",
       "      <td>0.998724</td>\n",
       "      <td>1.275633e-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.987244e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110619</th>\n",
       "      <td>7</td>\n",
       "      <td>-8.845709</td>\n",
       "      <td>-4.001274</td>\n",
       "      <td>-9.392918</td>\n",
       "      <td>-3.977211</td>\n",
       "      <td>-17.629686</td>\n",
       "      <td>-10.536378</td>\n",
       "      <td>-19.714973</td>\n",
       "      <td>Qwen2.5-32B-Instruct</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PRI scale</td>\n",
       "      <td>0.003862</td>\n",
       "      <td>4.906208e-01</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>5.025696e-01</td>\n",
       "      <td>5.915643e-07</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>7.351451e-08</td>\n",
       "      <td>3.862200e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110620</th>\n",
       "      <td>2</td>\n",
       "      <td>-17.420201</td>\n",
       "      <td>-19.657488</td>\n",
       "      <td>-4.351640</td>\n",
       "      <td>-4.030129</td>\n",
       "      <td>-12.673425</td>\n",
       "      <td>-1.886397</td>\n",
       "      <td>-10.425184</td>\n",
       "      <td>Qwen2.5-32B-Instruct</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PRI scale</td>\n",
       "      <td>0.903548</td>\n",
       "      <td>9.645174e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.035483e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110621</th>\n",
       "      <td>5</td>\n",
       "      <td>-3.879368</td>\n",
       "      <td>-15.631071</td>\n",
       "      <td>-13.646896</td>\n",
       "      <td>-5.340074</td>\n",
       "      <td>-17.478235</td>\n",
       "      <td>-5.063257</td>\n",
       "      <td>-4.972999</td>\n",
       "      <td>Qwen2.5-32B-Instruct</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PRI scale</td>\n",
       "      <td>0.533839</td>\n",
       "      <td>4.204465e-06</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>1.238894e-01</td>\n",
       "      <td>6.629759e-07</td>\n",
       "      <td>0.163401</td>\n",
       "      <td>1.788350e-01</td>\n",
       "      <td>3.057928e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110622</th>\n",
       "      <td>1</td>\n",
       "      <td>-13.745078</td>\n",
       "      <td>-13.557388</td>\n",
       "      <td>-13.096325</td>\n",
       "      <td>-15.379370</td>\n",
       "      <td>-18.317863</td>\n",
       "      <td>-2.868425</td>\n",
       "      <td>-5.771282</td>\n",
       "      <td>Qwen2.5-32B-Instruct</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PRI scale</td>\n",
       "      <td>0.453215</td>\n",
       "      <td>5.467854e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.467854e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110623</th>\n",
       "      <td>6</td>\n",
       "      <td>-6.596496</td>\n",
       "      <td>-16.845604</td>\n",
       "      <td>-1.290349</td>\n",
       "      <td>-13.324259</td>\n",
       "      <td>-19.568536</td>\n",
       "      <td>-2.967439</td>\n",
       "      <td>-3.438716</td>\n",
       "      <td>Qwen2.5-32B-Instruct</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PRI scale</td>\n",
       "      <td>0.003791</td>\n",
       "      <td>1.341669e-07</td>\n",
       "      <td>0.764200</td>\n",
       "      <td>4.538854e-06</td>\n",
       "      <td>8.812331e-09</td>\n",
       "      <td>0.142842</td>\n",
       "      <td>8.916262e-02</td>\n",
       "      <td>1.341669e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1110624 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         human_number          1          2          3          4          5  \\\n",
       "0                   2  -1.673159  -8.927156  -6.351227 -13.426509  -6.463020   \n",
       "1                   7 -11.778463  -7.172970 -14.481384 -14.637796 -16.262840   \n",
       "2                   2 -12.116095 -17.705244 -12.270945  -5.040867 -17.331262   \n",
       "3                   3  -2.549023  -9.531290  -2.248499 -15.409730  -3.927116   \n",
       "4                   2  -6.773948 -13.436984  -9.910970 -12.314688 -19.389068   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "1110619             7  -8.845709  -4.001274  -9.392918  -3.977211 -17.629686   \n",
       "1110620             2 -17.420201 -19.657488  -4.351640  -4.030129 -12.673425   \n",
       "1110621             5  -3.879368 -15.631071 -13.646896  -5.340074 -17.478235   \n",
       "1110622             1 -13.745078 -13.557388 -13.096325 -15.379370 -18.317863   \n",
       "1110623             6  -6.596496 -16.845604  -1.290349 -13.324259 -19.568536   \n",
       "\n",
       "                 6          7                 model  item  ...  flipped  \\\n",
       "0        -2.028295 -10.300617        gemma-3-27b-it     1  ...     True   \n",
       "1       -11.101444 -18.689278        gemma-3-27b-it     2  ...     True   \n",
       "2       -11.550570  -2.495935        gemma-3-27b-it     3  ...     True   \n",
       "3       -10.289861 -12.538290        gemma-3-27b-it     4  ...     True   \n",
       "4        -7.484261  -8.330785        gemma-3-27b-it     5  ...     True   \n",
       "...            ...        ...                   ...   ...  ...      ...   \n",
       "1110619 -10.536378 -19.714973  Qwen2.5-32B-Instruct    12  ...     True   \n",
       "1110620  -1.886397 -10.425184  Qwen2.5-32B-Instruct    13  ...     True   \n",
       "1110621  -5.063257  -4.972999  Qwen2.5-32B-Instruct    14  ...     True   \n",
       "1110622  -2.868425  -5.771282  Qwen2.5-32B-Instruct    15  ...     True   \n",
       "1110623  -2.967439  -3.438716  Qwen2.5-32B-Instruct    16  ...     True   \n",
       "\n",
       "         experiment    prob_1        prob_2    prob_3        prob_4  \\\n",
       "0         PRI scale  0.999293  7.068416e-04       NaN           NaN   \n",
       "1         PRI scale  0.009696  9.698982e-01  0.000650  5.556400e-04   \n",
       "2         PRI scale  0.996276  3.724283e-03       NaN           NaN   \n",
       "3         PRI scale  0.384019  3.564452e-04  0.518643  9.977432e-07   \n",
       "4         PRI scale  0.998724  1.275633e-03       NaN           NaN   \n",
       "...             ...       ...           ...       ...           ...   \n",
       "1110619   PRI scale  0.003862  4.906208e-01  0.002235  5.025696e-01   \n",
       "1110620   PRI scale  0.903548  9.645174e-02       NaN           NaN   \n",
       "1110621   PRI scale  0.533839  4.204465e-06  0.000031  1.238894e-01   \n",
       "1110622   PRI scale  0.453215  5.467854e-01       NaN           NaN   \n",
       "1110623   PRI scale  0.003791  1.341669e-07  0.764200  4.538854e-06   \n",
       "\n",
       "               prob_5    prob_6        prob_7     prob_pred  \n",
       "0                 NaN       NaN           NaN  9.992932e-01  \n",
       "1        1.094072e-04  0.019081  9.666234e-06  9.695859e-03  \n",
       "2                 NaN       NaN           NaN  9.962757e-01  \n",
       "3        9.679542e-02  0.000167  1.762258e-05  9.679542e-02  \n",
       "4                 NaN       NaN           NaN  9.987244e-01  \n",
       "...               ...       ...           ...           ...  \n",
       "1110619  5.915643e-07  0.000712  7.351451e-08  3.862200e-03  \n",
       "1110620           NaN       NaN           NaN  9.035483e-01  \n",
       "1110621  6.629759e-07  0.163401  1.788350e-01  3.057928e-05  \n",
       "1110622           NaN       NaN           NaN  5.467854e-01  \n",
       "1110623  8.812331e-09  0.142842  8.916262e-02  1.341669e-07  \n",
       "\n",
       "[1110624 rows x 21 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRI_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7ae95ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_PRI = get_LLM_value_per_item(PRI_data)\n",
    "model_item_scores_PRI_top_n = get_LLM_value_per_item_top_n(PRI_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_PRI = model_item_scores_PRI.merge(\n",
    "    model_item_scores_PRI_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ffab96f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding task specific categories to save in all data\n",
    "\n",
    "# add item categories\n",
    "item_to_category = {\n",
    "     1: \"decision\", 3: \"decision\", 5: \"decision\", 7: \"decision\", 9: \"decision\", 11: \"decision\", 13: \"decision\", 15: \"decision\",\n",
    "     2: \"certainty\", 4: \"certainty\", 6: \"certainty\", 8: \"certainty\", 10: \"certainty\", 12: \"certainty\", 14: \"certainty\", 16: \"certainty\"\n",
    "}\n",
    "\n",
    "\n",
    "model_item_scores_PRI[\"category\"] = model_item_scores_PRI[\"item\"].map(item_to_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "68281602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_PRI], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d1f8ec",
   "metadata": {},
   "source": [
    "## SOEP SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2db32d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (486542, 17)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "SOEP_data = load_dataframes(task_name=\"SOEP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "59969196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probabilities out of log-probabilities\n",
    "\n",
    "cols = [str(i) for i in range(1, 12)]\n",
    "# Compute normalized probabilities\n",
    "exp_vals = np.exp(SOEP_data[cols])\n",
    "prob_vals = exp_vals.div(exp_vals.sum(axis=1), axis=0)\n",
    "\n",
    "# Rename columns all at once\n",
    "prob_vals.columns = [f\"prob_{i}\" for i in range(1, 12)]\n",
    "\n",
    "# Join to original dataframe in one step\n",
    "SOEP_data = pd.concat([SOEP_data, prob_vals], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "aaea5af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "SOEP_data=filter_pred_prob(SOEP_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "829772eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (SOEP_data[\"flipped\"] == \"yes\") \n",
    "SOEP_data.loc[mask, \"human_number\"] = 12 - SOEP_data.loc[mask, \"human_number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2810bbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_SOEP = get_LLM_value_per_item(SOEP_data)\n",
    "model_item_scores_SOEP_top_n = get_LLM_value_per_item_top_n(SOEP_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_SOEP = model_item_scores_SOEP.merge(\n",
    "    model_item_scores_SOEP_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2d70fee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding task specific categories to save in all data\n",
    "\n",
    "# add item categories\n",
    "item_to_category = {\n",
    "     1: \"SOEP\", 2: \"SOEPdri\", 3: \"SOEPfin\",  4: \"SOEPrec\", 5: \"SOEPocc\",  6: \"SOEPhea\",  7: \"SOEPsoc\"\n",
    "}\n",
    "\n",
    "model_item_scores_SOEP[\"category\"] = model_item_scores_SOEP[\"item\"].map(item_to_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "6ef74f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_SOEP], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919cb194",
   "metadata": {},
   "source": [
    "## SSSV SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4ee11e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (2776560, 8)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "SSSV_data = load_dataframes(task_name=\"SSSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "dfaf361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one\n",
    "SSSV_data[\"prob_1\"] = np.exp(SSSV_data[\"1\"])/(np.exp(SSSV_data[\"1\"]) + np.exp(SSSV_data[\"2\"]))\n",
    "SSSV_data[\"prob_2\"] = np.exp(SSSV_data[\"2\"])/(np.exp(SSSV_data[\"1\"]) + np.exp(SSSV_data[\"2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "3c2a7fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "SSSV_data=filter_pred_prob(SSSV_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "dd874639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (SSSV_data[\"flipped\"] == True) \n",
    "SSSV_data.loc[mask, \"human_number\"] = 3 - SSSV_data.loc[mask, \"human_number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7f9e0a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # since several items are reversed in whether they indicate low or high sensation seeking, flip some human answers\n",
    "\n",
    "# reverse_coded = {\n",
    "#      1: True, 2: False, 3: True, 4: False, 5: True, 6: True, 7: False, 8: True, 9: True, 10: False, \n",
    "#      11: False, 12: False, 13: False, 14: True, 15: False, 16: True, 17: True, 18: True, 19: False, 20: False,\n",
    "#      21: False, 22: True, 23: True, 24: True, 25: False, 26: False, 27: False, 28: True, 29: True, 30: False,\n",
    "#      31: False, 32: True, 33: False, 34: True, 35: False, 36: True, 37: False, 38: False, 39: True, 40: False\n",
    "\n",
    "# }\n",
    "\n",
    "\n",
    "# for row in SSSV_data.groupby([\"experiment\", \"model\"]):\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4a4ec1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_SSSV = get_LLM_value_per_item(SSSV_data)\n",
    "model_item_scores_SSSV_top_n = get_LLM_value_per_item_top_n(SSSV_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_SSSV = model_item_scores_SSSV.merge(\n",
    "    model_item_scores_SSSV_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "91ea4053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.776560e+06\n",
       "mean     1.491352e+00\n",
       "std      4.999253e-01\n",
       "min      1.000000e+00\n",
       "25%      1.000000e+00\n",
       "50%      1.000000e+00\n",
       "75%      2.000000e+00\n",
       "max      2.000000e+00\n",
       "Name: human_number, dtype: float64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSSV_data[\"human_number\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d56d1fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1840.000000\n",
       "mean        1.382914\n",
       "std         0.137175\n",
       "min         1.092261\n",
       "25%         1.285301\n",
       "50%         1.391667\n",
       "75%         1.461820\n",
       "max         1.934140\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_item_scores_SSSV[\"score\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "2f7bb971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding task specific categories to save in all data\n",
    "\n",
    "# add item categories\n",
    "item_to_category = {\n",
    "     3: \"SStas\", 11: \"SStas\", 16: \"SStas\", 17: \"SStas\", 20: \"SStas\", 21: \"SStas\", 23: \"SStas\", 28: \"SStas\", 38: \"SStas\", 40: \"SStas\",\n",
    "     4: \"SSexp\", 6: \"SSexp\", 9: \"SSexp\", 10: \"SSexp\", 14: \"SSexp\", 18: \"SSexp\", 19: \"SSexp\", 22: \"SSexp\", 26: \"SSexp\", 37: \"SSexp\",\n",
    "     1: \"SSdis\", 12: \"SSdis\", 13: \"SSdis\", 25: \"SSdis\", 29: \"SSdis\", 30: \"SSdis\", 32: \"SSdis\", 33: \"SSdis\", 35: \"SSdis\", 36: \"SSdis\",\n",
    "     2: \"SSbor\", 5: \"SSbor\", 7: \"SSbor\", 8: \"SSbor\", 15: \"SSbor\", 24: \"SSbor\", 27: \"SSbor\", 31: \"SSbor\", 34: \"SSbor\", 39: \"SSbor\"\n",
    "}\n",
    "\n",
    "reverse_coded = {\n",
    "     1: True, 2: False, 3: True, 4: False, 5: True, 6: True, 7: False, 8: True, 9: True, 10: False, \n",
    "     11: False, 12: False, 13: False, 14: True, 15: False, 16: True, 17: True, 18: True, 19: False, 20: False,\n",
    "     21: False, 22: True, 23: True, 24: True, 25: False, 26: False, 27: False, 28: True, 29: True, 30: False,\n",
    "     31: False, 32: True, 33: False, 34: True, 35: False, 36: True, 37: False, 38: False, 39: True, 40: False\n",
    "\n",
    "}\n",
    "\n",
    "model_item_scores_SSSV[\"category\"] = model_item_scores_SSSV[\"item\"].map(item_to_category)\n",
    "model_item_scores_SSSV[\"reverse_coded\"] = model_item_scores_SSSV[\"item\"].map(reverse_coded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "1540d214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back answers that where reverse coded\n",
    "mask = (model_item_scores_SSSV[\"reverse_coded\"] == True)\n",
    "model_item_scores_SSSV.loc[mask, \"score\"] = 3 - model_item_scores_SSSV.loc[mask, \"score\"]\n",
    "model_item_scores_SSSV.loc[mask, \"score_top_n\"] = 3 - model_item_scores_SSSV.loc[mask, \"score_top_n\"]\n",
    "# drop reverse-coded column (not needed in final data)\n",
    "model_item_scores_SSSV = model_item_scores_SSSV.drop(columns=[\"reverse_coded\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "55c256df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>model</th>\n",
       "      <th>item</th>\n",
       "      <th>score</th>\n",
       "      <th>score_top_n</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>2</td>\n",
       "      <td>2.271818</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>3</td>\n",
       "      <td>2.215974</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>4</td>\n",
       "      <td>2.378609</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>5</td>\n",
       "      <td>2.702775</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11817</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>36</td>\n",
       "      <td>1.654326</td>\n",
       "      <td>2</td>\n",
       "      <td>SSdis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>37</td>\n",
       "      <td>1.407635</td>\n",
       "      <td>1</td>\n",
       "      <td>SSexp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>38</td>\n",
       "      <td>1.402630</td>\n",
       "      <td>1</td>\n",
       "      <td>SStas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>39</td>\n",
       "      <td>1.634443</td>\n",
       "      <td>2</td>\n",
       "      <td>SSbor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>40</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>SStas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11822 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        experiment                      model  item     score  score_top_n  \\\n",
       "0      AUDIT scale  Apertus-70B-Instruct-2509     1       NaN            2   \n",
       "1      AUDIT scale  Apertus-70B-Instruct-2509     2  2.271818            2   \n",
       "2      AUDIT scale  Apertus-70B-Instruct-2509     3  2.215974            2   \n",
       "3      AUDIT scale  Apertus-70B-Instruct-2509     4  2.378609            2   \n",
       "4      AUDIT scale  Apertus-70B-Instruct-2509     5  2.702775            2   \n",
       "...            ...                        ...   ...       ...          ...   \n",
       "11817   SSSV scale             zephyr-7b-beta    36  1.654326            2   \n",
       "11818   SSSV scale             zephyr-7b-beta    37  1.407635            1   \n",
       "11819   SSSV scale             zephyr-7b-beta    38  1.402630            1   \n",
       "11820   SSSV scale             zephyr-7b-beta    39  1.634443            2   \n",
       "11821   SSSV scale             zephyr-7b-beta    40  1.500000            1   \n",
       "\n",
       "      category  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "...        ...  \n",
       "11817    SSdis  \n",
       "11818    SSexp  \n",
       "11819    SStas  \n",
       "11820    SSbor  \n",
       "11821    SStas  \n",
       "\n",
       "[11822 rows x 6 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_SSSV], ignore_index=True)\n",
    "all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b140480",
   "metadata": {},
   "source": [
    "# Saving new processed dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b3a81d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "all_data.to_csv('processed_data/items_per_LLM.csv', index=False)\n",
    "#all_data.to_csv(\"simulation_random/items_per_LLM_random_simulation.csv\", index=False)\n",
    "#all_data.to_csv(\"simulation_semi_random/items_per_LLM_semi_random_simulation.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "be7afd59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>model</th>\n",
       "      <th>item</th>\n",
       "      <th>score</th>\n",
       "      <th>score_top_n</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>2</td>\n",
       "      <td>2.271818</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>3</td>\n",
       "      <td>2.215974</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>4</td>\n",
       "      <td>2.378609</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>5</td>\n",
       "      <td>2.702775</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11817</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>36</td>\n",
       "      <td>1.654326</td>\n",
       "      <td>2</td>\n",
       "      <td>SSdis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>37</td>\n",
       "      <td>1.407635</td>\n",
       "      <td>1</td>\n",
       "      <td>SSexp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>38</td>\n",
       "      <td>1.402630</td>\n",
       "      <td>1</td>\n",
       "      <td>SStas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>39</td>\n",
       "      <td>1.634443</td>\n",
       "      <td>2</td>\n",
       "      <td>SSbor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>40</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>SStas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11822 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        experiment                      model  item     score  score_top_n  \\\n",
       "0      AUDIT scale  Apertus-70B-Instruct-2509     1       NaN            2   \n",
       "1      AUDIT scale  Apertus-70B-Instruct-2509     2  2.271818            2   \n",
       "2      AUDIT scale  Apertus-70B-Instruct-2509     3  2.215974            2   \n",
       "3      AUDIT scale  Apertus-70B-Instruct-2509     4  2.378609            2   \n",
       "4      AUDIT scale  Apertus-70B-Instruct-2509     5  2.702775            2   \n",
       "...            ...                        ...   ...       ...          ...   \n",
       "11817   SSSV scale             zephyr-7b-beta    36  1.654326            2   \n",
       "11818   SSSV scale             zephyr-7b-beta    37  1.407635            1   \n",
       "11819   SSSV scale             zephyr-7b-beta    38  1.402630            1   \n",
       "11820   SSSV scale             zephyr-7b-beta    39  1.634443            2   \n",
       "11821   SSSV scale             zephyr-7b-beta    40  1.500000            1   \n",
       "\n",
       "      category  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "...        ...  \n",
       "11817    SSdis  \n",
       "11818    SSexp  \n",
       "11819    SStas  \n",
       "11820    SSbor  \n",
       "11821    SStas  \n",
       "\n",
       "[11822 rows x 6 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
