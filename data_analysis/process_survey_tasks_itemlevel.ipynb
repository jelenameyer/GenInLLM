{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfc545a9",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "Starting point:\n",
    "- 848 datasets (18 tasks per model (minus the NON_IDEAL_OUTPUTS)) with all logprobs for all answer alternatives of each subtask for all ~1.500 participants. \n",
    "\n",
    "What does this script do\n",
    "- Read all survey data sets\n",
    "- normalise log-prob scores so that they are probabilities that sum up to 1 over all answer options\n",
    "- filter out the probability that the LLm assigned to the answer option which the participant actually chose (for each item)\n",
    "- flip back answers where scale was flipped to cope with prompt sensitivity issues\n",
    "- weigh probabiliies with human answers and divide by all probabilities for that item, to have one number (in the realm if not exact the number of the answer alternatives) per item per model\n",
    "- second weighing strategy, where score of model per item is only weighed with top n most likely probabilities that model assigned\n",
    "- for some scales: add subcategories (each item belongs to a subcategory)\n",
    "- for some tasks, but unsure, reverse back some scores that are asked on a reverse scale due to the nature of the task\n",
    "- concat the itemwise scores for each task per model all together in one `all_data` final data frame and save it.\n",
    "\n",
    "Specials:\n",
    "- for every scale I compared the frey materials quest_raw.csv and quest_proc.csv and tried to trace back how they got from one to the other. Then I did the same transformations\n",
    "- therefore, for AUDIT and FTND and some more the scores are mapped onto a different scale (point system depending on given answer) on the `human_number` level (before mapped to LLM assigned probabilities)\n",
    "- ! for other scales the scores might have to be transfered into another point system as well!\n",
    "- ! SSSV must be reversed in some items, I think, but resluts are awful when done!?!?!?!\n",
    "\n",
    "Goal:\n",
    "- first have one value per item per model\n",
    "- then transform those values in \"outcomes\" for each subscale (like Frey did)\n",
    "- Have 36 values per model! (one per (sub-) scale)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2ebc19",
   "metadata": {},
   "source": [
    "## Packages & Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "fef727d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import load_dataframes, filter_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "69d790d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------\n",
    "# Pro Modell × Item die Zähler und Nenner berechnen\n",
    "# ----------------------------------------------------------------------------------------------\n",
    "# - Zähler = Summe von (Antwort * Wahrscheinlichkeit)\n",
    "# - Nenner = Summe von (Wahrscheinlichkeiten)\n",
    "\n",
    "def compute_weighted_score(group):\n",
    "    numerator = (group[\"human_number\"] * group[\"prob_pred\"]).sum()\n",
    "    denominator = group[\"prob_pred\"].sum()\n",
    "    return numerator / denominator if denominator > 0 else None\n",
    "\n",
    "\n",
    "# Funktion für Top-n gewichteten Score\n",
    "def compute_top_n_weighted_score(group, n = 100):\n",
    "    # Sortiere die Zeilen nach Wahrscheinlichkeit absteigend\n",
    "    top_n = group.sort_values(\"prob_pred\", ascending=False).head(n)\n",
    "    # Numerator = Summe von (Antwort * Wahrscheinlichkeit)\n",
    "    numerator = (top_n[\"human_number\"] * top_n[\"prob_pred\"]).sum()\n",
    "    # Denominator = Summe von Wahrscheinlichkeiten der Top n\n",
    "    denominator = top_n[\"prob_pred\"].sum()\n",
    "    return numerator / denominator if denominator > 0 else None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# produce df with one value per model per item --------------------------------------------------\n",
    "# more compact version (that runs faster)\n",
    "def get_LLM_value_per_item(data):\n",
    "    grouped = data.groupby([\"experiment\", \"model\", \"item\"])\n",
    "    score = (grouped[\"human_number\"].apply(lambda x: (x * data.loc[x.index, \"prob_pred\"]).sum())\n",
    "             / grouped[\"prob_pred\"].sum())\n",
    "    return score.reset_index(name=\"score\")\n",
    "\n",
    "# produce df with one value per model per item for top n version --------------------------------------------------\n",
    "def get_LLM_value_per_item_top_n(data):\n",
    "    new_df = (\n",
    "    data.groupby([\"experiment\", \"model\", \"item\"])[[\"human_number\", \"prob_pred\"]]\n",
    "      .apply(compute_top_n_weighted_score)\n",
    "      .reset_index(name=\"score_top_n\")\n",
    "    )\n",
    "    return(new_df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eece353e",
   "metadata": {},
   "source": [
    "## AUDIT SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "65a51faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (712264, 11)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "AUDIT_data = load_dataframes(task_name=\"AUDIT\", path = \"LLM_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "fd081b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one (tun so als hätten wir sehr guten Prompt, dann würde LLM nur zwischen möglichen Antwortalternativen aussuchen, da simulieren wir dadurch)\n",
    "mask = (AUDIT_data[\"item\"] == 1)\n",
    "AUDIT_data.loc[mask, \"prob_1\"] = np.exp(AUDIT_data.loc[mask, \"1\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]))\n",
    "AUDIT_data.loc[mask, \"prob_2\"] = np.exp(AUDIT_data.loc[mask, \"2\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]))\n",
    "\n",
    "mask = (AUDIT_data[\"item\"].isin([10, 11]))\n",
    "AUDIT_data.loc[mask, \"prob_1\"] = np.exp(AUDIT_data.loc[mask, \"1\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]))\n",
    "AUDIT_data.loc[mask, \"prob_2\"] = np.exp(AUDIT_data.loc[mask, \"2\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]))\n",
    "AUDIT_data.loc[mask, \"prob_3\"] = np.exp(AUDIT_data.loc[mask, \"3\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]))\n",
    "\n",
    "\n",
    "mask = (AUDIT_data[\"item\"].isin([2, 3, 4, 5, 6, 7, 8, 9]))\n",
    "AUDIT_data.loc[mask, \"prob_1\"] = np.exp(AUDIT_data.loc[mask, \"1\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]) + np.exp(AUDIT_data.loc[mask, \"4\"]) + np.exp(AUDIT_data.loc[mask, \"5\"]))\n",
    "AUDIT_data.loc[mask, \"prob_2\"] = np.exp(AUDIT_data.loc[mask, \"2\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]) + np.exp(AUDIT_data.loc[mask, \"4\"]) + np.exp(AUDIT_data.loc[mask, \"5\"]))\n",
    "AUDIT_data.loc[mask, \"prob_3\"] = np.exp(AUDIT_data.loc[mask, \"3\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]) + np.exp(AUDIT_data.loc[mask, \"4\"]) + np.exp(AUDIT_data.loc[mask, \"5\"]))\n",
    "AUDIT_data.loc[mask, \"prob_4\"] = np.exp(AUDIT_data.loc[mask, \"4\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]) + np.exp(AUDIT_data.loc[mask, \"4\"]) + np.exp(AUDIT_data.loc[mask, \"5\"]))\n",
    "AUDIT_data.loc[mask, \"prob_5\"] = np.exp(AUDIT_data.loc[mask, \"5\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]) + np.exp(AUDIT_data.loc[mask, \"4\"]) + np.exp(AUDIT_data.loc[mask, \"5\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "8b52a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "AUDIT_data=filter_pred_prob(AUDIT_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "1421f934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (AUDIT_data[\"flipped\"] == \"yes\") & (AUDIT_data[\"item\"] == 1)\n",
    "AUDIT_data.loc[mask, \"human_number\"] = 3 - AUDIT_data.loc[mask, \"human_number\"]\n",
    "mask = (AUDIT_data[\"flipped\"] == \"yes\") & (AUDIT_data[\"item\"].isin([10, 11]))\n",
    "AUDIT_data.loc[mask, \"human_number\"] = 4 - AUDIT_data.loc[mask, \"human_number\"]\n",
    "mask = (AUDIT_data[\"flipped\"] == \"yes\") & (AUDIT_data[\"item\"].isin([2, 3, 4, 5, 6, 7, 8, 9]))\n",
    "AUDIT_data.loc[mask, \"human_number\"] = 6 - AUDIT_data.loc[mask, \"human_number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "7a81387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mappings for each AUDIT question:\n",
    "audit_maps = {\n",
    "    1: {1: 1, 2: 0},                            # AlcSplit\n",
    "    2: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4},          # AUDIT_1 (in proc data Frey)\n",
    "    3: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4},          # AUDIT_2 (in proc data Frey)\n",
    "    4: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4},          # AUDIT_3 (in proc data Frey)\n",
    "    5: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4},          # AUDIT_4 (in proc data Frey)\n",
    "    6: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4},          # AUDIT_5 (in proc data Frey)\n",
    "    7: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4},          # AUDIT_6 (in proc data Frey)\n",
    "    8: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4},          # AUDIT_7 (in proc data Frey)\n",
    "    9: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4},          # AUDIT_8 (in proc data Frey)\n",
    "    10: {1: 0, 2: 2, 3: 4},                     # AUDIT_10 (in proc data Frey)\n",
    "    11: {1: 0, 2: 2, 3: 4},                     # AUDIT_11 (in proc data Frey)\n",
    "\n",
    "}\n",
    "\n",
    "# Apply mapping row-wise based on item number\n",
    "def recode_audit(row):\n",
    "    mapping = audit_maps.get(row[\"item\"])\n",
    "    if mapping is not None:\n",
    "        return mapping.get(row[\"human_number\"], None)  # None if invalid code\n",
    "    return row[\"human_number\"]  \n",
    "\n",
    "AUDIT_data[\"human_number\"] = AUDIT_data.apply(recode_audit, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "f0d05126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_AUDIT = get_LLM_value_per_item(AUDIT_data)\n",
    "model_item_scores_AUDIT_top_n = get_LLM_value_per_item_top_n(AUDIT_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_AUDIT = model_item_scores_AUDIT.merge(\n",
    "    model_item_scores_AUDIT_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d65688",
   "metadata": {},
   "source": [
    "## BARRAT SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "cc730c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (2082420, 10)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "BARRAT_data = load_dataframes(task_name=\"BARRAT\", path = \"LLM_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "4b88e1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one\n",
    "BARRAT_data[\"prob_1\"] = np.exp(BARRAT_data[\"1\"])/(np.exp(BARRAT_data[\"1\"]) + np.exp(BARRAT_data[\"2\"]) + np.exp(BARRAT_data[\"3\"]) + np.exp(BARRAT_data[\"4\"]))\n",
    "BARRAT_data[\"prob_2\"] = np.exp(BARRAT_data[\"2\"])/(np.exp(BARRAT_data[\"1\"]) + np.exp(BARRAT_data[\"2\"]) + np.exp(BARRAT_data[\"3\"]) + np.exp(BARRAT_data[\"4\"]))\n",
    "BARRAT_data[\"prob_3\"] = np.exp(BARRAT_data[\"3\"])/(np.exp(BARRAT_data[\"1\"]) + np.exp(BARRAT_data[\"2\"]) + np.exp(BARRAT_data[\"3\"]) + np.exp(BARRAT_data[\"4\"]))\n",
    "BARRAT_data[\"prob_4\"] = np.exp(BARRAT_data[\"4\"])/(np.exp(BARRAT_data[\"1\"]) + np.exp(BARRAT_data[\"2\"]) + np.exp(BARRAT_data[\"3\"]) + np.exp(BARRAT_data[\"4\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "9945c979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "BARRAT_data=filter_pred_prob(BARRAT_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "29d02886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (BARRAT_data[\"flipped\"] == True)\n",
    "BARRAT_data.loc[mask, \"human_number\"] = 5 - BARRAT_data.loc[mask, \"human_number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "3100efef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_BARRAT = get_LLM_value_per_item(BARRAT_data)\n",
    "model_item_scores_BARRAT_top_n = get_LLM_value_per_item_top_n(BARRAT_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_BARRAT = model_item_scores_BARRAT.merge(\n",
    "    model_item_scores_BARRAT_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "38eda3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding task specific categories to save in all data\n",
    "\n",
    "# add item categories\n",
    "item_to_category = {\n",
    "    1: \"BISn\", 2: \"BISm\", 3: \"BISm\",  4: \"BISm\", 5: \"BISa\",  6: \"BISa\",  7: \"BISn\",  8: \"BISn\",  9: \"BISa\",  10: \"BISn\",\n",
    "    11: \"BISa\", 12: \"BISn\", 13: \"BISn\",  14: \"BISn\", 15: \"BISn\",  16: \"BISm\",  17: \"BISm\",  18: \"BISn\",  19: \"BISm\",  20: \"BISa\",\n",
    "    21: \"BISm\", 22: \"BISm\", 23: \"BISm\",  24: \"BISa\", 25: \"BISm\",  26: \"BISa\",  27: \"BISn\",  28: \"BISa\",  29: \"BISn\",  30: \"BISm\"\n",
    "}\n",
    "# add whether item was reverse coded\n",
    "reverse_coded = {\n",
    "    1: True, 2: False, 3: False,  4: False, 5: False,  6: False,  7: True,  8: True,  9: True,  10: True,\n",
    "    11: False, 12: True, 13: True,  14: False, 15: True,  16: False,  17: False,  18: False,  19: False,  20: True,\n",
    "    21: False, 22: False, 23: False,  24: False, 25: False,  26: False,  27: False,  28: False,  29: True,  30: True\n",
    "    }\n",
    "\n",
    "model_item_scores_BARRAT[\"category\"] = model_item_scores_BARRAT[\"item\"].map(item_to_category)\n",
    "model_item_scores_BARRAT[\"reverse_coded\"] = model_item_scores_BARRAT[\"item\"].map(reverse_coded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "65e25fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back answers that where reverse coded\n",
    "mask = (model_item_scores_BARRAT[\"reverse_coded\"] == True)\n",
    "model_item_scores_BARRAT.loc[mask, \"score\"] = 5 - model_item_scores_BARRAT.loc[mask, \"score\"]\n",
    "model_item_scores_BARRAT.loc[mask, \"score_top_n\"] = 5 - model_item_scores_BARRAT.loc[mask, \"score_top_n\"]\n",
    "# drop reverse-coded column (not needed in final data)\n",
    "model_item_scores_BARRAT = model_item_scores_BARRAT.drop(columns=[\"reverse_coded\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "7ddb9972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([model_item_scores_AUDIT, model_item_scores_BARRAT], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0226ac",
   "metadata": {},
   "source": [
    "## CARE TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "f1491661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (1320614, 106)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "CARE_data = load_dataframes(task_name=\"CARE\", path = \"LLM_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "d59c8fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probabilities out of log-probabilities\n",
    "\n",
    "cols = [str(i) for i in range(0, 100)]\n",
    "# Compute normalized probabilities\n",
    "exp_vals = np.exp(CARE_data[cols])\n",
    "prob_vals = exp_vals.div(exp_vals.sum(axis=1), axis=0)\n",
    "\n",
    "# Rename columns all at once\n",
    "prob_vals.columns = [f\"prob_{i}\" for i in range(0, 100)]\n",
    "\n",
    "# Join to original dataframe in one step\n",
    "CARE_data = pd.concat([CARE_data, prob_vals], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "a389bebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "CARE_data=filter_pred_prob(CARE_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "914d1030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_CARE = get_LLM_value_per_item(CARE_data)\n",
    "model_item_scores_CARE_top_n = get_LLM_value_per_item_top_n(CARE_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_CARE = model_item_scores_CARE.merge(\n",
    "    model_item_scores_CARE_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "4a344c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding task specific categories to save in all data\n",
    "# add item categories\n",
    "item_to_category = {\n",
    "    1: \"CAREa\", 2: \"CAREa\", 3: \"CAREa\",  4: \"CAREa\", 5: \"CAREa\",  6: \"CAREa\",  7: \"CAREa\",  8: \"CAREa\",  9: \"CAREa\",  10: \"CAREs\",\n",
    "    11: \"CAREs\", 12: \"CAREs\", 13: \"CAREs\",  14: \"CAREs\", 15: \"CAREs\",  16: \"CAREw\",  17: \"CAREw\",  18: \"CAREw\",  19: \"CAREw\"\n",
    "}\n",
    "\n",
    "model_item_scores_CARE[\"category\"] = model_item_scores_CARE[\"item\"].map(item_to_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "b8720af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([all_data, model_item_scores_CARE], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1623f7ae",
   "metadata": {},
   "source": [
    "## DAST SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "a1e720e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (1391040, 8)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "DAST_data = load_dataframes(task_name=\"DAST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "acf31561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one \n",
    "DAST_data[\"prob_1\"] = np.exp(DAST_data[\"1\"])/(np.exp(DAST_data[\"1\"]) + np.exp(DAST_data[\"2\"]))\n",
    "DAST_data[\"prob_2\"] = np.exp(DAST_data[\"2\"])/(np.exp(DAST_data[\"1\"]) + np.exp(DAST_data[\"2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "6833d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "DAST_data=filter_pred_prob(DAST_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "4d9b749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (DAST_data[\"flipped\"] == True) \n",
    "DAST_data.loc[mask, \"human_number\"] = 3 - DAST_data.loc[mask, \"human_number\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "79db3eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mappings for each DAST question:\n",
    "dast_maps = {\n",
    "    1: {1: 1, 2: 0},                           \n",
    "    2: {1: 1, 2: 0},\n",
    "    3: {1: 1, 2: 0},\n",
    "    4: {1: 0, 2: 1},\n",
    "    5: {1: 0, 2: 1},\n",
    "    6: {1: 1, 2: 0},\n",
    "    7: {1: 1, 2: 0},\n",
    "    8: {1: 1, 2: 0},\n",
    "    9: {1: 1, 2: 0},\n",
    "    10: {1: 1, 2: 0},\n",
    "    11: {1: 1, 2: 0},\n",
    "    12: {1: 1, 2: 0},\n",
    "    13: {1: 1, 2: 0},\n",
    "    14: {1: 1, 2: 0},\n",
    "    15: {1: 1, 2: 0},\n",
    "    16: {1: 1, 2: 0},\n",
    "    17: {1: 1, 2: 0},\n",
    "    18: {1: 1, 2: 0},\n",
    "    19: {1: 1, 2: 0},\n",
    "    20: {1: 1, 2: 0}\n",
    "}\n",
    "\n",
    "# Apply mapping row-wise based on item number\n",
    "def recode_dast(row):\n",
    "    mapping = dast_maps.get(row[\"item\"])\n",
    "    if mapping is not None:\n",
    "        return mapping.get(row[\"human_number\"], None)  # None if invalid code\n",
    "    return row[\"human_number\"]  \n",
    "\n",
    "DAST_data[\"human_number\"] = DAST_data.apply(recode_dast, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "806cd5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_DAST = get_LLM_value_per_item(DAST_data)\n",
    "model_item_scores_DAST_top_n = get_LLM_value_per_item_top_n(DAST_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_DAST = model_item_scores_DAST.merge(\n",
    "    model_item_scores_DAST_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "54525c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_DAST], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a376a9e9",
   "metadata": {},
   "source": [
    "## DM SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "a50dd425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (1318866, 10)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "DM_data = load_dataframes(task_name=\"DM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "f8a1b71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one\n",
    "DM_data[\"prob_1\"] = np.exp(DM_data[\"1\"])/(np.exp(DM_data[\"1\"]) + np.exp(DM_data[\"2\"]) + np.exp(DM_data[\"3\"]) + np.exp(DM_data[\"4\"]))\n",
    "DM_data[\"prob_2\"] = np.exp(DM_data[\"2\"])/(np.exp(DM_data[\"1\"]) + np.exp(DM_data[\"2\"]) + np.exp(DM_data[\"3\"]) + np.exp(DM_data[\"4\"]))\n",
    "DM_data[\"prob_3\"] = np.exp(DM_data[\"3\"])/(np.exp(DM_data[\"1\"]) + np.exp(DM_data[\"2\"]) + np.exp(DM_data[\"3\"]) + np.exp(DM_data[\"4\"]))\n",
    "DM_data[\"prob_4\"] = np.exp(DM_data[\"4\"])/(np.exp(DM_data[\"1\"]) + np.exp(DM_data[\"2\"]) + np.exp(DM_data[\"3\"]) + np.exp(DM_data[\"4\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "4b778d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "DM_data=filter_pred_prob(DM_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "22d0cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (DM_data[\"flipped\"] == True) \n",
    "DM_data.loc[mask, \"human_number\"] = 5 - DM_data.loc[mask, \"human_number\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "f0d4d183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mappings for DM, so that all 4s are transformed to 1s (like in original Fey dataset):\n",
    "# hier Abweichung von sonst Orientierung an Frey quest_proc df, aber da sonst später Umwandlung, hier gleich zu Scale 0-2\n",
    "mapping = {\n",
    "    4: 1,\n",
    "    3: 2,\n",
    "    2: 1,\n",
    "    1: 0\n",
    "}\n",
    "DM_data[\"human_number\"] = DM_data[\"human_number\"].map(mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "cb8e201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_DM = get_LLM_value_per_item(DM_data)\n",
    "model_item_scores_DM_top_n = get_LLM_value_per_item_top_n(DM_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_DM = model_item_scores_DM.merge(\n",
    "    model_item_scores_DM_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "dd2ac9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>model</th>\n",
       "      <th>item</th>\n",
       "      <th>score</th>\n",
       "      <th>score_top_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dm scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>1</td>\n",
       "      <td>1.732626</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dm scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>2</td>\n",
       "      <td>0.429937</td>\n",
       "      <td>1.130817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dm scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>3</td>\n",
       "      <td>1.189583</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dm scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>4</td>\n",
       "      <td>0.529104</td>\n",
       "      <td>1.211428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dm scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>5</td>\n",
       "      <td>1.293137</td>\n",
       "      <td>1.471195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>Dm scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>15</td>\n",
       "      <td>0.084566</td>\n",
       "      <td>0.019992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>Dm scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>16</td>\n",
       "      <td>0.096645</td>\n",
       "      <td>0.179757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>Dm scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>17</td>\n",
       "      <td>0.382729</td>\n",
       "      <td>0.365378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>Dm scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>18</td>\n",
       "      <td>1.132564</td>\n",
       "      <td>0.395929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>Dm scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>19</td>\n",
       "      <td>0.936382</td>\n",
       "      <td>0.990000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>874 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    experiment                      model  item     score  score_top_n\n",
       "0     Dm scale  Apertus-70B-Instruct-2509     1  1.732626     2.000000\n",
       "1     Dm scale  Apertus-70B-Instruct-2509     2  0.429937     1.130817\n",
       "2     Dm scale  Apertus-70B-Instruct-2509     3  1.189583     2.000000\n",
       "3     Dm scale  Apertus-70B-Instruct-2509     4  0.529104     1.211428\n",
       "4     Dm scale  Apertus-70B-Instruct-2509     5  1.293137     1.471195\n",
       "..         ...                        ...   ...       ...          ...\n",
       "869   Dm scale             zephyr-7b-beta    15  0.084566     0.019992\n",
       "870   Dm scale             zephyr-7b-beta    16  0.096645     0.179757\n",
       "871   Dm scale             zephyr-7b-beta    17  0.382729     0.365378\n",
       "872   Dm scale             zephyr-7b-beta    18  1.132564     0.395929\n",
       "873   Dm scale             zephyr-7b-beta    19  0.936382     0.990000\n",
       "\n",
       "[874 rows x 5 columns]"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_item_scores_DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "125ae7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_DM], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf36e830",
   "metadata": {},
   "source": [
    "## DOSPERT SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "4828b1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (2780240, 11)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "DOSPERT_data = load_dataframes(task_name=\"DOSPERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "df6de3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one\n",
    "DOSPERT_data[\"prob_1\"] = np.exp(DOSPERT_data[\"1\"])/(np.exp(DOSPERT_data[\"1\"]) + np.exp(DOSPERT_data[\"2\"]) + np.exp(DOSPERT_data[\"3\"]) + np.exp(DOSPERT_data[\"4\"]) + np.exp(DOSPERT_data[\"5\"]))\n",
    "DOSPERT_data[\"prob_2\"] = np.exp(DOSPERT_data[\"2\"])/(np.exp(DOSPERT_data[\"1\"]) + np.exp(DOSPERT_data[\"2\"]) + np.exp(DOSPERT_data[\"3\"]) + np.exp(DOSPERT_data[\"4\"]) + np.exp(DOSPERT_data[\"5\"]))\n",
    "DOSPERT_data[\"prob_3\"] = np.exp(DOSPERT_data[\"3\"])/(np.exp(DOSPERT_data[\"1\"]) + np.exp(DOSPERT_data[\"2\"]) + np.exp(DOSPERT_data[\"3\"]) + np.exp(DOSPERT_data[\"4\"]) + np.exp(DOSPERT_data[\"5\"]))\n",
    "DOSPERT_data[\"prob_4\"] = np.exp(DOSPERT_data[\"4\"])/(np.exp(DOSPERT_data[\"1\"]) + np.exp(DOSPERT_data[\"2\"]) + np.exp(DOSPERT_data[\"3\"]) + np.exp(DOSPERT_data[\"4\"]) + np.exp(DOSPERT_data[\"5\"]))\n",
    "DOSPERT_data[\"prob_5\"] = np.exp(DOSPERT_data[\"5\"])/(np.exp(DOSPERT_data[\"1\"]) + np.exp(DOSPERT_data[\"2\"]) + np.exp(DOSPERT_data[\"3\"]) + np.exp(DOSPERT_data[\"4\"]) + np.exp(DOSPERT_data[\"5\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "c87c6117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "DOSPERT_data=filter_pred_prob(DOSPERT_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "270ff6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (DOSPERT_data[\"flipped\"] == 'yes') \n",
    "DOSPERT_data.loc[mask, \"human_number\"] = 6 - DOSPERT_data.loc[mask, \"human_number\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "a15c7fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_DOSPERT = get_LLM_value_per_item(DOSPERT_data)\n",
    "model_item_scores_DOSPERT_top_n = get_LLM_value_per_item_top_n(DOSPERT_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_DOSPERT = model_item_scores_DOSPERT.merge(\n",
    "    model_item_scores_DOSPERT_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "005799af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding task specific categories to save in all data\n",
    "\n",
    "# add item categories\n",
    "item_to_category = {\n",
    "    1: \"Social\", 10: \"Social\", 16: \"Social\", 19: \"Social\", 23: \"Social\", 26: \"Social\", 34: \"Social\", 35: \"Social\",\n",
    "    2: \"Recreational\", 6: \"Recreational\", 15: \"Recreational\", 17: \"Recreational\", 21: \"Recreational\", 31: \"Recreational\", 37: \"Recreational\", 38: \"Recreational\",\n",
    "    3: \"Gambling\", 11: \"Gambling\", 22: \"Gambling\", 33: \"Gambling\",\n",
    "    4: \"Health\", 8: \"Health\", 27: \"Health\", 29: \"Health\", 32: \"Health\", 36: \"Health\", 39: \"Health\", 40: \"Health\",\n",
    "    5: \"Ethical\", 9: \"Ethical\", 12: \"Ethical\", 13: \"Ethical\", 14: \"Ethical\", 20: \"Ethical\", 25: \"Ethical\", 28: \"Ethical\",\n",
    "    7: \"Investment\", 18: \"Investment\", 24: \"Investment\", 30: \"Investment\"\n",
    "}\n",
    "\n",
    "model_item_scores_DOSPERT[\"category\"] = model_item_scores_DOSPERT[\"item\"].map(item_to_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "eae478ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_DOSPERT], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cbad99",
   "metadata": {},
   "source": [
    "## FTND SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "b79895fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (163162, 10)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "FTND_data = load_dataframes(task_name=\"FTND\")\n",
    "# load human daa also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "3d512cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one (tun so als hätten wir sehr guten Prompt, dann würde LLM nur zwischen möglichen Antwortalternativen aussuchen, da simulieren wir dadurch)\n",
    "mask = (FTND_data[\"item\"] == 1)\n",
    "FTND_data.loc[mask, \"prob_1\"] = np.exp(FTND_data.loc[mask, \"1\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]) + np.exp(FTND_data.loc[mask, \"3\"]))\n",
    "FTND_data.loc[mask, \"prob_2\"] = np.exp(FTND_data.loc[mask, \"2\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]) + np.exp(FTND_data.loc[mask, \"3\"]))\n",
    "FTND_data.loc[mask, \"prob_3\"] = np.exp(FTND_data.loc[mask, \"3\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]) + np.exp(FTND_data.loc[mask, \"3\"]))\n",
    "\n",
    "mask = (FTND_data[\"item\"].isin([3, 4, 6, 7]))\n",
    "FTND_data.loc[mask, \"prob_1\"] = np.exp(FTND_data.loc[mask, \"1\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]))\n",
    "FTND_data.loc[mask, \"prob_2\"] = np.exp(FTND_data.loc[mask, \"2\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]))\n",
    "\n",
    "mask = (FTND_data[\"item\"].isin([2, 5]))\n",
    "FTND_data.loc[mask, \"prob_1\"] = np.exp(FTND_data.loc[mask, \"1\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]) + np.exp(FTND_data.loc[mask, \"3\"]) + np.exp(FTND_data.loc[mask, \"4\"]))\n",
    "FTND_data.loc[mask, \"prob_2\"] = np.exp(FTND_data.loc[mask, \"2\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]) + np.exp(FTND_data.loc[mask, \"3\"]) + np.exp(FTND_data.loc[mask, \"4\"]))\n",
    "FTND_data.loc[mask, \"prob_3\"] = np.exp(FTND_data.loc[mask, \"3\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]) + np.exp(FTND_data.loc[mask, \"3\"]) + np.exp(FTND_data.loc[mask, \"4\"]))\n",
    "FTND_data.loc[mask, \"prob_4\"] = np.exp(FTND_data.loc[mask, \"4\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]) + np.exp(FTND_data.loc[mask, \"3\"]) + np.exp(FTND_data.loc[mask, \"4\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "f407d56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "FTND_data=filter_pred_prob(FTND_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "6c3668c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (FTND_data[\"flipped\"] == True) & (FTND_data[\"item\"] == 1)\n",
    "FTND_data.loc[mask, \"human_number\"] = 4 - FTND_data.loc[mask, \"human_number\"]\n",
    "mask = (FTND_data[\"flipped\"] == True) & (FTND_data[\"item\"].isin([3, 4, 6, 7]))\n",
    "FTND_data.loc[mask, \"human_number\"] = 3 - FTND_data.loc[mask, \"human_number\"]\n",
    "mask = (FTND_data[\"flipped\"] == True) & (FTND_data[\"item\"].isin([2, 5]))\n",
    "FTND_data.loc[mask, \"human_number\"] = 5 - FTND_data.loc[mask, \"human_number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813faab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mappings for each FTND question:\n",
    "ftnd_maps = {\n",
    "    1: {1: 2, 2: 0, 3: 1},             # FTND_1Eingangsfrage: smoke?\n",
    "    2: {1: 3, 2: 2, 3: 1, 4: 0},       # FTND_1: time until first cigarette\n",
    "    3: {1: 1, 2: 0},                   # FTND_2: difficult to refrain\n",
    "    4: {1: 1, 2: 0},                   # FTND_3: which cigarette hardest to give up\n",
    "    5: {1: 0, 2: 1, 3: 2, 4: 3},       # FTND_4: cigarettes per day\n",
    "    6: {1: 1, 2: 0},                   # FTND_5: smoke more frequently in morning\n",
    "    7: {1: 1, 2: 0}                    # FTND_6: smoke when ill\n",
    "}\n",
    "\n",
    "# Apply mapping row-wise based on item number\n",
    "def recode_ftnd(row):\n",
    "    mapping = ftnd_maps.get(row[\"item\"])\n",
    "    if mapping is not None:\n",
    "        return mapping.get(row[\"human_number\"], None) \n",
    "    return row[\"human_number\"]  \n",
    "\n",
    "FTND_data[\"human_number\"] = FTND_data.apply(recode_ftnd, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "0bf07e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_FTND = get_LLM_value_per_item(FTND_data)\n",
    "model_item_scores_FTND_top_n = get_LLM_value_per_item_top_n(FTND_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_FTND = model_item_scores_FTND.merge(\n",
    "    model_item_scores_FTND_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "ce78b07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_FTND], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54306e48",
   "metadata": {},
   "source": [
    "## GABS SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "dc20119a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (581210, 10)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "GABS_data = load_dataframes(task_name=\"GABS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "8cf18026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one\n",
    "\n",
    "# columns representing log-probabilities\n",
    "answer_cols = [\"1\", \"2\", \"3\", \"4\"]\n",
    "\n",
    "# make a copy to avoid SettingWithCopy warnings\n",
    "GABS_data = GABS_data.copy()\n",
    "\n",
    "# case 1: item == 1 → only options 1 and 2\n",
    "mask_item1 = GABS_data[\"item\"] == 1\n",
    "exp_vals_item1 = np.exp(GABS_data.loc[mask_item1, [\"1\", \"2\"]])\n",
    "probs_item1 = exp_vals_item1.div(exp_vals_item1.sum(axis=1), axis=0)\n",
    "probs_item1.columns = [\"prob_1\", \"prob_2\"]\n",
    "\n",
    "# case 2: items 2–17 → options 1–4\n",
    "mask_item2plus = GABS_data[\"item\"].between(2, 17)\n",
    "exp_vals_item2plus = np.exp(GABS_data.loc[mask_item2plus, answer_cols])\n",
    "probs_item2plus = exp_vals_item2plus.div(exp_vals_item2plus.sum(axis=1), axis=0)\n",
    "probs_item2plus.columns = [f\"prob_{c}\" for c in answer_cols]\n",
    "\n",
    "# merge both parts back into original df\n",
    "GABS_data = GABS_data.join(pd.concat([probs_item1, probs_item2plus]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "45796a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "GABS_data=filter_pred_prob(GABS_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "29b40036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (GABS_data[\"flipped\"] == True) & (GABS_data[\"item\"] == 1)\n",
    "GABS_data.loc[mask, \"human_number\"] = 3 - GABS_data.loc[mask, \"human_number\"]\n",
    "mask = (GABS_data[\"flipped\"] == True) & (GABS_data[\"item\"].isin(range(2,17)))\n",
    "GABS_data.loc[mask, \"human_number\"] = 5 - GABS_data.loc[mask, \"human_number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "6cb6a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_GABS = get_LLM_value_per_item(GABS_data)\n",
    "model_item_scores_GABS_top_n = get_LLM_value_per_item_top_n(GABS_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_GABS = model_item_scores_GABS.merge(\n",
    "    model_item_scores_GABS_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "abcf63ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_GABS], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed59198",
   "metadata": {},
   "source": [
    "## PG SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "e97aa4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (1127322, 13)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "PG_data = load_dataframes(task_name=\"PG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "66851dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one \n",
    "\n",
    "mask = (PG_data[\"item\"].isin([1, 26]))\n",
    "PG_data.loc[mask, \"prob_1\"] = np.exp(PG_data.loc[mask, \"1\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]))\n",
    "PG_data.loc[mask, \"prob_2\"] = np.exp(PG_data.loc[mask, \"2\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]))\n",
    "\n",
    "\n",
    "\n",
    "mask = (PG_data[\"item\"].isin(range(2, 21)))\n",
    "PG_data.loc[mask, \"prob_1\"] = np.exp(PG_data.loc[mask, \"1\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]))\n",
    "PG_data.loc[mask, \"prob_2\"] = np.exp(PG_data.loc[mask, \"2\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]))\n",
    "PG_data.loc[mask, \"prob_3\"] = np.exp(PG_data.loc[mask, \"3\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]))\n",
    "PG_data.loc[mask, \"prob_4\"] = np.exp(PG_data.loc[mask, \"4\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]))\n",
    "PG_data.loc[mask, \"prob_5\"] = np.exp(PG_data.loc[mask, \"5\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]))\n",
    "\n",
    "\n",
    "\n",
    "mask = (PG_data[\"item\"] == 25)\n",
    "PG_data.loc[mask, \"prob_1\"] = np.exp(PG_data.loc[mask, \"1\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]) + np.exp(PG_data.loc[mask, \"6\"]))\n",
    "PG_data.loc[mask, \"prob_2\"] = np.exp(PG_data.loc[mask, \"2\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]) + np.exp(PG_data.loc[mask, \"6\"]))\n",
    "PG_data.loc[mask, \"prob_3\"] = np.exp(PG_data.loc[mask, \"3\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]) + np.exp(PG_data.loc[mask, \"6\"]))\n",
    "PG_data.loc[mask, \"prob_4\"] = np.exp(PG_data.loc[mask, \"4\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]) + np.exp(PG_data.loc[mask, \"6\"]))\n",
    "PG_data.loc[mask, \"prob_5\"] = np.exp(PG_data.loc[mask, \"5\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]) + np.exp(PG_data.loc[mask, \"6\"]))\n",
    "PG_data.loc[mask, \"prob_6\"] = np.exp(PG_data.loc[mask, \"6\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]) + np.exp(PG_data.loc[mask, \"6\"]))\n",
    "\n",
    "\n",
    "mask = (PG_data[\"item\"].isin([21, 22, 23, 24, 27, 28, 29, 30, 31, 32]))\n",
    "PG_data.loc[mask, \"prob_0\"] = np.exp(PG_data.loc[mask, \"0\"])/(np.exp(PG_data.loc[mask, \"0\"]) + np.exp(PG_data.loc[mask, \"1\"]))\n",
    "PG_data.loc[mask, \"prob_1\"] = np.exp(PG_data.loc[mask, \"1\"])/(np.exp(PG_data.loc[mask, \"0\"]) + np.exp(PG_data.loc[mask, \"1\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "dfc61164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "PG_data=filter_pred_prob(PG_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "66d9d25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (PG_data[\"flipped\"] == True) & (PG_data[\"item\"].isin([1, 26]))\n",
    "PG_data.loc[mask, \"human_number\"] = 3 - PG_data.loc[mask, \"human_number\"]\n",
    "\n",
    "mask = (PG_data[\"flipped\"] == True) & (PG_data[\"item\"].isin(range(2, 21)))\n",
    "PG_data.loc[mask, \"human_number\"] = 6 - PG_data.loc[mask, \"human_number\"]\n",
    "\n",
    "mask = (PG_data[\"flipped\"] == True) & (PG_data[\"item\"] == 25)\n",
    "PG_data.loc[mask, \"human_number\"] = 7 - PG_data.loc[mask, \"human_number\"]\n",
    "\n",
    "mask = (PG_data[\"flipped\"] == True) & (PG_data[\"item\"].isin([21, 22, 23, 24, 27, 28, 29, 30, 31, 32]))\n",
    "PG_data.loc[mask, \"human_number\"] = 1 - PG_data.loc[mask, \"human_number\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "1d02db9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human_number</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>model</th>\n",
       "      <th>item</th>\n",
       "      <th>...</th>\n",
       "      <th>flipped</th>\n",
       "      <th>experiment</th>\n",
       "      <th>prob_1</th>\n",
       "      <th>prob_2</th>\n",
       "      <th>prob_3</th>\n",
       "      <th>prob_4</th>\n",
       "      <th>prob_5</th>\n",
       "      <th>prob_6</th>\n",
       "      <th>prob_0</th>\n",
       "      <th>prob_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-12.7500</td>\n",
       "      <td>-13.1875</td>\n",
       "      <td>-14.8750</td>\n",
       "      <td>-14.6250</td>\n",
       "      <td>-14.8750</td>\n",
       "      <td>-14.6875</td>\n",
       "      <td>-15.1875</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.843895</td>\n",
       "      <td>0.156105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.156105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>-11.6875</td>\n",
       "      <td>-10.8750</td>\n",
       "      <td>-11.8125</td>\n",
       "      <td>-12.2500</td>\n",
       "      <td>-12.3125</td>\n",
       "      <td>-11.1250</td>\n",
       "      <td>-12.7500</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.375832</td>\n",
       "      <td>0.147178</td>\n",
       "      <td>0.095025</td>\n",
       "      <td>0.089268</td>\n",
       "      <td>0.292698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.375832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>-15.4375</td>\n",
       "      <td>-13.5625</td>\n",
       "      <td>-12.8750</td>\n",
       "      <td>-14.8750</td>\n",
       "      <td>-15.6875</td>\n",
       "      <td>-14.3750</td>\n",
       "      <td>-16.2500</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.261707</td>\n",
       "      <td>0.520467</td>\n",
       "      <td>0.070438</td>\n",
       "      <td>0.031256</td>\n",
       "      <td>0.116132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.261707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>-13.1875</td>\n",
       "      <td>-12.3125</td>\n",
       "      <td>-13.4375</td>\n",
       "      <td>-13.0000</td>\n",
       "      <td>-12.5625</td>\n",
       "      <td>-12.9375</td>\n",
       "      <td>-15.3125</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.318315</td>\n",
       "      <td>0.103342</td>\n",
       "      <td>0.160059</td>\n",
       "      <td>0.247904</td>\n",
       "      <td>0.170382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.318315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-13.2500</td>\n",
       "      <td>-12.8750</td>\n",
       "      <td>-14.3750</td>\n",
       "      <td>-14.0000</td>\n",
       "      <td>-12.3125</td>\n",
       "      <td>-12.0625</td>\n",
       "      <td>-15.0625</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.179974</td>\n",
       "      <td>0.040158</td>\n",
       "      <td>0.058429</td>\n",
       "      <td>0.315863</td>\n",
       "      <td>0.405577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.179974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-12.1250</td>\n",
       "      <td>-12.4375</td>\n",
       "      <td>-14.0000</td>\n",
       "      <td>-14.0000</td>\n",
       "      <td>-13.0000</td>\n",
       "      <td>-11.3750</td>\n",
       "      <td>-12.8125</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.204809</td>\n",
       "      <td>0.042930</td>\n",
       "      <td>0.042930</td>\n",
       "      <td>0.116697</td>\n",
       "      <td>0.592634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.204809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>-12.0625</td>\n",
       "      <td>-11.9375</td>\n",
       "      <td>-13.8125</td>\n",
       "      <td>-13.8750</td>\n",
       "      <td>-13.0000</td>\n",
       "      <td>-11.8125</td>\n",
       "      <td>-12.4375</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.360210</td>\n",
       "      <td>0.055240</td>\n",
       "      <td>0.051893</td>\n",
       "      <td>0.124485</td>\n",
       "      <td>0.408171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.360210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>-11.8750</td>\n",
       "      <td>-11.5625</td>\n",
       "      <td>-13.4375</td>\n",
       "      <td>-13.6875</td>\n",
       "      <td>-12.7500</td>\n",
       "      <td>-12.0000</td>\n",
       "      <td>-12.5625</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.449758</td>\n",
       "      <td>0.068973</td>\n",
       "      <td>0.053716</td>\n",
       "      <td>0.137168</td>\n",
       "      <td>0.290385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.449758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>-11.8750</td>\n",
       "      <td>-12.0000</td>\n",
       "      <td>-13.8750</td>\n",
       "      <td>-14.2500</td>\n",
       "      <td>-13.1875</td>\n",
       "      <td>-12.3125</td>\n",
       "      <td>-13.3750</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.435663</td>\n",
       "      <td>0.066811</td>\n",
       "      <td>0.045919</td>\n",
       "      <td>0.132870</td>\n",
       "      <td>0.318738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.435663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>-11.5625</td>\n",
       "      <td>-11.1875</td>\n",
       "      <td>-13.3125</td>\n",
       "      <td>-13.6875</td>\n",
       "      <td>-12.8750</td>\n",
       "      <td>-12.3125</td>\n",
       "      <td>-13.1875</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.584402</td>\n",
       "      <td>0.069797</td>\n",
       "      <td>0.047971</td>\n",
       "      <td>0.108103</td>\n",
       "      <td>0.189727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.584402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>-11.8125</td>\n",
       "      <td>-11.8750</td>\n",
       "      <td>-13.9375</td>\n",
       "      <td>-14.5000</td>\n",
       "      <td>-13.7500</td>\n",
       "      <td>-13.1875</td>\n",
       "      <td>-14.3125</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.616494</td>\n",
       "      <td>0.078378</td>\n",
       "      <td>0.044659</td>\n",
       "      <td>0.094542</td>\n",
       "      <td>0.165927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.616494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>-12.5625</td>\n",
       "      <td>-12.4375</td>\n",
       "      <td>-14.2500</td>\n",
       "      <td>-15.2500</td>\n",
       "      <td>-15.1875</td>\n",
       "      <td>-14.0000</td>\n",
       "      <td>-15.4375</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.668074</td>\n",
       "      <td>0.109060</td>\n",
       "      <td>0.040121</td>\n",
       "      <td>0.042709</td>\n",
       "      <td>0.140036</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.109060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>-12.4375</td>\n",
       "      <td>-12.1250</td>\n",
       "      <td>-14.0625</td>\n",
       "      <td>-14.5625</td>\n",
       "      <td>-14.4375</td>\n",
       "      <td>-13.1875</td>\n",
       "      <td>-14.8125</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.596642</td>\n",
       "      <td>0.085954</td>\n",
       "      <td>0.052134</td>\n",
       "      <td>0.059076</td>\n",
       "      <td>0.206194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.596642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>-11.7500</td>\n",
       "      <td>-11.3750</td>\n",
       "      <td>-13.4375</td>\n",
       "      <td>-14.0625</td>\n",
       "      <td>-13.6250</td>\n",
       "      <td>-12.5625</td>\n",
       "      <td>-14.5625</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.622832</td>\n",
       "      <td>0.079184</td>\n",
       "      <td>0.042384</td>\n",
       "      <td>0.065646</td>\n",
       "      <td>0.189953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.622832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>-13.3125</td>\n",
       "      <td>-13.1875</td>\n",
       "      <td>-14.8750</td>\n",
       "      <td>-15.8125</td>\n",
       "      <td>-15.0625</td>\n",
       "      <td>-13.8750</td>\n",
       "      <td>-15.8125</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.522573</td>\n",
       "      <td>0.096666</td>\n",
       "      <td>0.037855</td>\n",
       "      <td>0.080139</td>\n",
       "      <td>0.262766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.522573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>-13.0000</td>\n",
       "      <td>-13.1875</td>\n",
       "      <td>-14.8750</td>\n",
       "      <td>-15.8750</td>\n",
       "      <td>-15.3125</td>\n",
       "      <td>-13.9375</td>\n",
       "      <td>-15.6250</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.542055</td>\n",
       "      <td>0.100270</td>\n",
       "      <td>0.036887</td>\n",
       "      <td>0.064739</td>\n",
       "      <td>0.256049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.542055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>-13.4375</td>\n",
       "      <td>-13.5625</td>\n",
       "      <td>-15.3750</td>\n",
       "      <td>-16.1250</td>\n",
       "      <td>-15.7500</td>\n",
       "      <td>-14.3750</td>\n",
       "      <td>-15.6875</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.556699</td>\n",
       "      <td>0.090879</td>\n",
       "      <td>0.042928</td>\n",
       "      <td>0.062460</td>\n",
       "      <td>0.247034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.556699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>-13.0625</td>\n",
       "      <td>-13.6875</td>\n",
       "      <td>-15.6875</td>\n",
       "      <td>-16.1250</td>\n",
       "      <td>-15.8750</td>\n",
       "      <td>-14.2500</td>\n",
       "      <td>-15.8750</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.525019</td>\n",
       "      <td>0.071054</td>\n",
       "      <td>0.045876</td>\n",
       "      <td>0.058905</td>\n",
       "      <td>0.299147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.525019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>-13.0625</td>\n",
       "      <td>-13.0625</td>\n",
       "      <td>-14.9375</td>\n",
       "      <td>-15.5625</td>\n",
       "      <td>-14.9375</td>\n",
       "      <td>-13.9375</td>\n",
       "      <td>-15.5000</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.553815</td>\n",
       "      <td>0.084930</td>\n",
       "      <td>0.045460</td>\n",
       "      <td>0.084930</td>\n",
       "      <td>0.230864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.553815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>-12.4375</td>\n",
       "      <td>-12.7500</td>\n",
       "      <td>-14.5625</td>\n",
       "      <td>-15.7500</td>\n",
       "      <td>-14.6875</td>\n",
       "      <td>-13.7500</td>\n",
       "      <td>-15.5000</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.579718</td>\n",
       "      <td>0.094636</td>\n",
       "      <td>0.028862</td>\n",
       "      <td>0.083516</td>\n",
       "      <td>0.213266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.579718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>-13.1875</td>\n",
       "      <td>-14.0000</td>\n",
       "      <td>-17.6250</td>\n",
       "      <td>-18.6250</td>\n",
       "      <td>-18.2500</td>\n",
       "      <td>-18.0000</td>\n",
       "      <td>-18.0000</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.307358</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.692642</td>\n",
       "      <td>0.307358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>-12.3750</td>\n",
       "      <td>-12.9375</td>\n",
       "      <td>-16.1250</td>\n",
       "      <td>-17.6250</td>\n",
       "      <td>-17.2500</td>\n",
       "      <td>-16.6250</td>\n",
       "      <td>-17.2500</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.362969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637031</td>\n",
       "      <td>0.362969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>-11.2500</td>\n",
       "      <td>-11.5000</td>\n",
       "      <td>-14.3125</td>\n",
       "      <td>-15.9375</td>\n",
       "      <td>-15.5000</td>\n",
       "      <td>-15.2500</td>\n",
       "      <td>-15.8750</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.437823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.562177</td>\n",
       "      <td>0.437823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>-12.0625</td>\n",
       "      <td>-11.3125</td>\n",
       "      <td>-14.4375</td>\n",
       "      <td>-15.3750</td>\n",
       "      <td>-14.8125</td>\n",
       "      <td>-14.6875</td>\n",
       "      <td>-15.4375</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.679179</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.320821</td>\n",
       "      <td>0.320821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>-14.0000</td>\n",
       "      <td>-14.1250</td>\n",
       "      <td>-16.0000</td>\n",
       "      <td>-16.2500</td>\n",
       "      <td>-16.3750</td>\n",
       "      <td>-15.3750</td>\n",
       "      <td>-15.4375</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.517106</td>\n",
       "      <td>0.079301</td>\n",
       "      <td>0.061760</td>\n",
       "      <td>0.054503</td>\n",
       "      <td>0.148153</td>\n",
       "      <td>0.139177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.139177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>-13.1875</td>\n",
       "      <td>-13.6250</td>\n",
       "      <td>-14.9375</td>\n",
       "      <td>-15.3125</td>\n",
       "      <td>-15.4375</td>\n",
       "      <td>-15.0625</td>\n",
       "      <td>-14.7500</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.787931</td>\n",
       "      <td>0.212069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>-15.5000</td>\n",
       "      <td>-15.3750</td>\n",
       "      <td>-17.3750</td>\n",
       "      <td>-18.2500</td>\n",
       "      <td>-18.0000</td>\n",
       "      <td>-18.1250</td>\n",
       "      <td>-18.0000</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.531209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.468791</td>\n",
       "      <td>0.531209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>-14.6250</td>\n",
       "      <td>-14.5625</td>\n",
       "      <td>-16.0000</td>\n",
       "      <td>-16.0000</td>\n",
       "      <td>-15.6250</td>\n",
       "      <td>-16.1250</td>\n",
       "      <td>-16.1250</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.515620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.484380</td>\n",
       "      <td>0.515620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>-14.8125</td>\n",
       "      <td>-14.9375</td>\n",
       "      <td>-16.8750</td>\n",
       "      <td>-16.7500</td>\n",
       "      <td>-17.2500</td>\n",
       "      <td>-18.1250</td>\n",
       "      <td>-18.1250</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.468791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.531209</td>\n",
       "      <td>0.468791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>-15.0000</td>\n",
       "      <td>-14.3125</td>\n",
       "      <td>-16.3750</td>\n",
       "      <td>-16.5000</td>\n",
       "      <td>-16.3750</td>\n",
       "      <td>-16.5000</td>\n",
       "      <td>-17.6250</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.665411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.334589</td>\n",
       "      <td>0.665411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>-14.5000</td>\n",
       "      <td>-14.0000</td>\n",
       "      <td>-16.5000</td>\n",
       "      <td>-16.2500</td>\n",
       "      <td>-16.2500</td>\n",
       "      <td>-17.0000</td>\n",
       "      <td>-16.6250</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.622459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.377541</td>\n",
       "      <td>0.622459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>-14.0625</td>\n",
       "      <td>-12.7500</td>\n",
       "      <td>-15.1875</td>\n",
       "      <td>-15.4375</td>\n",
       "      <td>-14.8750</td>\n",
       "      <td>-15.8125</td>\n",
       "      <td>-16.2500</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.787931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.212069</td>\n",
       "      <td>0.212069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>-11.9375</td>\n",
       "      <td>-13.4375</td>\n",
       "      <td>-13.6250</td>\n",
       "      <td>-14.1250</td>\n",
       "      <td>-14.1875</td>\n",
       "      <td>-13.6875</td>\n",
       "      <td>-14.0000</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.546738</td>\n",
       "      <td>0.453262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.546738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>-12.7500</td>\n",
       "      <td>-14.3750</td>\n",
       "      <td>-15.0625</td>\n",
       "      <td>-15.0000</td>\n",
       "      <td>-15.0000</td>\n",
       "      <td>-14.9375</td>\n",
       "      <td>-15.5000</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.665411</td>\n",
       "      <td>0.334589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.334589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>-11.9375</td>\n",
       "      <td>-13.4375</td>\n",
       "      <td>-13.6250</td>\n",
       "      <td>-14.1250</td>\n",
       "      <td>-14.1875</td>\n",
       "      <td>-13.6875</td>\n",
       "      <td>-14.0000</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.546738</td>\n",
       "      <td>0.453262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.546738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>-12.7500</td>\n",
       "      <td>-13.1875</td>\n",
       "      <td>-14.8750</td>\n",
       "      <td>-14.6250</td>\n",
       "      <td>-14.8750</td>\n",
       "      <td>-14.6875</td>\n",
       "      <td>-15.1875</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.843895</td>\n",
       "      <td>0.156105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.156105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5</td>\n",
       "      <td>-11.6875</td>\n",
       "      <td>-10.8750</td>\n",
       "      <td>-11.8125</td>\n",
       "      <td>-12.2500</td>\n",
       "      <td>-12.3125</td>\n",
       "      <td>-11.1250</td>\n",
       "      <td>-12.7500</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.375832</td>\n",
       "      <td>0.147178</td>\n",
       "      <td>0.095025</td>\n",
       "      <td>0.089268</td>\n",
       "      <td>0.292698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.375832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5</td>\n",
       "      <td>-15.4375</td>\n",
       "      <td>-13.5625</td>\n",
       "      <td>-12.8750</td>\n",
       "      <td>-14.8750</td>\n",
       "      <td>-15.6875</td>\n",
       "      <td>-14.3750</td>\n",
       "      <td>-16.2500</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.261707</td>\n",
       "      <td>0.520467</td>\n",
       "      <td>0.070438</td>\n",
       "      <td>0.031256</td>\n",
       "      <td>0.116132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.261707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5</td>\n",
       "      <td>-13.1875</td>\n",
       "      <td>-12.3125</td>\n",
       "      <td>-13.4375</td>\n",
       "      <td>-13.0000</td>\n",
       "      <td>-12.5625</td>\n",
       "      <td>-12.9375</td>\n",
       "      <td>-15.3125</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.318315</td>\n",
       "      <td>0.103342</td>\n",
       "      <td>0.160059</td>\n",
       "      <td>0.247904</td>\n",
       "      <td>0.170382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.318315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5</td>\n",
       "      <td>-13.2500</td>\n",
       "      <td>-12.8750</td>\n",
       "      <td>-14.3750</td>\n",
       "      <td>-14.0000</td>\n",
       "      <td>-12.3125</td>\n",
       "      <td>-12.0625</td>\n",
       "      <td>-15.0625</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.179974</td>\n",
       "      <td>0.040158</td>\n",
       "      <td>0.058429</td>\n",
       "      <td>0.315863</td>\n",
       "      <td>0.405577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.179974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2</td>\n",
       "      <td>-11.7500</td>\n",
       "      <td>-12.1250</td>\n",
       "      <td>-14.1875</td>\n",
       "      <td>-14.1250</td>\n",
       "      <td>-12.6250</td>\n",
       "      <td>-11.4375</td>\n",
       "      <td>-13.7500</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.259219</td>\n",
       "      <td>0.032956</td>\n",
       "      <td>0.035082</td>\n",
       "      <td>0.157224</td>\n",
       "      <td>0.515519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.157224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5</td>\n",
       "      <td>-13.0625</td>\n",
       "      <td>-12.8125</td>\n",
       "      <td>-14.8125</td>\n",
       "      <td>-14.4375</td>\n",
       "      <td>-13.0625</td>\n",
       "      <td>-12.0625</td>\n",
       "      <td>-13.0625</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.236516</td>\n",
       "      <td>0.032009</td>\n",
       "      <td>0.046573</td>\n",
       "      <td>0.184199</td>\n",
       "      <td>0.500704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.236516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5</td>\n",
       "      <td>-12.3750</td>\n",
       "      <td>-11.9375</td>\n",
       "      <td>-13.8750</td>\n",
       "      <td>-14.0000</td>\n",
       "      <td>-12.8125</td>\n",
       "      <td>-12.3125</td>\n",
       "      <td>-12.9375</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.420990</td>\n",
       "      <td>0.060649</td>\n",
       "      <td>0.053523</td>\n",
       "      <td>0.175495</td>\n",
       "      <td>0.289342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5</td>\n",
       "      <td>-12.2500</td>\n",
       "      <td>-12.3125</td>\n",
       "      <td>-14.3125</td>\n",
       "      <td>-14.5625</td>\n",
       "      <td>-13.3125</td>\n",
       "      <td>-12.6250</td>\n",
       "      <td>-13.7500</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.427309</td>\n",
       "      <td>0.057830</td>\n",
       "      <td>0.045038</td>\n",
       "      <td>0.157198</td>\n",
       "      <td>0.312626</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.427309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5</td>\n",
       "      <td>-11.7500</td>\n",
       "      <td>-11.3125</td>\n",
       "      <td>-13.6250</td>\n",
       "      <td>-13.8750</td>\n",
       "      <td>-12.9375</td>\n",
       "      <td>-12.5000</td>\n",
       "      <td>-13.4375</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.595941</td>\n",
       "      <td>0.059006</td>\n",
       "      <td>0.045954</td>\n",
       "      <td>0.117348</td>\n",
       "      <td>0.181752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.595941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5</td>\n",
       "      <td>-12.0000</td>\n",
       "      <td>-11.8750</td>\n",
       "      <td>-14.0625</td>\n",
       "      <td>-14.5625</td>\n",
       "      <td>-13.7500</td>\n",
       "      <td>-13.2500</td>\n",
       "      <td>-14.5000</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.630341</td>\n",
       "      <td>0.070722</td>\n",
       "      <td>0.042895</td>\n",
       "      <td>0.096666</td>\n",
       "      <td>0.159375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.630341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5</td>\n",
       "      <td>-12.1875</td>\n",
       "      <td>-11.9375</td>\n",
       "      <td>-14.0625</td>\n",
       "      <td>-14.5000</td>\n",
       "      <td>-14.0625</td>\n",
       "      <td>-13.3750</td>\n",
       "      <td>-14.6250</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.643708</td>\n",
       "      <td>0.076880</td>\n",
       "      <td>0.049637</td>\n",
       "      <td>0.076880</td>\n",
       "      <td>0.152894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.643708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5</td>\n",
       "      <td>-12.2500</td>\n",
       "      <td>-11.9375</td>\n",
       "      <td>-14.1875</td>\n",
       "      <td>-14.3750</td>\n",
       "      <td>-14.0625</td>\n",
       "      <td>-13.0000</td>\n",
       "      <td>-14.6250</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.603208</td>\n",
       "      <td>0.063578</td>\n",
       "      <td>0.052708</td>\n",
       "      <td>0.072043</td>\n",
       "      <td>0.208463</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5</td>\n",
       "      <td>-11.7500</td>\n",
       "      <td>-11.0625</td>\n",
       "      <td>-13.5000</td>\n",
       "      <td>-13.8125</td>\n",
       "      <td>-13.3750</td>\n",
       "      <td>-12.1250</td>\n",
       "      <td>-14.3750</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.626601</td>\n",
       "      <td>0.054752</td>\n",
       "      <td>0.040057</td>\n",
       "      <td>0.062042</td>\n",
       "      <td>0.216548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5</td>\n",
       "      <td>-13.0625</td>\n",
       "      <td>-13.0625</td>\n",
       "      <td>-14.5625</td>\n",
       "      <td>-15.5625</td>\n",
       "      <td>-14.8125</td>\n",
       "      <td>-13.8125</td>\n",
       "      <td>-15.6250</td>\n",
       "      <td>bloomz-7b1</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PG scale</td>\n",
       "      <td>0.512464</td>\n",
       "      <td>0.114346</td>\n",
       "      <td>0.042066</td>\n",
       "      <td>0.089053</td>\n",
       "      <td>0.242071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.512464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    human_number        0        1        2        3        4        5  \\\n",
       "0              1 -12.7500 -13.1875 -14.8750 -14.6250 -14.8750 -14.6875   \n",
       "1              5 -11.6875 -10.8750 -11.8125 -12.2500 -12.3125 -11.1250   \n",
       "2              5 -15.4375 -13.5625 -12.8750 -14.8750 -15.6875 -14.3750   \n",
       "3              5 -13.1875 -12.3125 -13.4375 -13.0000 -12.5625 -12.9375   \n",
       "4              5 -13.2500 -12.8750 -14.3750 -14.0000 -12.3125 -12.0625   \n",
       "5              5 -12.1250 -12.4375 -14.0000 -14.0000 -13.0000 -11.3750   \n",
       "6              5 -12.0625 -11.9375 -13.8125 -13.8750 -13.0000 -11.8125   \n",
       "7              5 -11.8750 -11.5625 -13.4375 -13.6875 -12.7500 -12.0000   \n",
       "8              5 -11.8750 -12.0000 -13.8750 -14.2500 -13.1875 -12.3125   \n",
       "9              5 -11.5625 -11.1875 -13.3125 -13.6875 -12.8750 -12.3125   \n",
       "10             5 -11.8125 -11.8750 -13.9375 -14.5000 -13.7500 -13.1875   \n",
       "11             4 -12.5625 -12.4375 -14.2500 -15.2500 -15.1875 -14.0000   \n",
       "12             5 -12.4375 -12.1250 -14.0625 -14.5625 -14.4375 -13.1875   \n",
       "13             5 -11.7500 -11.3750 -13.4375 -14.0625 -13.6250 -12.5625   \n",
       "14             5 -13.3125 -13.1875 -14.8750 -15.8125 -15.0625 -13.8750   \n",
       "15             5 -13.0000 -13.1875 -14.8750 -15.8750 -15.3125 -13.9375   \n",
       "16             5 -13.4375 -13.5625 -15.3750 -16.1250 -15.7500 -14.3750   \n",
       "17             5 -13.0625 -13.6875 -15.6875 -16.1250 -15.8750 -14.2500   \n",
       "18             5 -13.0625 -13.0625 -14.9375 -15.5625 -14.9375 -13.9375   \n",
       "19             5 -12.4375 -12.7500 -14.5625 -15.7500 -14.6875 -13.7500   \n",
       "20             0 -13.1875 -14.0000 -17.6250 -18.6250 -18.2500 -18.0000   \n",
       "21             0 -12.3750 -12.9375 -16.1250 -17.6250 -17.2500 -16.6250   \n",
       "22             0 -11.2500 -11.5000 -14.3125 -15.9375 -15.5000 -15.2500   \n",
       "23             1 -12.0625 -11.3125 -14.4375 -15.3750 -14.8125 -14.6875   \n",
       "24             1 -14.0000 -14.1250 -16.0000 -16.2500 -16.3750 -15.3750   \n",
       "25             2 -13.1875 -13.6250 -14.9375 -15.3125 -15.4375 -15.0625   \n",
       "26             0 -15.5000 -15.3750 -17.3750 -18.2500 -18.0000 -18.1250   \n",
       "27             0 -14.6250 -14.5625 -16.0000 -16.0000 -15.6250 -16.1250   \n",
       "28             0 -14.8125 -14.9375 -16.8750 -16.7500 -17.2500 -18.1250   \n",
       "29             0 -15.0000 -14.3125 -16.3750 -16.5000 -16.3750 -16.5000   \n",
       "30             0 -14.5000 -14.0000 -16.5000 -16.2500 -16.2500 -17.0000   \n",
       "31             1 -14.0625 -12.7500 -15.1875 -15.4375 -14.8750 -15.8125   \n",
       "32             2 -11.9375 -13.4375 -13.6250 -14.1250 -14.1875 -13.6875   \n",
       "33             2 -12.7500 -14.3750 -15.0625 -15.0000 -15.0000 -14.9375   \n",
       "34             2 -11.9375 -13.4375 -13.6250 -14.1250 -14.1875 -13.6875   \n",
       "35             1 -12.7500 -13.1875 -14.8750 -14.6250 -14.8750 -14.6875   \n",
       "36             5 -11.6875 -10.8750 -11.8125 -12.2500 -12.3125 -11.1250   \n",
       "37             5 -15.4375 -13.5625 -12.8750 -14.8750 -15.6875 -14.3750   \n",
       "38             5 -13.1875 -12.3125 -13.4375 -13.0000 -12.5625 -12.9375   \n",
       "39             5 -13.2500 -12.8750 -14.3750 -14.0000 -12.3125 -12.0625   \n",
       "40             2 -11.7500 -12.1250 -14.1875 -14.1250 -12.6250 -11.4375   \n",
       "41             5 -13.0625 -12.8125 -14.8125 -14.4375 -13.0625 -12.0625   \n",
       "42             5 -12.3750 -11.9375 -13.8750 -14.0000 -12.8125 -12.3125   \n",
       "43             5 -12.2500 -12.3125 -14.3125 -14.5625 -13.3125 -12.6250   \n",
       "44             5 -11.7500 -11.3125 -13.6250 -13.8750 -12.9375 -12.5000   \n",
       "45             5 -12.0000 -11.8750 -14.0625 -14.5625 -13.7500 -13.2500   \n",
       "46             5 -12.1875 -11.9375 -14.0625 -14.5000 -14.0625 -13.3750   \n",
       "47             5 -12.2500 -11.9375 -14.1875 -14.3750 -14.0625 -13.0000   \n",
       "48             5 -11.7500 -11.0625 -13.5000 -13.8125 -13.3750 -12.1250   \n",
       "49             5 -13.0625 -13.0625 -14.5625 -15.5625 -14.8125 -13.8125   \n",
       "\n",
       "          6       model  item  ...  flipped  experiment    prob_1    prob_2  \\\n",
       "0  -15.1875  bloomz-7b1     1  ...     True    PG scale  0.843895  0.156105   \n",
       "1  -12.7500  bloomz-7b1     2  ...     True    PG scale  0.375832  0.147178   \n",
       "2  -16.2500  bloomz-7b1     3  ...     True    PG scale  0.261707  0.520467   \n",
       "3  -15.3125  bloomz-7b1     4  ...     True    PG scale  0.318315  0.103342   \n",
       "4  -15.0625  bloomz-7b1     5  ...     True    PG scale  0.179974  0.040158   \n",
       "5  -12.8125  bloomz-7b1     6  ...     True    PG scale  0.204809  0.042930   \n",
       "6  -12.4375  bloomz-7b1     7  ...     True    PG scale  0.360210  0.055240   \n",
       "7  -12.5625  bloomz-7b1     8  ...     True    PG scale  0.449758  0.068973   \n",
       "8  -13.3750  bloomz-7b1     9  ...     True    PG scale  0.435663  0.066811   \n",
       "9  -13.1875  bloomz-7b1    10  ...     True    PG scale  0.584402  0.069797   \n",
       "10 -14.3125  bloomz-7b1    11  ...     True    PG scale  0.616494  0.078378   \n",
       "11 -15.4375  bloomz-7b1    12  ...     True    PG scale  0.668074  0.109060   \n",
       "12 -14.8125  bloomz-7b1    13  ...     True    PG scale  0.596642  0.085954   \n",
       "13 -14.5625  bloomz-7b1    14  ...     True    PG scale  0.622832  0.079184   \n",
       "14 -15.8125  bloomz-7b1    15  ...     True    PG scale  0.522573  0.096666   \n",
       "15 -15.6250  bloomz-7b1    16  ...     True    PG scale  0.542055  0.100270   \n",
       "16 -15.6875  bloomz-7b1    17  ...     True    PG scale  0.556699  0.090879   \n",
       "17 -15.8750  bloomz-7b1    18  ...     True    PG scale  0.525019  0.071054   \n",
       "18 -15.5000  bloomz-7b1    19  ...     True    PG scale  0.553815  0.084930   \n",
       "19 -15.5000  bloomz-7b1    20  ...     True    PG scale  0.579718  0.094636   \n",
       "20 -18.0000  bloomz-7b1    21  ...     True    PG scale  0.307358       NaN   \n",
       "21 -17.2500  bloomz-7b1    22  ...     True    PG scale  0.362969       NaN   \n",
       "22 -15.8750  bloomz-7b1    23  ...     True    PG scale  0.437823       NaN   \n",
       "23 -15.4375  bloomz-7b1    24  ...     True    PG scale  0.679179       NaN   \n",
       "24 -15.4375  bloomz-7b1    25  ...     True    PG scale  0.517106  0.079301   \n",
       "25 -14.7500  bloomz-7b1    26  ...     True    PG scale  0.787931  0.212069   \n",
       "26 -18.0000  bloomz-7b1    27  ...     True    PG scale  0.531209       NaN   \n",
       "27 -16.1250  bloomz-7b1    28  ...     True    PG scale  0.515620       NaN   \n",
       "28 -18.1250  bloomz-7b1    29  ...     True    PG scale  0.468791       NaN   \n",
       "29 -17.6250  bloomz-7b1    30  ...     True    PG scale  0.665411       NaN   \n",
       "30 -16.6250  bloomz-7b1    31  ...     True    PG scale  0.622459       NaN   \n",
       "31 -16.2500  bloomz-7b1    32  ...     True    PG scale  0.787931       NaN   \n",
       "32 -14.0000  bloomz-7b1     1  ...     True    PG scale  0.546738  0.453262   \n",
       "33 -15.5000  bloomz-7b1     1  ...    False    PG scale  0.665411  0.334589   \n",
       "34 -14.0000  bloomz-7b1     1  ...     True    PG scale  0.546738  0.453262   \n",
       "35 -15.1875  bloomz-7b1     1  ...     True    PG scale  0.843895  0.156105   \n",
       "36 -12.7500  bloomz-7b1     2  ...     True    PG scale  0.375832  0.147178   \n",
       "37 -16.2500  bloomz-7b1     3  ...     True    PG scale  0.261707  0.520467   \n",
       "38 -15.3125  bloomz-7b1     4  ...     True    PG scale  0.318315  0.103342   \n",
       "39 -15.0625  bloomz-7b1     5  ...     True    PG scale  0.179974  0.040158   \n",
       "40 -13.7500  bloomz-7b1     6  ...     True    PG scale  0.259219  0.032956   \n",
       "41 -13.0625  bloomz-7b1     7  ...     True    PG scale  0.236516  0.032009   \n",
       "42 -12.9375  bloomz-7b1     8  ...     True    PG scale  0.420990  0.060649   \n",
       "43 -13.7500  bloomz-7b1     9  ...     True    PG scale  0.427309  0.057830   \n",
       "44 -13.4375  bloomz-7b1    10  ...     True    PG scale  0.595941  0.059006   \n",
       "45 -14.5000  bloomz-7b1    11  ...     True    PG scale  0.630341  0.070722   \n",
       "46 -14.6250  bloomz-7b1    12  ...     True    PG scale  0.643708  0.076880   \n",
       "47 -14.6250  bloomz-7b1    13  ...     True    PG scale  0.603208  0.063578   \n",
       "48 -14.3750  bloomz-7b1    14  ...     True    PG scale  0.626601  0.054752   \n",
       "49 -15.6250  bloomz-7b1    15  ...     True    PG scale  0.512464  0.114346   \n",
       "\n",
       "      prob_3    prob_4    prob_5    prob_6    prob_0  prob_pred  \n",
       "0        NaN       NaN       NaN       NaN       NaN   0.156105  \n",
       "1   0.095025  0.089268  0.292698       NaN       NaN   0.375832  \n",
       "2   0.070438  0.031256  0.116132       NaN       NaN   0.261707  \n",
       "3   0.160059  0.247904  0.170382       NaN       NaN   0.318315  \n",
       "4   0.058429  0.315863  0.405577       NaN       NaN   0.179974  \n",
       "5   0.042930  0.116697  0.592634       NaN       NaN   0.204809  \n",
       "6   0.051893  0.124485  0.408171       NaN       NaN   0.360210  \n",
       "7   0.053716  0.137168  0.290385       NaN       NaN   0.449758  \n",
       "8   0.045919  0.132870  0.318738       NaN       NaN   0.435663  \n",
       "9   0.047971  0.108103  0.189727       NaN       NaN   0.584402  \n",
       "10  0.044659  0.094542  0.165927       NaN       NaN   0.616494  \n",
       "11  0.040121  0.042709  0.140036       NaN       NaN   0.109060  \n",
       "12  0.052134  0.059076  0.206194       NaN       NaN   0.596642  \n",
       "13  0.042384  0.065646  0.189953       NaN       NaN   0.622832  \n",
       "14  0.037855  0.080139  0.262766       NaN       NaN   0.522573  \n",
       "15  0.036887  0.064739  0.256049       NaN       NaN   0.542055  \n",
       "16  0.042928  0.062460  0.247034       NaN       NaN   0.556699  \n",
       "17  0.045876  0.058905  0.299147       NaN       NaN   0.525019  \n",
       "18  0.045460  0.084930  0.230864       NaN       NaN   0.553815  \n",
       "19  0.028862  0.083516  0.213266       NaN       NaN   0.579718  \n",
       "20       NaN       NaN       NaN       NaN  0.692642   0.307358  \n",
       "21       NaN       NaN       NaN       NaN  0.637031   0.362969  \n",
       "22       NaN       NaN       NaN       NaN  0.562177   0.437823  \n",
       "23       NaN       NaN       NaN       NaN  0.320821   0.320821  \n",
       "24  0.061760  0.054503  0.148153  0.139177       NaN   0.139177  \n",
       "25       NaN       NaN       NaN       NaN       NaN   0.787931  \n",
       "26       NaN       NaN       NaN       NaN  0.468791   0.531209  \n",
       "27       NaN       NaN       NaN       NaN  0.484380   0.515620  \n",
       "28       NaN       NaN       NaN       NaN  0.531209   0.468791  \n",
       "29       NaN       NaN       NaN       NaN  0.334589   0.665411  \n",
       "30       NaN       NaN       NaN       NaN  0.377541   0.622459  \n",
       "31       NaN       NaN       NaN       NaN  0.212069   0.212069  \n",
       "32       NaN       NaN       NaN       NaN       NaN   0.546738  \n",
       "33       NaN       NaN       NaN       NaN       NaN   0.334589  \n",
       "34       NaN       NaN       NaN       NaN       NaN   0.546738  \n",
       "35       NaN       NaN       NaN       NaN       NaN   0.156105  \n",
       "36  0.095025  0.089268  0.292698       NaN       NaN   0.375832  \n",
       "37  0.070438  0.031256  0.116132       NaN       NaN   0.261707  \n",
       "38  0.160059  0.247904  0.170382       NaN       NaN   0.318315  \n",
       "39  0.058429  0.315863  0.405577       NaN       NaN   0.179974  \n",
       "40  0.035082  0.157224  0.515519       NaN       NaN   0.157224  \n",
       "41  0.046573  0.184199  0.500704       NaN       NaN   0.236516  \n",
       "42  0.053523  0.175495  0.289342       NaN       NaN   0.420990  \n",
       "43  0.045038  0.157198  0.312626       NaN       NaN   0.427309  \n",
       "44  0.045954  0.117348  0.181752       NaN       NaN   0.595941  \n",
       "45  0.042895  0.096666  0.159375       NaN       NaN   0.630341  \n",
       "46  0.049637  0.076880  0.152894       NaN       NaN   0.643708  \n",
       "47  0.052708  0.072043  0.208463       NaN       NaN   0.603208  \n",
       "48  0.040057  0.062042  0.216548       NaN       NaN   0.626601  \n",
       "49  0.042066  0.089053  0.242071       NaN       NaN   0.512464  \n",
       "\n",
       "[50 rows x 21 columns]"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PG_data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "9508ec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mappings for each GABS question:\n",
    "pg_maps = {     \n",
    "    1: {1: 1, 2: 0},                      \n",
    "    2: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    3: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    4: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    5: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    6: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    7: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    8: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    9: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    10: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    11: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    12: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    13: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    14: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    15: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    16: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    17: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    18: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    19: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    20: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "    26: {1: 1, 2: 0}\n",
    "}\n",
    "\n",
    "# Apply mapping row-wise based on item number\n",
    "def recode_pg(row):\n",
    "    mapping = pg_maps.get(row[\"item\"])\n",
    "    if mapping is not None:\n",
    "        return mapping.get(row[\"human_number\"], None)  # None if invalid code\n",
    "    return row[\"human_number\"]  \n",
    "\n",
    "PG_data[\"human_number\"] = PG_data.apply(recode_pg, axis=1)\n",
    "\n",
    "# jetzt ist es konsistent mit Freys df quest_proc (außer an den Items, wo es in der gleichen Skale bei ESS_GABS_ausserh_01-10 plötzlich ?vergessen? wurde bei Frey)\n",
    "# aber meiner Meinung nach müsste man, damit man die Skala in binned factors umwandeln kann, noch alles in die gleiche Richtung bringen,\n",
    "# 1 und 26 sind in falscher Richtung! -> habe ich jetzt gefixt obwohl Abweichung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "c5f8e0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_PG = get_LLM_value_per_item(PG_data)\n",
    "model_item_scores_PG_top_n = get_LLM_value_per_item_top_n(PG_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_PG = model_item_scores_PG.merge(\n",
    "    model_item_scores_PG_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "5e0c6aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_PG], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b01fef",
   "metadata": {},
   "source": [
    "## PRI SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "80602ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (1110624, 13)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "PRI_data = load_dataframes(task_name=\"PRI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "39ee7b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one \n",
    "\n",
    "mask = (PRI_data[\"item\"].isin([1, 3, 5, 7, 9, 11, 13, 15]))\n",
    "PRI_data.loc[mask, \"prob_1\"] = np.exp(PRI_data.loc[mask, \"1\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]))\n",
    "PRI_data.loc[mask, \"prob_2\"] = np.exp(PRI_data.loc[mask, \"2\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]))\n",
    "\n",
    "\n",
    "\n",
    "mask = (PRI_data[\"item\"].isin([2, 4, 6, 8, 10, 12, 14, 16]))\n",
    "PRI_data.loc[mask, \"prob_1\"] = np.exp(PRI_data.loc[mask, \"1\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]) + np.exp(PRI_data.loc[mask, \"3\"]) + np.exp(PRI_data.loc[mask, \"4\"]) + np.exp(PRI_data.loc[mask, \"5\"]) + np.exp(PRI_data.loc[mask, \"6\"]) + np.exp(PRI_data.loc[mask, \"7\"]))\n",
    "PRI_data.loc[mask, \"prob_2\"] = np.exp(PRI_data.loc[mask, \"2\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]) + np.exp(PRI_data.loc[mask, \"3\"]) + np.exp(PRI_data.loc[mask, \"4\"]) + np.exp(PRI_data.loc[mask, \"5\"]) + np.exp(PRI_data.loc[mask, \"6\"]) + np.exp(PRI_data.loc[mask, \"7\"]))\n",
    "PRI_data.loc[mask, \"prob_3\"] = np.exp(PRI_data.loc[mask, \"3\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]) + np.exp(PRI_data.loc[mask, \"3\"]) + np.exp(PRI_data.loc[mask, \"4\"]) + np.exp(PRI_data.loc[mask, \"5\"]) + np.exp(PRI_data.loc[mask, \"6\"]) + np.exp(PRI_data.loc[mask, \"7\"]))\n",
    "PRI_data.loc[mask, \"prob_4\"] = np.exp(PRI_data.loc[mask, \"4\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]) + np.exp(PRI_data.loc[mask, \"3\"]) + np.exp(PRI_data.loc[mask, \"4\"]) + np.exp(PRI_data.loc[mask, \"5\"]) + np.exp(PRI_data.loc[mask, \"6\"]) + np.exp(PRI_data.loc[mask, \"7\"]))\n",
    "PRI_data.loc[mask, \"prob_5\"] = np.exp(PRI_data.loc[mask, \"5\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]) + np.exp(PRI_data.loc[mask, \"3\"]) + np.exp(PRI_data.loc[mask, \"4\"]) + np.exp(PRI_data.loc[mask, \"5\"]) + np.exp(PRI_data.loc[mask, \"6\"]) + np.exp(PRI_data.loc[mask, \"7\"]))\n",
    "PRI_data.loc[mask, \"prob_6\"] = np.exp(PRI_data.loc[mask, \"6\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]) + np.exp(PRI_data.loc[mask, \"3\"]) + np.exp(PRI_data.loc[mask, \"4\"]) + np.exp(PRI_data.loc[mask, \"5\"]) + np.exp(PRI_data.loc[mask, \"6\"]) + np.exp(PRI_data.loc[mask, \"7\"]))\n",
    "PRI_data.loc[mask, \"prob_7\"] = np.exp(PRI_data.loc[mask, \"7\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]) + np.exp(PRI_data.loc[mask, \"3\"]) + np.exp(PRI_data.loc[mask, \"4\"]) + np.exp(PRI_data.loc[mask, \"5\"]) + np.exp(PRI_data.loc[mask, \"6\"]) + np.exp(PRI_data.loc[mask, \"7\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "fe6591f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "PRI_data=filter_pred_prob(PRI_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "0ff04f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (PRI_data[\"flipped\"] == True) & (PRI_data[\"item\"].isin([1, 3, 5, 7, 9, 11, 13, 15]))\n",
    "PRI_data.loc[mask, \"human_number\"] = 3 - PRI_data.loc[mask, \"human_number\"]\n",
    "\n",
    "mask = (PRI_data[\"flipped\"] == True) & (PRI_data[\"item\"].isin([2, 4, 6, 8, 10, 12, 14, 16]))\n",
    "PRI_data.loc[mask, \"human_number\"] = 8 - PRI_data.loc[mask, \"human_number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "d354e93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human_number</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>model</th>\n",
       "      <th>item</th>\n",
       "      <th>...</th>\n",
       "      <th>flipped</th>\n",
       "      <th>experiment</th>\n",
       "      <th>prob_1</th>\n",
       "      <th>prob_2</th>\n",
       "      <th>prob_3</th>\n",
       "      <th>prob_4</th>\n",
       "      <th>prob_5</th>\n",
       "      <th>prob_6</th>\n",
       "      <th>prob_7</th>\n",
       "      <th>prob_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-6.90625</td>\n",
       "      <td>-7.15625</td>\n",
       "      <td>-8.5000</td>\n",
       "      <td>-8.375</td>\n",
       "      <td>-8.0625</td>\n",
       "      <td>-8.3125</td>\n",
       "      <td>-8.31250</td>\n",
       "      <td>gemma-3-27b-it</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PRI scale</td>\n",
       "      <td>0.562177</td>\n",
       "      <td>0.437823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.562177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>-7.28125</td>\n",
       "      <td>-7.65625</td>\n",
       "      <td>-9.1875</td>\n",
       "      <td>-8.750</td>\n",
       "      <td>-8.4375</td>\n",
       "      <td>-9.0000</td>\n",
       "      <td>-7.78125</td>\n",
       "      <td>gemma-3-27b-it</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PRI scale</td>\n",
       "      <td>0.315794</td>\n",
       "      <td>0.217042</td>\n",
       "      <td>0.046939</td>\n",
       "      <td>0.072700</td>\n",
       "      <td>0.099369</td>\n",
       "      <td>0.056619</td>\n",
       "      <td>0.191539</td>\n",
       "      <td>0.315794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-9.25000</td>\n",
       "      <td>-9.43750</td>\n",
       "      <td>-11.1250</td>\n",
       "      <td>-10.875</td>\n",
       "      <td>-10.6875</td>\n",
       "      <td>-11.1250</td>\n",
       "      <td>-10.00000</td>\n",
       "      <td>gemma-3-27b-it</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PRI scale</td>\n",
       "      <td>0.546738</td>\n",
       "      <td>0.453262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.546738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-10.12500</td>\n",
       "      <td>-9.93750</td>\n",
       "      <td>-10.6250</td>\n",
       "      <td>-10.875</td>\n",
       "      <td>-10.5000</td>\n",
       "      <td>-10.6875</td>\n",
       "      <td>-10.68750</td>\n",
       "      <td>gemma-3-27b-it</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PRI scale</td>\n",
       "      <td>0.195619</td>\n",
       "      <td>0.235961</td>\n",
       "      <td>0.118649</td>\n",
       "      <td>0.092404</td>\n",
       "      <td>0.134447</td>\n",
       "      <td>0.111460</td>\n",
       "      <td>0.111460</td>\n",
       "      <td>0.134447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-10.25000</td>\n",
       "      <td>-10.25000</td>\n",
       "      <td>-11.5000</td>\n",
       "      <td>-11.375</td>\n",
       "      <td>-11.1250</td>\n",
       "      <td>-12.1875</td>\n",
       "      <td>-10.87500</td>\n",
       "      <td>gemma-3-27b-it</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PRI scale</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110619</th>\n",
       "      <td>7</td>\n",
       "      <td>-23.25000</td>\n",
       "      <td>-23.75000</td>\n",
       "      <td>-25.5000</td>\n",
       "      <td>-25.125</td>\n",
       "      <td>-24.2500</td>\n",
       "      <td>-25.1250</td>\n",
       "      <td>-26.37500</td>\n",
       "      <td>Qwen2.5-32B-Instruct</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PRI scale</td>\n",
       "      <td>0.411445</td>\n",
       "      <td>0.249554</td>\n",
       "      <td>0.043366</td>\n",
       "      <td>0.063097</td>\n",
       "      <td>0.151362</td>\n",
       "      <td>0.063097</td>\n",
       "      <td>0.018078</td>\n",
       "      <td>0.411445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110620</th>\n",
       "      <td>2</td>\n",
       "      <td>-25.75000</td>\n",
       "      <td>-27.50000</td>\n",
       "      <td>-29.0000</td>\n",
       "      <td>-28.375</td>\n",
       "      <td>-28.5000</td>\n",
       "      <td>-26.1250</td>\n",
       "      <td>-27.37500</td>\n",
       "      <td>Qwen2.5-32B-Instruct</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PRI scale</td>\n",
       "      <td>0.851953</td>\n",
       "      <td>0.148047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.851953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110621</th>\n",
       "      <td>5</td>\n",
       "      <td>-28.87500</td>\n",
       "      <td>-29.87500</td>\n",
       "      <td>-30.8750</td>\n",
       "      <td>-30.250</td>\n",
       "      <td>-29.8750</td>\n",
       "      <td>-29.7500</td>\n",
       "      <td>-31.25000</td>\n",
       "      <td>Qwen2.5-32B-Instruct</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PRI scale</td>\n",
       "      <td>0.379678</td>\n",
       "      <td>0.139676</td>\n",
       "      <td>0.051384</td>\n",
       "      <td>0.095998</td>\n",
       "      <td>0.139676</td>\n",
       "      <td>0.158273</td>\n",
       "      <td>0.035316</td>\n",
       "      <td>0.051384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110622</th>\n",
       "      <td>1</td>\n",
       "      <td>-23.87500</td>\n",
       "      <td>-26.87500</td>\n",
       "      <td>-27.5000</td>\n",
       "      <td>-26.750</td>\n",
       "      <td>-27.2500</td>\n",
       "      <td>-25.2500</td>\n",
       "      <td>-26.62500</td>\n",
       "      <td>Qwen2.5-32B-Instruct</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PRI scale</td>\n",
       "      <td>0.952574</td>\n",
       "      <td>0.047426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110623</th>\n",
       "      <td>6</td>\n",
       "      <td>-30.50000</td>\n",
       "      <td>-31.87500</td>\n",
       "      <td>-33.2500</td>\n",
       "      <td>-31.750</td>\n",
       "      <td>-31.7500</td>\n",
       "      <td>-32.0000</td>\n",
       "      <td>-33.50000</td>\n",
       "      <td>Qwen2.5-32B-Instruct</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>PRI scale</td>\n",
       "      <td>0.462386</td>\n",
       "      <td>0.116910</td>\n",
       "      <td>0.029559</td>\n",
       "      <td>0.132476</td>\n",
       "      <td>0.132476</td>\n",
       "      <td>0.103172</td>\n",
       "      <td>0.023021</td>\n",
       "      <td>0.116910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1110624 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         human_number         1         2        3       4        5        6  \\\n",
       "0                   2  -6.90625  -7.15625  -8.5000  -8.375  -8.0625  -8.3125   \n",
       "1                   7  -7.28125  -7.65625  -9.1875  -8.750  -8.4375  -9.0000   \n",
       "2                   2  -9.25000  -9.43750 -11.1250 -10.875 -10.6875 -11.1250   \n",
       "3                   3 -10.12500  -9.93750 -10.6250 -10.875 -10.5000 -10.6875   \n",
       "4                   2 -10.25000 -10.25000 -11.5000 -11.375 -11.1250 -12.1875   \n",
       "...               ...       ...       ...      ...     ...      ...      ...   \n",
       "1110619             7 -23.25000 -23.75000 -25.5000 -25.125 -24.2500 -25.1250   \n",
       "1110620             2 -25.75000 -27.50000 -29.0000 -28.375 -28.5000 -26.1250   \n",
       "1110621             5 -28.87500 -29.87500 -30.8750 -30.250 -29.8750 -29.7500   \n",
       "1110622             1 -23.87500 -26.87500 -27.5000 -26.750 -27.2500 -25.2500   \n",
       "1110623             6 -30.50000 -31.87500 -33.2500 -31.750 -31.7500 -32.0000   \n",
       "\n",
       "                7                 model  item  ...  flipped  experiment  \\\n",
       "0        -8.31250        gemma-3-27b-it     1  ...     True   PRI scale   \n",
       "1        -7.78125        gemma-3-27b-it     2  ...     True   PRI scale   \n",
       "2       -10.00000        gemma-3-27b-it     3  ...     True   PRI scale   \n",
       "3       -10.68750        gemma-3-27b-it     4  ...     True   PRI scale   \n",
       "4       -10.87500        gemma-3-27b-it     5  ...     True   PRI scale   \n",
       "...           ...                   ...   ...  ...      ...         ...   \n",
       "1110619 -26.37500  Qwen2.5-32B-Instruct    12  ...     True   PRI scale   \n",
       "1110620 -27.37500  Qwen2.5-32B-Instruct    13  ...     True   PRI scale   \n",
       "1110621 -31.25000  Qwen2.5-32B-Instruct    14  ...     True   PRI scale   \n",
       "1110622 -26.62500  Qwen2.5-32B-Instruct    15  ...     True   PRI scale   \n",
       "1110623 -33.50000  Qwen2.5-32B-Instruct    16  ...     True   PRI scale   \n",
       "\n",
       "           prob_1    prob_2    prob_3    prob_4    prob_5    prob_6    prob_7  \\\n",
       "0        0.562177  0.437823       NaN       NaN       NaN       NaN       NaN   \n",
       "1        0.315794  0.217042  0.046939  0.072700  0.099369  0.056619  0.191539   \n",
       "2        0.546738  0.453262       NaN       NaN       NaN       NaN       NaN   \n",
       "3        0.195619  0.235961  0.118649  0.092404  0.134447  0.111460  0.111460   \n",
       "4        0.500000  0.500000       NaN       NaN       NaN       NaN       NaN   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "1110619  0.411445  0.249554  0.043366  0.063097  0.151362  0.063097  0.018078   \n",
       "1110620  0.851953  0.148047       NaN       NaN       NaN       NaN       NaN   \n",
       "1110621  0.379678  0.139676  0.051384  0.095998  0.139676  0.158273  0.035316   \n",
       "1110622  0.952574  0.047426       NaN       NaN       NaN       NaN       NaN   \n",
       "1110623  0.462386  0.116910  0.029559  0.132476  0.132476  0.103172  0.023021   \n",
       "\n",
       "         prob_pred  \n",
       "0         0.562177  \n",
       "1         0.315794  \n",
       "2         0.546738  \n",
       "3         0.134447  \n",
       "4         0.500000  \n",
       "...            ...  \n",
       "1110619   0.411445  \n",
       "1110620   0.851953  \n",
       "1110621   0.051384  \n",
       "1110622   0.047426  \n",
       "1110623   0.116910  \n",
       "\n",
       "[1110624 rows x 21 columns]"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRI_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "7ae95ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_PRI = get_LLM_value_per_item(PRI_data)\n",
    "model_item_scores_PRI_top_n = get_LLM_value_per_item_top_n(PRI_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_PRI = model_item_scores_PRI.merge(\n",
    "    model_item_scores_PRI_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "ffab96f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding task specific categories to save in all data\n",
    "\n",
    "# add item categories\n",
    "item_to_category = {\n",
    "     1: \"decision\", 3: \"decision\", 5: \"decision\", 7: \"decision\", 9: \"decision\", 11: \"decision\", 13: \"decision\", 15: \"decision\",\n",
    "     2: \"certainty\", 4: \"certainty\", 6: \"certainty\", 8: \"certainty\", 10: \"certainty\", 12: \"certainty\", 14: \"certainty\", 16: \"certainty\"\n",
    "}\n",
    "\n",
    "\n",
    "model_item_scores_PRI[\"category\"] = model_item_scores_PRI[\"item\"].map(item_to_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "68281602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_PRI], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d1f8ec",
   "metadata": {},
   "source": [
    "## SOEP SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "2db32d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (486542, 17)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "SOEP_data = load_dataframes(task_name=\"SOEP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "59969196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probabilities out of log-probabilities\n",
    "\n",
    "cols = [str(i) for i in range(1, 12)]\n",
    "# Compute normalized probabilities\n",
    "exp_vals = np.exp(SOEP_data[cols])\n",
    "prob_vals = exp_vals.div(exp_vals.sum(axis=1), axis=0)\n",
    "\n",
    "# Rename columns all at once\n",
    "prob_vals.columns = [f\"prob_{i}\" for i in range(1, 12)]\n",
    "\n",
    "# Join to original dataframe in one step\n",
    "SOEP_data = pd.concat([SOEP_data, prob_vals], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "aaea5af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "SOEP_data=filter_pred_prob(SOEP_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "829772eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (SOEP_data[\"flipped\"] == \"yes\") \n",
    "SOEP_data.loc[mask, \"human_number\"] = 12 - SOEP_data.loc[mask, \"human_number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "2810bbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_SOEP = get_LLM_value_per_item(SOEP_data)\n",
    "model_item_scores_SOEP_top_n = get_LLM_value_per_item_top_n(SOEP_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_SOEP = model_item_scores_SOEP.merge(\n",
    "    model_item_scores_SOEP_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "2d70fee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding task specific categories to save in all data\n",
    "\n",
    "# add item categories\n",
    "item_to_category = {\n",
    "     1: \"SOEP\", 2: \"SOEPdri\", 3: \"SOEPfin\",  4: \"SOEPrec\", 5: \"SOEPocc\",  6: \"SOEPhea\",  7: \"SOEPsoc\"\n",
    "}\n",
    "\n",
    "model_item_scores_SOEP[\"category\"] = model_item_scores_SOEP[\"item\"].map(item_to_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "6ef74f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_SOEP], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919cb194",
   "metadata": {},
   "source": [
    "## SSSV SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "4ee11e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (2776560, 8)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "SSSV_data = load_dataframes(task_name=\"SSSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "dfaf361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one\n",
    "SSSV_data[\"prob_1\"] = np.exp(SSSV_data[\"1\"])/(np.exp(SSSV_data[\"1\"]) + np.exp(SSSV_data[\"2\"]))\n",
    "SSSV_data[\"prob_2\"] = np.exp(SSSV_data[\"2\"])/(np.exp(SSSV_data[\"1\"]) + np.exp(SSSV_data[\"2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "3c2a7fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "SSSV_data=filter_pred_prob(SSSV_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "dd874639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (SSSV_data[\"flipped\"] == True) \n",
    "SSSV_data.loc[mask, \"human_number\"] = 3 - SSSV_data.loc[mask, \"human_number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "7f9e0a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # since several items are reversed in whether they indicate low or high sensation seeking, flip some human answers\n",
    "\n",
    "# reverse_coded = {\n",
    "#      1: True, 2: False, 3: True, 4: False, 5: True, 6: True, 7: False, 8: True, 9: True, 10: False, \n",
    "#      11: False, 12: False, 13: False, 14: True, 15: False, 16: True, 17: True, 18: True, 19: False, 20: False,\n",
    "#      21: False, 22: True, 23: True, 24: True, 25: False, 26: False, 27: False, 28: True, 29: True, 30: False,\n",
    "#      31: False, 32: True, 33: False, 34: True, 35: False, 36: True, 37: False, 38: False, 39: True, 40: False\n",
    "\n",
    "# }\n",
    "\n",
    "\n",
    "# for row in SSSV_data.groupby([\"experiment\", \"model\"]):\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "4a4ec1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_SSSV = get_LLM_value_per_item(SSSV_data)\n",
    "model_item_scores_SSSV_top_n = get_LLM_value_per_item_top_n(SSSV_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_SSSV = model_item_scores_SSSV.merge(\n",
    "    model_item_scores_SSSV_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "91ea4053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.776560e+06\n",
       "mean     1.491352e+00\n",
       "std      4.999253e-01\n",
       "min      1.000000e+00\n",
       "25%      1.000000e+00\n",
       "50%      1.000000e+00\n",
       "75%      2.000000e+00\n",
       "max      2.000000e+00\n",
       "Name: human_number, dtype: float64"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSSV_data[\"human_number\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "d56d1fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1840.000000\n",
       "mean        1.469630\n",
       "std         0.212606\n",
       "min         1.009405\n",
       "25%         1.302924\n",
       "50%         1.490199\n",
       "75%         1.635330\n",
       "max         1.904396\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_item_scores_SSSV[\"score\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "2f7bb971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding task specific categories to save in all data\n",
    "\n",
    "# add item categories\n",
    "item_to_category = {\n",
    "     3: \"SStas\", 11: \"SStas\", 16: \"SStas\", 17: \"SStas\", 20: \"SStas\", 21: \"SStas\", 23: \"SStas\", 28: \"SStas\", 38: \"SStas\", 40: \"SStas\",\n",
    "     4: \"SSexp\", 6: \"SSexp\", 9: \"SSexp\", 10: \"SSexp\", 14: \"SSexp\", 18: \"SSexp\", 19: \"SSexp\", 22: \"SSexp\", 26: \"SSexp\", 37: \"SSexp\",\n",
    "     1: \"SSdis\", 12: \"SSdis\", 13: \"SSdis\", 25: \"SSdis\", 29: \"SSdis\", 30: \"SSdis\", 32: \"SSdis\", 33: \"SSdis\", 35: \"SSdis\", 36: \"SSdis\",\n",
    "     2: \"SSbor\", 5: \"SSbor\", 7: \"SSbor\", 8: \"SSbor\", 15: \"SSbor\", 24: \"SSbor\", 27: \"SSbor\", 31: \"SSbor\", 34: \"SSbor\", 39: \"SSbor\"\n",
    "}\n",
    "\n",
    "reverse_coded = {\n",
    "     1: True, 2: False, 3: True, 4: False, 5: True, 6: True, 7: False, 8: True, 9: True, 10: False, \n",
    "     11: False, 12: False, 13: False, 14: True, 15: False, 16: True, 17: True, 18: True, 19: False, 20: False,\n",
    "     21: False, 22: True, 23: True, 24: True, 25: False, 26: False, 27: False, 28: True, 29: True, 30: False,\n",
    "     31: False, 32: True, 33: False, 34: True, 35: False, 36: True, 37: False, 38: False, 39: True, 40: False\n",
    "\n",
    "}\n",
    "\n",
    "model_item_scores_SSSV[\"category\"] = model_item_scores_SSSV[\"item\"].map(item_to_category)\n",
    "model_item_scores_SSSV[\"reverse_coded\"] = model_item_scores_SSSV[\"item\"].map(reverse_coded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "1540d214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back answers that where reverse coded\n",
    "mask = (model_item_scores_SSSV[\"reverse_coded\"] == True)\n",
    "model_item_scores_SSSV.loc[mask, \"score\"] = 3 - model_item_scores_SSSV.loc[mask, \"score\"]\n",
    "model_item_scores_SSSV.loc[mask, \"score_top_n\"] = 3 - model_item_scores_SSSV.loc[mask, \"score_top_n\"]\n",
    "# drop reverse-coded column (not needed in final data)\n",
    "model_item_scores_SSSV = model_item_scores_SSSV.drop(columns=[\"reverse_coded\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "55c256df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>model</th>\n",
       "      <th>item</th>\n",
       "      <th>score</th>\n",
       "      <th>score_top_n</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>1</td>\n",
       "      <td>0.927946</td>\n",
       "      <td>0.431521</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>2</td>\n",
       "      <td>2.674954</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>3</td>\n",
       "      <td>0.656189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>4</td>\n",
       "      <td>1.163460</td>\n",
       "      <td>0.984894</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>5</td>\n",
       "      <td>0.134567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11817</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>36</td>\n",
       "      <td>1.422210</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>SSdis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>37</td>\n",
       "      <td>1.791699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>SSexp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>38</td>\n",
       "      <td>1.661893</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>SStas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>39</td>\n",
       "      <td>1.570623</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>SSbor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>40</td>\n",
       "      <td>1.577203</td>\n",
       "      <td>1.590000</td>\n",
       "      <td>SStas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11822 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        experiment                      model  item     score  score_top_n  \\\n",
       "0      AUDIT scale  Apertus-70B-Instruct-2509     1  0.927946     0.431521   \n",
       "1      AUDIT scale  Apertus-70B-Instruct-2509     2  2.674954     3.000000   \n",
       "2      AUDIT scale  Apertus-70B-Instruct-2509     3  0.656189     0.000000   \n",
       "3      AUDIT scale  Apertus-70B-Instruct-2509     4  1.163460     0.984894   \n",
       "4      AUDIT scale  Apertus-70B-Instruct-2509     5  0.134567     0.000000   \n",
       "...            ...                        ...   ...       ...          ...   \n",
       "11817   SSSV scale             zephyr-7b-beta    36  1.422210     2.000000   \n",
       "11818   SSSV scale             zephyr-7b-beta    37  1.791699     1.000000   \n",
       "11819   SSSV scale             zephyr-7b-beta    38  1.661893     1.000000   \n",
       "11820   SSSV scale             zephyr-7b-beta    39  1.570623     2.000000   \n",
       "11821   SSSV scale             zephyr-7b-beta    40  1.577203     1.590000   \n",
       "\n",
       "      category  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "...        ...  \n",
       "11817    SSdis  \n",
       "11818    SSexp  \n",
       "11819    SStas  \n",
       "11820    SSbor  \n",
       "11821    SStas  \n",
       "\n",
       "[11822 rows x 6 columns]"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_SSSV], ignore_index=True)\n",
    "all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b140480",
   "metadata": {},
   "source": [
    "# Saving new processed dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "b3a81d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "all_data.to_csv('processed_data/items_per_LLM.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "be7afd59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>model</th>\n",
       "      <th>item</th>\n",
       "      <th>score</th>\n",
       "      <th>score_top_n</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>1</td>\n",
       "      <td>0.927946</td>\n",
       "      <td>0.431521</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>2</td>\n",
       "      <td>2.674954</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>3</td>\n",
       "      <td>0.656189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>4</td>\n",
       "      <td>1.163460</td>\n",
       "      <td>0.984894</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>5</td>\n",
       "      <td>0.134567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11817</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>36</td>\n",
       "      <td>1.422210</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>SSdis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>37</td>\n",
       "      <td>1.791699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>SSexp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>38</td>\n",
       "      <td>1.661893</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>SStas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>39</td>\n",
       "      <td>1.570623</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>SSbor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>40</td>\n",
       "      <td>1.577203</td>\n",
       "      <td>1.590000</td>\n",
       "      <td>SStas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11822 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        experiment                      model  item     score  score_top_n  \\\n",
       "0      AUDIT scale  Apertus-70B-Instruct-2509     1  0.927946     0.431521   \n",
       "1      AUDIT scale  Apertus-70B-Instruct-2509     2  2.674954     3.000000   \n",
       "2      AUDIT scale  Apertus-70B-Instruct-2509     3  0.656189     0.000000   \n",
       "3      AUDIT scale  Apertus-70B-Instruct-2509     4  1.163460     0.984894   \n",
       "4      AUDIT scale  Apertus-70B-Instruct-2509     5  0.134567     0.000000   \n",
       "...            ...                        ...   ...       ...          ...   \n",
       "11817   SSSV scale             zephyr-7b-beta    36  1.422210     2.000000   \n",
       "11818   SSSV scale             zephyr-7b-beta    37  1.791699     1.000000   \n",
       "11819   SSSV scale             zephyr-7b-beta    38  1.661893     1.000000   \n",
       "11820   SSSV scale             zephyr-7b-beta    39  1.570623     2.000000   \n",
       "11821   SSSV scale             zephyr-7b-beta    40  1.577203     1.590000   \n",
       "\n",
       "      category  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "...        ...  \n",
       "11817    SSdis  \n",
       "11818    SSexp  \n",
       "11819    SStas  \n",
       "11820    SSbor  \n",
       "11821    SStas  \n",
       "\n",
       "[11822 rows x 6 columns]"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
