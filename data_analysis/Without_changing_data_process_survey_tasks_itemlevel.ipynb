{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfc545a9",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "Starting point:\n",
    "- 848 datasets (18 tasks per model (minus the NON_IDEAL_OUTPUTS)) with all logprobs for all answer alternatives of each subtask for all ~1.500 participants. \n",
    "\n",
    "What does this script do\n",
    "- Read all survey data sets\n",
    "- normalise log-prob scores so that they are probabilities that sum up to 1 over all answer options\n",
    "- filter out the probability that the LLm assigned to the answer option which the participant actually chose (for each item)\n",
    "- flip back answers where scale was flipped to cope with prompt sensitivity issues\n",
    "- weigh probabiliies with human answers and divide by all probabilities for that item, to have one number (in the realm if not exact the number of the answer alternatives) per item per model\n",
    "- second weighing strategy, where score of model per item is only weighed with top n most likely probabilities that model assigned\n",
    "- for some scales: add subcategories (each item belongs to a subcategory)\n",
    "- for some tasks, but unsure, reverse back some scores that are asked on a reverse scale due to the nature of the task\n",
    "- concat the itemwise scores for each task per model all together in one `all_data` final data frame and save it.\n",
    "\n",
    "Specials:\n",
    "- for every scale I compared the frey materials quest_raw.csv and quest_proc.csv and tried to trace back how they got from one to the other. Then I did the same transformations\n",
    "- therefore, for AUDIT and FTND and some more the scores are mapped onto a different scale (point system depending on given answer) on the `human_number` level (before mapped to LLM assigned probabilities)\n",
    "- ! for other scales the scores might have to be transfered into another point system as well!\n",
    "- ! SSSV must be reversed in some items, I think, but resluts are awful when done!?!?!?!\n",
    "\n",
    "Goal:\n",
    "- first have one value per item per model\n",
    "- then transform those values in \"outcomes\" for each subscale (like Frey did)\n",
    "- Have 36 values per model! (one per (sub-) scale)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2ebc19",
   "metadata": {},
   "source": [
    "## Packages & Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fef727d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import load_dataframes, filter_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d790d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------\n",
    "# Pro Modell × Item die Zähler und Nenner berechnen\n",
    "# ----------------------------------------------------------------------------------------------\n",
    "# - Zähler = Summe von (Antwort * Wahrscheinlichkeit)\n",
    "# - Nenner = Summe von (Wahrscheinlichkeiten)\n",
    "\n",
    "def compute_weighted_score(group):\n",
    "    numerator = (group[\"human_number\"] * group[\"prob_pred\"]).sum()\n",
    "    denominator = group[\"prob_pred\"].sum()\n",
    "    return numerator / denominator if denominator > 0 else None\n",
    "\n",
    "\n",
    "# Funktion für Top-n gewichteten Score\n",
    "def compute_top_n_weighted_score(group, n = 100):\n",
    "    # Sortiere die Zeilen nach Wahrscheinlichkeit absteigend\n",
    "    top_n = group.sort_values(\"prob_pred\", ascending=False).head(n)\n",
    "    # Numerator = Summe von (Antwort * Wahrscheinlichkeit)\n",
    "    numerator = (top_n[\"human_number\"] * top_n[\"prob_pred\"]).sum()\n",
    "    # Denominator = Summe von Wahrscheinlichkeiten der Top n\n",
    "    denominator = top_n[\"prob_pred\"].sum()\n",
    "    return numerator / denominator if denominator > 0 else None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# produce df with one value per model per item --------------------------------------------------\n",
    "# more compact version (that runs faster)\n",
    "def get_LLM_value_per_item(data):\n",
    "    grouped = data.groupby([\"experiment\", \"model\", \"item\"])\n",
    "    score = (grouped[\"human_number\"].apply(lambda x: (x * data.loc[x.index, \"prob_pred\"]).sum())\n",
    "             / grouped[\"prob_pred\"].sum())\n",
    "    return score.reset_index(name=\"score\")\n",
    "\n",
    "# produce df with one value per model per item for top n version --------------------------------------------------\n",
    "def get_LLM_value_per_item_top_n(data):\n",
    "    new_df = (\n",
    "    data.groupby([\"experiment\", \"model\", \"item\"])[[\"human_number\", \"prob_pred\"]]\n",
    "      .apply(compute_top_n_weighted_score)\n",
    "      .reset_index(name=\"score_top_n\")\n",
    "    )\n",
    "    return(new_df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eece353e",
   "metadata": {},
   "source": [
    "## AUDIT SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65a51faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (712264, 11)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "AUDIT_data = load_dataframes(task_name=\"AUDIT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd081b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one (tun so als hätten wir sehr guten Prompt, dann würde LLM nur zwischen möglichen Antwortalternativen aussuchen, da simulieren wir dadurch)\n",
    "mask = (AUDIT_data[\"item\"] == 1)\n",
    "AUDIT_data.loc[mask, \"prob_1\"] = np.exp(AUDIT_data.loc[mask, \"1\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]))\n",
    "AUDIT_data.loc[mask, \"prob_2\"] = np.exp(AUDIT_data.loc[mask, \"2\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]))\n",
    "\n",
    "mask = (AUDIT_data[\"item\"].isin([10, 11]))\n",
    "AUDIT_data.loc[mask, \"prob_1\"] = np.exp(AUDIT_data.loc[mask, \"1\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]))\n",
    "AUDIT_data.loc[mask, \"prob_2\"] = np.exp(AUDIT_data.loc[mask, \"2\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]))\n",
    "AUDIT_data.loc[mask, \"prob_3\"] = np.exp(AUDIT_data.loc[mask, \"3\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]))\n",
    "\n",
    "\n",
    "mask = (AUDIT_data[\"item\"].isin([2, 3, 4, 5, 6, 7, 8, 9]))\n",
    "AUDIT_data.loc[mask, \"prob_1\"] = np.exp(AUDIT_data.loc[mask, \"1\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]) + np.exp(AUDIT_data.loc[mask, \"4\"]) + np.exp(AUDIT_data.loc[mask, \"5\"]))\n",
    "AUDIT_data.loc[mask, \"prob_2\"] = np.exp(AUDIT_data.loc[mask, \"2\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]) + np.exp(AUDIT_data.loc[mask, \"4\"]) + np.exp(AUDIT_data.loc[mask, \"5\"]))\n",
    "AUDIT_data.loc[mask, \"prob_3\"] = np.exp(AUDIT_data.loc[mask, \"3\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]) + np.exp(AUDIT_data.loc[mask, \"4\"]) + np.exp(AUDIT_data.loc[mask, \"5\"]))\n",
    "AUDIT_data.loc[mask, \"prob_4\"] = np.exp(AUDIT_data.loc[mask, \"4\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]) + np.exp(AUDIT_data.loc[mask, \"4\"]) + np.exp(AUDIT_data.loc[mask, \"5\"]))\n",
    "AUDIT_data.loc[mask, \"prob_5\"] = np.exp(AUDIT_data.loc[mask, \"5\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]) + np.exp(AUDIT_data.loc[mask, \"4\"]) + np.exp(AUDIT_data.loc[mask, \"5\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b52a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "AUDIT_data=filter_pred_prob(AUDIT_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1421f934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # flip back human answers where they were flipped\n",
    "# mask = (AUDIT_data[\"flipped\"] == \"yes\") & (AUDIT_data[\"item\"] == 1)\n",
    "# AUDIT_data.loc[mask, \"human_number\"] = 3 - AUDIT_data.loc[mask, \"human_number\"]\n",
    "# mask = (AUDIT_data[\"flipped\"] == \"yes\") & (AUDIT_data[\"item\"].isin([10, 11]))\n",
    "# AUDIT_data.loc[mask, \"human_number\"] = 4 - AUDIT_data.loc[mask, \"human_number\"]\n",
    "# mask = (AUDIT_data[\"flipped\"] == \"yes\") & (AUDIT_data[\"item\"].isin([2, 3, 4, 5, 6, 7, 8, 9]))\n",
    "# AUDIT_data.loc[mask, \"human_number\"] = 6 - AUDIT_data.loc[mask, \"human_number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a81387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define mappings for each AUDIT question:\n",
    "# audit_maps = {\n",
    "#     1: {1: 1, 2: 0},                            # AlcSplit\n",
    "#     2: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4},          # AUDIT_1 (in proc data Frey)\n",
    "#     3: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4},          # AUDIT_2 (in proc data Frey)\n",
    "#     4: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4},          # AUDIT_3 (in proc data Frey)\n",
    "#     5: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4},          # AUDIT_4 (in proc data Frey)\n",
    "#     6: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4},          # AUDIT_5 (in proc data Frey)\n",
    "#     7: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4},          # AUDIT_6 (in proc data Frey)\n",
    "#     8: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4},          # AUDIT_7 (in proc data Frey)\n",
    "#     9: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4},          # AUDIT_8 (in proc data Frey)\n",
    "#     10: {1: 0, 2: 2, 3: 4},                     # AUDIT_10 (in proc data Frey)\n",
    "#     11: {1: 0, 2: 2, 3: 4},                     # AUDIT_11 (in proc data Frey)\n",
    "\n",
    "# }\n",
    "\n",
    "# # Apply mapping row-wise based on item number\n",
    "# def recode_audit(row):\n",
    "#     mapping = audit_maps.get(row[\"item\"])\n",
    "#     if mapping is not None:\n",
    "#         return mapping.get(row[\"human_number\"], None)  # None if invalid code\n",
    "#     return row[\"human_number\"]  \n",
    "\n",
    "# AUDIT_data[\"human_number\"] = AUDIT_data.apply(recode_audit, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0d05126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_AUDIT = get_LLM_value_per_item(AUDIT_data)\n",
    "model_item_scores_AUDIT_top_n = get_LLM_value_per_item_top_n(AUDIT_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_AUDIT = model_item_scores_AUDIT.merge(\n",
    "    model_item_scores_AUDIT_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d65688",
   "metadata": {},
   "source": [
    "## BARRAT SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc730c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (2082420, 10)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "BARRAT_data = load_dataframes(task_name=\"BARRAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b88e1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one\n",
    "BARRAT_data[\"prob_1\"] = np.exp(BARRAT_data[\"1\"])/(np.exp(BARRAT_data[\"1\"]) + np.exp(BARRAT_data[\"2\"]) + np.exp(BARRAT_data[\"3\"]) + np.exp(BARRAT_data[\"4\"]))\n",
    "BARRAT_data[\"prob_2\"] = np.exp(BARRAT_data[\"2\"])/(np.exp(BARRAT_data[\"1\"]) + np.exp(BARRAT_data[\"2\"]) + np.exp(BARRAT_data[\"3\"]) + np.exp(BARRAT_data[\"4\"]))\n",
    "BARRAT_data[\"prob_3\"] = np.exp(BARRAT_data[\"3\"])/(np.exp(BARRAT_data[\"1\"]) + np.exp(BARRAT_data[\"2\"]) + np.exp(BARRAT_data[\"3\"]) + np.exp(BARRAT_data[\"4\"]))\n",
    "BARRAT_data[\"prob_4\"] = np.exp(BARRAT_data[\"4\"])/(np.exp(BARRAT_data[\"1\"]) + np.exp(BARRAT_data[\"2\"]) + np.exp(BARRAT_data[\"3\"]) + np.exp(BARRAT_data[\"4\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9945c979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "BARRAT_data=filter_pred_prob(BARRAT_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29d02886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # flip back human answers where they were flipped\n",
    "# mask = (BARRAT_data[\"flipped\"] == True)\n",
    "# BARRAT_data.loc[mask, \"human_number\"] = 5 - BARRAT_data.loc[mask, \"human_number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d415b71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reverse human answers (again) where the items where reversed phrased\n",
    "\n",
    "# # add whether item was reverse coded\n",
    "# reverse_coded = {\n",
    "#     1: True, 2: False, 3: False,  4: False, 5: False,  6: False,  7: True,  8: True,  9: True,  10: True,\n",
    "#     11: False, 12: True, 13: True,  14: False, 15: True,  16: False,  17: False,  18: False,  19: False,  20: True,\n",
    "#     21: False, 22: False, 23: False,  24: False, 25: False,  26: False,  27: False,  28: False,  29: True,  30: True\n",
    "#     }\n",
    "\n",
    "# # Apply mapping row-wise based on item number\n",
    "# BARRAT_data[\"reverse_coded\"] = BARRAT_data[\"item\"].map(reverse_coded)\n",
    "\n",
    "\n",
    "# # flip back answers that where reverse coded\n",
    "# mask = (BARRAT_data[\"reverse_coded\"] == True)\n",
    "# BARRAT_data.loc[mask, \"human_number\"] = 5 - BARRAT_data.loc[mask, \"human_number\"]\n",
    "# # drop reverse-coded column (not needed in final data)\n",
    "# BARRAT_data = BARRAT_data.drop(columns=[\"reverse_coded\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3100efef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_BARRAT = get_LLM_value_per_item(BARRAT_data)\n",
    "model_item_scores_BARRAT_top_n = get_LLM_value_per_item_top_n(BARRAT_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_BARRAT = model_item_scores_BARRAT.merge(\n",
    "    model_item_scores_BARRAT_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38eda3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding task specific categories to save in all data\n",
    "\n",
    "# add item categories\n",
    "item_to_category = {\n",
    "    1: \"BISn\", 2: \"BISm\", 3: \"BISm\",  4: \"BISm\", 5: \"BISa\",  6: \"BISa\",  7: \"BISn\",  8: \"BISn\",  9: \"BISa\",  10: \"BISn\",\n",
    "    11: \"BISa\", 12: \"BISn\", 13: \"BISn\",  14: \"BISn\", 15: \"BISn\",  16: \"BISm\",  17: \"BISm\",  18: \"BISn\",  19: \"BISm\",  20: \"BISa\",\n",
    "    21: \"BISm\", 22: \"BISm\", 23: \"BISm\",  24: \"BISa\", 25: \"BISm\",  26: \"BISa\",  27: \"BISn\",  28: \"BISa\",  29: \"BISn\",  30: \"BISm\"\n",
    "}\n",
    "\n",
    "model_item_scores_BARRAT[\"category\"] = model_item_scores_BARRAT[\"item\"].map(item_to_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ddb9972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([model_item_scores_AUDIT, model_item_scores_BARRAT], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0226ac",
   "metadata": {},
   "source": [
    "## CARE TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1491661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (1320614, 106)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "CARE_data = load_dataframes(task_name=\"CARE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d59c8fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probabilities out of log-probabilities\n",
    "\n",
    "cols = [str(i) for i in range(0, 100)]\n",
    "# Compute normalized probabilities\n",
    "exp_vals = np.exp(CARE_data[cols])\n",
    "prob_vals = exp_vals.div(exp_vals.sum(axis=1), axis=0)\n",
    "\n",
    "# Rename columns all at once\n",
    "prob_vals.columns = [f\"prob_{i}\" for i in range(0, 100)]\n",
    "\n",
    "# Join to original dataframe in one step\n",
    "CARE_data = pd.concat([CARE_data, prob_vals], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a389bebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "CARE_data=filter_pred_prob(CARE_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "914d1030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_CARE = get_LLM_value_per_item(CARE_data)\n",
    "model_item_scores_CARE_top_n = get_LLM_value_per_item_top_n(CARE_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_CARE = model_item_scores_CARE.merge(\n",
    "    model_item_scores_CARE_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a344c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding task specific categories to save in all data\n",
    "# add item categories\n",
    "item_to_category = {\n",
    "    1: \"CAREa\", 2: \"CAREa\", 3: \"CAREa\",  4: \"CAREa\", 5: \"CAREa\",  6: \"CAREa\",  7: \"CAREa\",  8: \"CAREa\",  9: \"CAREa\",  10: \"CAREs\",\n",
    "    11: \"CAREs\", 12: \"CAREs\", 13: \"CAREs\",  14: \"CAREs\", 15: \"CAREs\",  16: \"CAREw\",  17: \"CAREw\",  18: \"CAREw\",  19: \"CAREw\"\n",
    "}\n",
    "\n",
    "model_item_scores_CARE[\"category\"] = model_item_scores_CARE[\"item\"].map(item_to_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8720af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([all_data, model_item_scores_CARE], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1623f7ae",
   "metadata": {},
   "source": [
    "## DAST SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1e720e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (1391040, 8)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "DAST_data = load_dataframes(task_name=\"DAST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acf31561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one \n",
    "DAST_data[\"prob_1\"] = np.exp(DAST_data[\"1\"])/(np.exp(DAST_data[\"1\"]) + np.exp(DAST_data[\"2\"]))\n",
    "DAST_data[\"prob_2\"] = np.exp(DAST_data[\"2\"])/(np.exp(DAST_data[\"1\"]) + np.exp(DAST_data[\"2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6833d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "DAST_data=filter_pred_prob(DAST_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d9b749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # flip back human answers where they were flipped\n",
    "# mask = (DAST_data[\"flipped\"] == True) \n",
    "# DAST_data.loc[mask, \"human_number\"] = 3 - DAST_data.loc[mask, \"human_number\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79db3eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define mappings for each DAST question:\n",
    "# dast_maps = {\n",
    "#     1: {1: 1, 2: 0},                           \n",
    "#     2: {1: 1, 2: 0},\n",
    "#     3: {1: 1, 2: 0},\n",
    "#     4: {1: 0, 2: 1},\n",
    "#     5: {1: 0, 2: 1},\n",
    "#     6: {1: 1, 2: 0},\n",
    "#     7: {1: 1, 2: 0},\n",
    "#     8: {1: 1, 2: 0},\n",
    "#     9: {1: 1, 2: 0},\n",
    "#     10: {1: 1, 2: 0},\n",
    "#     11: {1: 1, 2: 0},\n",
    "#     12: {1: 1, 2: 0},\n",
    "#     13: {1: 1, 2: 0},\n",
    "#     14: {1: 1, 2: 0},\n",
    "#     15: {1: 1, 2: 0},\n",
    "#     16: {1: 1, 2: 0},\n",
    "#     17: {1: 1, 2: 0},\n",
    "#     18: {1: 1, 2: 0},\n",
    "#     19: {1: 1, 2: 0},\n",
    "#     20: {1: 1, 2: 0}\n",
    "# }\n",
    "\n",
    "# # Apply mapping row-wise based on item number\n",
    "# def recode_dast(row):\n",
    "#     mapping = dast_maps.get(row[\"item\"])\n",
    "#     if mapping is not None:\n",
    "#         return mapping.get(row[\"human_number\"], None)  # None if invalid code\n",
    "#     return row[\"human_number\"]  \n",
    "\n",
    "# DAST_data[\"human_number\"] = DAST_data.apply(recode_dast, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "806cd5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_DAST = get_LLM_value_per_item(DAST_data)\n",
    "model_item_scores_DAST_top_n = get_LLM_value_per_item_top_n(DAST_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_DAST = model_item_scores_DAST.merge(\n",
    "    model_item_scores_DAST_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54525c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_DAST], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a376a9e9",
   "metadata": {},
   "source": [
    "## DM SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a50dd425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (1318866, 10)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "DM_data = load_dataframes(task_name=\"DM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8a1b71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one\n",
    "DM_data[\"prob_1\"] = np.exp(DM_data[\"1\"])/(np.exp(DM_data[\"1\"]) + np.exp(DM_data[\"2\"]) + np.exp(DM_data[\"3\"]) + np.exp(DM_data[\"4\"]))\n",
    "DM_data[\"prob_2\"] = np.exp(DM_data[\"2\"])/(np.exp(DM_data[\"1\"]) + np.exp(DM_data[\"2\"]) + np.exp(DM_data[\"3\"]) + np.exp(DM_data[\"4\"]))\n",
    "DM_data[\"prob_3\"] = np.exp(DM_data[\"3\"])/(np.exp(DM_data[\"1\"]) + np.exp(DM_data[\"2\"]) + np.exp(DM_data[\"3\"]) + np.exp(DM_data[\"4\"]))\n",
    "DM_data[\"prob_4\"] = np.exp(DM_data[\"4\"])/(np.exp(DM_data[\"1\"]) + np.exp(DM_data[\"2\"]) + np.exp(DM_data[\"3\"]) + np.exp(DM_data[\"4\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b778d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "DM_data=filter_pred_prob(DM_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22d0cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # flip back human answers where they were flipped\n",
    "# mask = (DM_data[\"flipped\"] == True) \n",
    "# DM_data.loc[mask, \"human_number\"] = 5 - DM_data.loc[mask, \"human_number\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0d4d183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define mappings for DM, so that all 4s are transformed to 1s (like in original Fey dataset):\n",
    "# # hier Abweichung von sonst Orientierung an Frey quest_proc df, aber da sonst später Umwandlung, hier gleich zu Scale 0-2\n",
    "# mapping = {\n",
    "#     4: 1,\n",
    "#     3: 2,\n",
    "#     2: 1,\n",
    "#     1: 0\n",
    "# }\n",
    "# DM_data[\"human_number\"] = DM_data[\"human_number\"].map(mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb8e201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_DM = get_LLM_value_per_item(DM_data)\n",
    "model_item_scores_DM_top_n = get_LLM_value_per_item_top_n(DM_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_DM = model_item_scores_DM.merge(\n",
    "    model_item_scores_DM_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "125ae7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_DM], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf36e830",
   "metadata": {},
   "source": [
    "## DOSPERT SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4828b1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (2780240, 11)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "DOSPERT_data = load_dataframes(task_name=\"DOSPERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df6de3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one\n",
    "DOSPERT_data[\"prob_1\"] = np.exp(DOSPERT_data[\"1\"])/(np.exp(DOSPERT_data[\"1\"]) + np.exp(DOSPERT_data[\"2\"]) + np.exp(DOSPERT_data[\"3\"]) + np.exp(DOSPERT_data[\"4\"]) + np.exp(DOSPERT_data[\"5\"]))\n",
    "DOSPERT_data[\"prob_2\"] = np.exp(DOSPERT_data[\"2\"])/(np.exp(DOSPERT_data[\"1\"]) + np.exp(DOSPERT_data[\"2\"]) + np.exp(DOSPERT_data[\"3\"]) + np.exp(DOSPERT_data[\"4\"]) + np.exp(DOSPERT_data[\"5\"]))\n",
    "DOSPERT_data[\"prob_3\"] = np.exp(DOSPERT_data[\"3\"])/(np.exp(DOSPERT_data[\"1\"]) + np.exp(DOSPERT_data[\"2\"]) + np.exp(DOSPERT_data[\"3\"]) + np.exp(DOSPERT_data[\"4\"]) + np.exp(DOSPERT_data[\"5\"]))\n",
    "DOSPERT_data[\"prob_4\"] = np.exp(DOSPERT_data[\"4\"])/(np.exp(DOSPERT_data[\"1\"]) + np.exp(DOSPERT_data[\"2\"]) + np.exp(DOSPERT_data[\"3\"]) + np.exp(DOSPERT_data[\"4\"]) + np.exp(DOSPERT_data[\"5\"]))\n",
    "DOSPERT_data[\"prob_5\"] = np.exp(DOSPERT_data[\"5\"])/(np.exp(DOSPERT_data[\"1\"]) + np.exp(DOSPERT_data[\"2\"]) + np.exp(DOSPERT_data[\"3\"]) + np.exp(DOSPERT_data[\"4\"]) + np.exp(DOSPERT_data[\"5\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c87c6117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "DOSPERT_data=filter_pred_prob(DOSPERT_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "270ff6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # flip back human answers where they were flipped\n",
    "# mask = (DOSPERT_data[\"flipped\"] == 'yes') \n",
    "# DOSPERT_data.loc[mask, \"human_number\"] = 6 - DOSPERT_data.loc[mask, \"human_number\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a15c7fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_DOSPERT = get_LLM_value_per_item(DOSPERT_data)\n",
    "model_item_scores_DOSPERT_top_n = get_LLM_value_per_item_top_n(DOSPERT_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_DOSPERT = model_item_scores_DOSPERT.merge(\n",
    "    model_item_scores_DOSPERT_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "005799af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding task specific categories to save in all data\n",
    "\n",
    "# add item categories\n",
    "item_to_category = {\n",
    "    1: \"Social\", 10: \"Social\", 16: \"Social\", 19: \"Social\", 23: \"Social\", 26: \"Social\", 34: \"Social\", 35: \"Social\",\n",
    "    2: \"Recreational\", 6: \"Recreational\", 15: \"Recreational\", 17: \"Recreational\", 21: \"Recreational\", 31: \"Recreational\", 37: \"Recreational\", 38: \"Recreational\",\n",
    "    3: \"Gambling\", 11: \"Gambling\", 22: \"Gambling\", 33: \"Gambling\",\n",
    "    4: \"Health\", 8: \"Health\", 27: \"Health\", 29: \"Health\", 32: \"Health\", 36: \"Health\", 39: \"Health\", 40: \"Health\",\n",
    "    5: \"Ethical\", 9: \"Ethical\", 12: \"Ethical\", 13: \"Ethical\", 14: \"Ethical\", 20: \"Ethical\", 25: \"Ethical\", 28: \"Ethical\",\n",
    "    7: \"Investment\", 18: \"Investment\", 24: \"Investment\", 30: \"Investment\"\n",
    "}\n",
    "\n",
    "model_item_scores_DOSPERT[\"category\"] = model_item_scores_DOSPERT[\"item\"].map(item_to_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eae478ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_DOSPERT], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cbad99",
   "metadata": {},
   "source": [
    "## FTND SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b79895fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (163162, 10)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "FTND_data = load_dataframes(task_name=\"FTND\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d512cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one (tun so als hätten wir sehr guten Prompt, dann würde LLM nur zwischen möglichen Antwortalternativen aussuchen, da simulieren wir dadurch)\n",
    "mask = (FTND_data[\"item\"] == 1)\n",
    "FTND_data.loc[mask, \"prob_1\"] = np.exp(FTND_data.loc[mask, \"1\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]) + np.exp(FTND_data.loc[mask, \"3\"]))\n",
    "FTND_data.loc[mask, \"prob_2\"] = np.exp(FTND_data.loc[mask, \"2\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]) + np.exp(FTND_data.loc[mask, \"3\"]))\n",
    "FTND_data.loc[mask, \"prob_3\"] = np.exp(FTND_data.loc[mask, \"3\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]) + np.exp(FTND_data.loc[mask, \"3\"]))\n",
    "\n",
    "mask = (FTND_data[\"item\"].isin([3, 4, 6, 7]))\n",
    "FTND_data.loc[mask, \"prob_1\"] = np.exp(FTND_data.loc[mask, \"1\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]))\n",
    "FTND_data.loc[mask, \"prob_2\"] = np.exp(FTND_data.loc[mask, \"2\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]))\n",
    "\n",
    "mask = (FTND_data[\"item\"].isin([2, 5]))\n",
    "FTND_data.loc[mask, \"prob_1\"] = np.exp(FTND_data.loc[mask, \"1\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]) + np.exp(FTND_data.loc[mask, \"3\"]) + np.exp(FTND_data.loc[mask, \"4\"]))\n",
    "FTND_data.loc[mask, \"prob_2\"] = np.exp(FTND_data.loc[mask, \"2\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]) + np.exp(FTND_data.loc[mask, \"3\"]) + np.exp(FTND_data.loc[mask, \"4\"]))\n",
    "FTND_data.loc[mask, \"prob_3\"] = np.exp(FTND_data.loc[mask, \"3\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]) + np.exp(FTND_data.loc[mask, \"3\"]) + np.exp(FTND_data.loc[mask, \"4\"]))\n",
    "FTND_data.loc[mask, \"prob_4\"] = np.exp(FTND_data.loc[mask, \"4\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]) + np.exp(FTND_data.loc[mask, \"3\"]) + np.exp(FTND_data.loc[mask, \"4\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f407d56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "FTND_data=filter_pred_prob(FTND_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c3668c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # flip back human answers where they were flipped\n",
    "# mask = (FTND_data[\"flipped\"] == True) & (FTND_data[\"item\"] == 1)\n",
    "# FTND_data.loc[mask, \"human_number\"] = 4 - FTND_data.loc[mask, \"human_number\"]\n",
    "# mask = (FTND_data[\"flipped\"] == True) & (FTND_data[\"item\"].isin([3, 4, 6, 7]))\n",
    "# FTND_data.loc[mask, \"human_number\"] = 3 - FTND_data.loc[mask, \"human_number\"]\n",
    "# mask = (FTND_data[\"flipped\"] == True) & (FTND_data[\"item\"].isin([2, 5]))\n",
    "# FTND_data.loc[mask, \"human_number\"] = 5 - FTND_data.loc[mask, \"human_number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "813faab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define mappings for each FTND question:\n",
    "# ftnd_maps = {\n",
    "#     1: {1: 2, 2: 0, 3: 1},             # FTND_1Eingangsfrage: smoke?\n",
    "#     2: {1: 3, 2: 2, 3: 1, 4: 0},       # FTND_1: time until first cigarette\n",
    "#     3: {1: 1, 2: 0},                   # FTND_2: difficult to refrain\n",
    "#     4: {1: 1, 2: 0},                   # FTND_3: which cigarette hardest to give up\n",
    "#     5: {1: 0, 2: 1, 3: 2, 4: 3},       # FTND_4: cigarettes per day\n",
    "#     6: {1: 1, 2: 0},                   # FTND_5: smoke more frequently in morning\n",
    "#     7: {1: 1, 2: 0}                    # FTND_6: smoke when ill\n",
    "# }\n",
    "\n",
    "# # Apply mapping row-wise based on item number\n",
    "# def recode_ftnd(row):\n",
    "#     mapping = ftnd_maps.get(row[\"item\"])\n",
    "#     if mapping is not None:\n",
    "#         return mapping.get(row[\"human_number\"], None) \n",
    "#     return row[\"human_number\"]  \n",
    "\n",
    "# FTND_data[\"human_number\"] = FTND_data.apply(recode_ftnd, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0bf07e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_FTND = get_LLM_value_per_item(FTND_data)\n",
    "model_item_scores_FTND_top_n = get_LLM_value_per_item_top_n(FTND_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_FTND = model_item_scores_FTND.merge(\n",
    "    model_item_scores_FTND_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ce78b07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_FTND], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54306e48",
   "metadata": {},
   "source": [
    "## GABS SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dc20119a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (581210, 10)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "GABS_data = load_dataframes(task_name=\"GABS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8cf18026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one\n",
    "\n",
    "# columns representing log-probabilities\n",
    "answer_cols = [\"1\", \"2\", \"3\", \"4\"]\n",
    "\n",
    "# make a copy to avoid SettingWithCopy warnings\n",
    "GABS_data = GABS_data.copy()\n",
    "\n",
    "# case 1: item == 1 → only options 1 and 2\n",
    "mask_item1 = GABS_data[\"item\"] == 1\n",
    "exp_vals_item1 = np.exp(GABS_data.loc[mask_item1, [\"1\", \"2\"]])\n",
    "probs_item1 = exp_vals_item1.div(exp_vals_item1.sum(axis=1), axis=0)\n",
    "probs_item1.columns = [\"prob_1\", \"prob_2\"]\n",
    "\n",
    "# case 2: items 2–17 → options 1–4\n",
    "mask_item2plus = GABS_data[\"item\"].between(2, 17)\n",
    "exp_vals_item2plus = np.exp(GABS_data.loc[mask_item2plus, answer_cols])\n",
    "probs_item2plus = exp_vals_item2plus.div(exp_vals_item2plus.sum(axis=1), axis=0)\n",
    "probs_item2plus.columns = [f\"prob_{c}\" for c in answer_cols]\n",
    "\n",
    "# merge both parts back into original df\n",
    "GABS_data = GABS_data.join(pd.concat([probs_item1, probs_item2plus]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "45796a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "GABS_data=filter_pred_prob(GABS_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "29b40036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # flip back human answers where they were flipped\n",
    "# mask = (GABS_data[\"flipped\"] == True) & (GABS_data[\"item\"] == 1)\n",
    "# GABS_data.loc[mask, \"human_number\"] = 3 - GABS_data.loc[mask, \"human_number\"]\n",
    "# mask = (GABS_data[\"flipped\"] == True) & (GABS_data[\"item\"].isin(range(2,17)))\n",
    "# GABS_data.loc[mask, \"human_number\"] = 5 - GABS_data.loc[mask, \"human_number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6cb6a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_GABS = get_LLM_value_per_item(GABS_data)\n",
    "model_item_scores_GABS_top_n = get_LLM_value_per_item_top_n(GABS_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_GABS = model_item_scores_GABS.merge(\n",
    "    model_item_scores_GABS_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "abcf63ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_GABS], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed59198",
   "metadata": {},
   "source": [
    "## PG SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e97aa4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (1127322, 13)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "PG_data = load_dataframes(task_name=\"PG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "66851dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one \n",
    "\n",
    "mask = (PG_data[\"item\"].isin([1, 26]))\n",
    "PG_data.loc[mask, \"prob_1\"] = np.exp(PG_data.loc[mask, \"1\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]))\n",
    "PG_data.loc[mask, \"prob_2\"] = np.exp(PG_data.loc[mask, \"2\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]))\n",
    "\n",
    "\n",
    "\n",
    "mask = (PG_data[\"item\"].isin(range(2, 21)))\n",
    "PG_data.loc[mask, \"prob_1\"] = np.exp(PG_data.loc[mask, \"1\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]))\n",
    "PG_data.loc[mask, \"prob_2\"] = np.exp(PG_data.loc[mask, \"2\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]))\n",
    "PG_data.loc[mask, \"prob_3\"] = np.exp(PG_data.loc[mask, \"3\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]))\n",
    "PG_data.loc[mask, \"prob_4\"] = np.exp(PG_data.loc[mask, \"4\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]))\n",
    "PG_data.loc[mask, \"prob_5\"] = np.exp(PG_data.loc[mask, \"5\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]))\n",
    "\n",
    "\n",
    "\n",
    "mask = (PG_data[\"item\"] == 25)\n",
    "PG_data.loc[mask, \"prob_1\"] = np.exp(PG_data.loc[mask, \"1\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]) + np.exp(PG_data.loc[mask, \"6\"]))\n",
    "PG_data.loc[mask, \"prob_2\"] = np.exp(PG_data.loc[mask, \"2\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]) + np.exp(PG_data.loc[mask, \"6\"]))\n",
    "PG_data.loc[mask, \"prob_3\"] = np.exp(PG_data.loc[mask, \"3\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]) + np.exp(PG_data.loc[mask, \"6\"]))\n",
    "PG_data.loc[mask, \"prob_4\"] = np.exp(PG_data.loc[mask, \"4\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]) + np.exp(PG_data.loc[mask, \"6\"]))\n",
    "PG_data.loc[mask, \"prob_5\"] = np.exp(PG_data.loc[mask, \"5\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]) + np.exp(PG_data.loc[mask, \"6\"]))\n",
    "PG_data.loc[mask, \"prob_6\"] = np.exp(PG_data.loc[mask, \"6\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]) + np.exp(PG_data.loc[mask, \"6\"]))\n",
    "\n",
    "\n",
    "mask = (PG_data[\"item\"].isin([21, 22, 23, 24, 27, 28, 29, 30, 31, 32]))\n",
    "PG_data.loc[mask, \"prob_0\"] = np.exp(PG_data.loc[mask, \"0\"])/(np.exp(PG_data.loc[mask, \"0\"]) + np.exp(PG_data.loc[mask, \"1\"]))\n",
    "PG_data.loc[mask, \"prob_1\"] = np.exp(PG_data.loc[mask, \"1\"])/(np.exp(PG_data.loc[mask, \"0\"]) + np.exp(PG_data.loc[mask, \"1\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dfc61164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "PG_data=filter_pred_prob(PG_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66d9d25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # flip back human answers where they were flipped\n",
    "# mask = (PG_data[\"flipped\"] == True) & (PG_data[\"item\"].isin([1, 26]))\n",
    "# PG_data.loc[mask, \"human_number\"] = 3 - PG_data.loc[mask, \"human_number\"]\n",
    "\n",
    "# mask = (PG_data[\"flipped\"] == True) & (PG_data[\"item\"].isin(range(2, 21)))\n",
    "# PG_data.loc[mask, \"human_number\"] = 6 - PG_data.loc[mask, \"human_number\"]\n",
    "\n",
    "# mask = (PG_data[\"flipped\"] == True) & (PG_data[\"item\"] == 25)\n",
    "# PG_data.loc[mask, \"human_number\"] = 7 - PG_data.loc[mask, \"human_number\"]\n",
    "\n",
    "# mask = (PG_data[\"flipped\"] == True) & (PG_data[\"item\"].isin([21, 22, 23, 24, 27, 28, 29, 30, 31, 32]))\n",
    "# PG_data.loc[mask, \"human_number\"] = 1 - PG_data.loc[mask, \"human_number\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9508ec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define mappings for each GABS question:\n",
    "# pg_maps = {     \n",
    "#     1: {1: 1, 2: 0},                      \n",
    "#     2: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "#     3: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "#     4: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "#     5: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "#     6: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "#     7: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "#     8: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "#     9: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "#     10: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "#     11: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "#     12: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "#     13: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "#     14: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "#     15: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "#     16: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "#     17: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "#     18: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "#     19: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "#     20: {1: 4, 2: 3, 3: 2, 4: 1, 5: 0},\n",
    "#     26: {1: 1, 2: 0}\n",
    "# }\n",
    "\n",
    "# # Apply mapping row-wise based on item number\n",
    "# def recode_pg(row):\n",
    "#     mapping = pg_maps.get(row[\"item\"])\n",
    "#     if mapping is not None:\n",
    "#         return mapping.get(row[\"human_number\"], None)  # None if invalid code\n",
    "#     return row[\"human_number\"]  \n",
    "\n",
    "# PG_data[\"human_number\"] = PG_data.apply(recode_pg, axis=1)\n",
    "\n",
    "# # jetzt ist es konsistent mit Freys df quest_proc (außer an den Items, wo es in der gleichen Skale bei ESS_GABS_ausserh_01-10 plötzlich ?vergessen? wurde bei Frey)\n",
    "# # aber meiner Meinung nach müsste man, damit man die Skala in binned factors umwandeln kann, noch alles in die gleiche Richtung bringen,\n",
    "# # 1 und 26 sind in falscher Richtung! -> habe ich jetzt gefixt obwohl Abweichung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c5f8e0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_PG = get_LLM_value_per_item(PG_data)\n",
    "model_item_scores_PG_top_n = get_LLM_value_per_item_top_n(PG_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_PG = model_item_scores_PG.merge(\n",
    "    model_item_scores_PG_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5e0c6aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_PG], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b01fef",
   "metadata": {},
   "source": [
    "## PRI SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "80602ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (1110624, 13)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "PRI_data = load_dataframes(task_name=\"PRI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "39ee7b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one \n",
    "\n",
    "mask = (PRI_data[\"item\"].isin([1, 3, 5, 7, 9, 11, 13, 15]))\n",
    "PRI_data.loc[mask, \"prob_1\"] = np.exp(PRI_data.loc[mask, \"1\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]))\n",
    "PRI_data.loc[mask, \"prob_2\"] = np.exp(PRI_data.loc[mask, \"2\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]))\n",
    "\n",
    "\n",
    "\n",
    "mask = (PRI_data[\"item\"].isin([2, 4, 6, 8, 10, 12, 14, 16]))\n",
    "PRI_data.loc[mask, \"prob_1\"] = np.exp(PRI_data.loc[mask, \"1\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]) + np.exp(PRI_data.loc[mask, \"3\"]) + np.exp(PRI_data.loc[mask, \"4\"]) + np.exp(PRI_data.loc[mask, \"5\"]) + np.exp(PRI_data.loc[mask, \"6\"]) + np.exp(PRI_data.loc[mask, \"7\"]))\n",
    "PRI_data.loc[mask, \"prob_2\"] = np.exp(PRI_data.loc[mask, \"2\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]) + np.exp(PRI_data.loc[mask, \"3\"]) + np.exp(PRI_data.loc[mask, \"4\"]) + np.exp(PRI_data.loc[mask, \"5\"]) + np.exp(PRI_data.loc[mask, \"6\"]) + np.exp(PRI_data.loc[mask, \"7\"]))\n",
    "PRI_data.loc[mask, \"prob_3\"] = np.exp(PRI_data.loc[mask, \"3\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]) + np.exp(PRI_data.loc[mask, \"3\"]) + np.exp(PRI_data.loc[mask, \"4\"]) + np.exp(PRI_data.loc[mask, \"5\"]) + np.exp(PRI_data.loc[mask, \"6\"]) + np.exp(PRI_data.loc[mask, \"7\"]))\n",
    "PRI_data.loc[mask, \"prob_4\"] = np.exp(PRI_data.loc[mask, \"4\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]) + np.exp(PRI_data.loc[mask, \"3\"]) + np.exp(PRI_data.loc[mask, \"4\"]) + np.exp(PRI_data.loc[mask, \"5\"]) + np.exp(PRI_data.loc[mask, \"6\"]) + np.exp(PRI_data.loc[mask, \"7\"]))\n",
    "PRI_data.loc[mask, \"prob_5\"] = np.exp(PRI_data.loc[mask, \"5\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]) + np.exp(PRI_data.loc[mask, \"3\"]) + np.exp(PRI_data.loc[mask, \"4\"]) + np.exp(PRI_data.loc[mask, \"5\"]) + np.exp(PRI_data.loc[mask, \"6\"]) + np.exp(PRI_data.loc[mask, \"7\"]))\n",
    "PRI_data.loc[mask, \"prob_6\"] = np.exp(PRI_data.loc[mask, \"6\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]) + np.exp(PRI_data.loc[mask, \"3\"]) + np.exp(PRI_data.loc[mask, \"4\"]) + np.exp(PRI_data.loc[mask, \"5\"]) + np.exp(PRI_data.loc[mask, \"6\"]) + np.exp(PRI_data.loc[mask, \"7\"]))\n",
    "PRI_data.loc[mask, \"prob_7\"] = np.exp(PRI_data.loc[mask, \"7\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]) + np.exp(PRI_data.loc[mask, \"3\"]) + np.exp(PRI_data.loc[mask, \"4\"]) + np.exp(PRI_data.loc[mask, \"5\"]) + np.exp(PRI_data.loc[mask, \"6\"]) + np.exp(PRI_data.loc[mask, \"7\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fe6591f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "PRI_data=filter_pred_prob(PRI_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0ff04f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # flip back human answers where they were flipped\n",
    "# mask = (PRI_data[\"flipped\"] == True) & (PRI_data[\"item\"].isin([1, 3, 5, 7, 9, 11, 13, 15]))\n",
    "# PRI_data.loc[mask, \"human_number\"] = 3 - PRI_data.loc[mask, \"human_number\"]\n",
    "\n",
    "# mask = (PRI_data[\"flipped\"] == True) & (PRI_data[\"item\"].isin([2, 4, 6, 8, 10, 12, 14, 16]))\n",
    "# PRI_data.loc[mask, \"human_number\"] = 8 - PRI_data.loc[mask, \"human_number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7ae95ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_PRI = get_LLM_value_per_item(PRI_data)\n",
    "model_item_scores_PRI_top_n = get_LLM_value_per_item_top_n(PRI_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_PRI = model_item_scores_PRI.merge(\n",
    "    model_item_scores_PRI_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ffab96f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding task specific categories to save in all data\n",
    "\n",
    "# add item categories\n",
    "item_to_category = {\n",
    "     1: \"decision\", 3: \"decision\", 5: \"decision\", 7: \"decision\", 9: \"decision\", 11: \"decision\", 13: \"decision\", 15: \"decision\",\n",
    "     2: \"certainty\", 4: \"certainty\", 6: \"certainty\", 8: \"certainty\", 10: \"certainty\", 12: \"certainty\", 14: \"certainty\", 16: \"certainty\"\n",
    "}\n",
    "\n",
    "model_item_scores_PRI[\"category\"] = model_item_scores_PRI[\"item\"].map(item_to_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "68281602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_PRI], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d1f8ec",
   "metadata": {},
   "source": [
    "## SOEP SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2db32d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (486542, 17)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "SOEP_data = load_dataframes(task_name=\"SOEP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "59969196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probabilities out of log-probabilities\n",
    "\n",
    "cols = [str(i) for i in range(1, 12)]\n",
    "# Compute normalized probabilities\n",
    "exp_vals = np.exp(SOEP_data[cols])\n",
    "prob_vals = exp_vals.div(exp_vals.sum(axis=1), axis=0)\n",
    "\n",
    "# Rename columns all at once\n",
    "prob_vals.columns = [f\"prob_{i}\" for i in range(1, 12)]\n",
    "\n",
    "# Join to original dataframe in one step\n",
    "SOEP_data = pd.concat([SOEP_data, prob_vals], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aaea5af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "SOEP_data=filter_pred_prob(SOEP_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "829772eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # flip back human answers where they were flipped\n",
    "# mask = (SOEP_data[\"flipped\"] == \"yes\") \n",
    "# SOEP_data.loc[mask, \"human_number\"] = 12 - SOEP_data.loc[mask, \"human_number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2810bbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_SOEP = get_LLM_value_per_item(SOEP_data)\n",
    "model_item_scores_SOEP_top_n = get_LLM_value_per_item_top_n(SOEP_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_SOEP = model_item_scores_SOEP.merge(\n",
    "    model_item_scores_SOEP_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2d70fee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding task specific categories to save in all data\n",
    "\n",
    "# add item categories\n",
    "item_to_category = {\n",
    "     1: \"SOEP\", 2: \"SOEPdri\", 3: \"SOEPfin\",  4: \"SOEPrec\", 5: \"SOEPocc\",  6: \"SOEPhea\",  7: \"SOEPsoc\"\n",
    "}\n",
    "\n",
    "model_item_scores_SOEP[\"category\"] = model_item_scores_SOEP[\"item\"].map(item_to_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6ef74f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_SOEP], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919cb194",
   "metadata": {},
   "source": [
    "## SSSV SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4ee11e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (2776560, 8)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "SSSV_data = load_dataframes(task_name=\"SSSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dfaf361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one\n",
    "SSSV_data[\"prob_1\"] = np.exp(SSSV_data[\"1\"])/(np.exp(SSSV_data[\"1\"]) + np.exp(SSSV_data[\"2\"]))\n",
    "SSSV_data[\"prob_2\"] = np.exp(SSSV_data[\"2\"])/(np.exp(SSSV_data[\"1\"]) + np.exp(SSSV_data[\"2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3c2a7fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "SSSV_data=filter_pred_prob(SSSV_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dd874639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # flip back human answers where they were flipped\n",
    "# mask = (SSSV_data[\"flipped\"] == True) \n",
    "# SSSV_data.loc[mask, \"human_number\"] = 3 - SSSV_data.loc[mask, \"human_number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b46968f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reverse human answers (again) where the items where reversed phrased\n",
    "\n",
    "# # add whether item was reverse coded\n",
    "# reverse_coded = {\n",
    "#      1: True, 2: False, 3: True, 4: False, 5: True, 6: True, 7: False, 8: True, 9: True, 10: False, \n",
    "#      11: False, 12: False, 13: False, 14: True, 15: False, 16: True, 17: True, 18: True, 19: False, 20: False,\n",
    "#      21: False, 22: True, 23: True, 24: True, 25: False, 26: False, 27: False, 28: True, 29: True, 30: False,\n",
    "#      31: False, 32: True, 33: False, 34: True, 35: False, 36: True, 37: False, 38: False, 39: True, 40: False\n",
    "\n",
    "# }\n",
    "\n",
    "# # Apply mapping row-wise based on item number\n",
    "# SSSV_data[\"reverse_coded\"] = SSSV_data[\"item\"].map(reverse_coded)\n",
    "\n",
    "# # flip back answers that where reverse coded\n",
    "# mask = (SSSV_data[\"reverse_coded\"] == True)\n",
    "# SSSV_data.loc[mask, \"human_number\"] = 3 - SSSV_data.loc[mask, \"human_number\"]\n",
    "# # drop reverse-coded column (not needed in final data)\n",
    "# model_item_scores_SSSV = SSSV_data.drop(columns=[\"reverse_coded\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4a4ec1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_SSSV = get_LLM_value_per_item(SSSV_data)\n",
    "model_item_scores_SSSV_top_n = get_LLM_value_per_item_top_n(SSSV_data)\n",
    "\n",
    "# Merge them on the grouping keys\n",
    "model_item_scores_SSSV = model_item_scores_SSSV.merge(\n",
    "    model_item_scores_SSSV_top_n,\n",
    "    on=[\"experiment\", \"model\", \"item\"],\n",
    "    how=\"inner\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2f7bb971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding task specific categories to save in all data\n",
    "\n",
    "# add item categories\n",
    "item_to_category = {\n",
    "     3: \"SStas\", 11: \"SStas\", 16: \"SStas\", 17: \"SStas\", 20: \"SStas\", 21: \"SStas\", 23: \"SStas\", 28: \"SStas\", 38: \"SStas\", 40: \"SStas\",\n",
    "     4: \"SSexp\", 6: \"SSexp\", 9: \"SSexp\", 10: \"SSexp\", 14: \"SSexp\", 18: \"SSexp\", 19: \"SSexp\", 22: \"SSexp\", 26: \"SSexp\", 37: \"SSexp\",\n",
    "     1: \"SSdis\", 12: \"SSdis\", 13: \"SSdis\", 25: \"SSdis\", 29: \"SSdis\", 30: \"SSdis\", 32: \"SSdis\", 33: \"SSdis\", 35: \"SSdis\", 36: \"SSdis\",\n",
    "     2: \"SSbor\", 5: \"SSbor\", 7: \"SSbor\", 8: \"SSbor\", 15: \"SSbor\", 24: \"SSbor\", 27: \"SSbor\", 31: \"SSbor\", 34: \"SSbor\", 39: \"SSbor\"\n",
    "}\n",
    "\n",
    "model_item_scores_SSSV[\"category\"] = model_item_scores_SSSV[\"item\"].map(item_to_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "55c256df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_SSSV], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b140480",
   "metadata": {},
   "source": [
    "# Saving new processed dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b3a81d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "all_data.to_csv('processed_data/no_change_item_data.csv', index=False)\n",
    "#all_data.to_csv(\"processed_data/items_per_LLM_random_simulation.csv\", index=False)\n",
    "#all_data.to_csv(\"processed_data/items_per_LLM_semi_random_simulation.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "be7afd59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>model</th>\n",
       "      <th>item</th>\n",
       "      <th>score</th>\n",
       "      <th>score_top_n</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>1</td>\n",
       "      <td>1.667793</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>2</td>\n",
       "      <td>2.534622</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>3</td>\n",
       "      <td>2.056587</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>4</td>\n",
       "      <td>2.477461</td>\n",
       "      <td>1.824985</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>5</td>\n",
       "      <td>3.412819</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11817</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>36</td>\n",
       "      <td>1.330655</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>SSdis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>37</td>\n",
       "      <td>1.362839</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>SSexp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>38</td>\n",
       "      <td>1.367971</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>SStas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>39</td>\n",
       "      <td>1.355507</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>SSbor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>40</td>\n",
       "      <td>1.477137</td>\n",
       "      <td>1.460000</td>\n",
       "      <td>SStas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11822 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        experiment                      model  item     score  score_top_n  \\\n",
       "0      AUDIT scale  Apertus-70B-Instruct-2509     1  1.667793     2.000000   \n",
       "1      AUDIT scale  Apertus-70B-Instruct-2509     2  2.534622     2.000000   \n",
       "2      AUDIT scale  Apertus-70B-Instruct-2509     3  2.056587     1.000000   \n",
       "3      AUDIT scale  Apertus-70B-Instruct-2509     4  2.477461     1.824985   \n",
       "4      AUDIT scale  Apertus-70B-Instruct-2509     5  3.412819     5.000000   \n",
       "...            ...                        ...   ...       ...          ...   \n",
       "11817   SSSV scale             zephyr-7b-beta    36  1.330655     1.000000   \n",
       "11818   SSSV scale             zephyr-7b-beta    37  1.362839     1.000000   \n",
       "11819   SSSV scale             zephyr-7b-beta    38  1.367971     1.000000   \n",
       "11820   SSSV scale             zephyr-7b-beta    39  1.355507     1.000000   \n",
       "11821   SSSV scale             zephyr-7b-beta    40  1.477137     1.460000   \n",
       "\n",
       "      category  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "...        ...  \n",
       "11817    SSdis  \n",
       "11818    SSexp  \n",
       "11819    SStas  \n",
       "11820    SSbor  \n",
       "11821    SStas  \n",
       "\n",
       "[11822 rows x 6 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
