{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfc545a9",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "Starting point:\n",
    "- 848 datasets (18 tasks per model (minus the NON_IDEAL_OUTPUTS)) with all logprobs for all answer alternatives of each subtask for all ~1.500 tasks. \n",
    "\n",
    "What does this script do\n",
    "- Read data sets: Which?\n",
    "- ...\n",
    "\n",
    "Goal:\n",
    "- first have one value per item per model\n",
    "- then transform those values in \"outcomes\" for each subscale (like Frey did)\n",
    "- Have 36 values per model! (one per (sub-) scale)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2ebc19",
   "metadata": {},
   "source": [
    "## Packages & Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fef727d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "69d790d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# 2. Pro Modell × Item die Zähler und Nenner berechnen\n",
    "# --------------------------------------------\n",
    "# - Numerator = Summe von (Antwort * Wahrscheinlichkeit)\n",
    "# - Denominator = Summe von (Wahrscheinlichkeiten)\n",
    "\n",
    "def compute_weighted_score(group):\n",
    "    numerator = (group[\"human_number\"] * group[\"prob_pred\"]).sum()\n",
    "    denominator = group[\"prob_pred\"].sum()\n",
    "    return numerator / denominator if denominator > 0 else None\n",
    "\n",
    "\n",
    "# produce df with one value per model per item --------------------------------------------------\n",
    "def get_LLM_value_per_item(data):\n",
    "    new_df = (\n",
    "    data.groupby([\"experiment\", \"model\", \"item\"])[[\"human_number\", \"prob_pred\"]]\n",
    "      .apply(compute_weighted_score)\n",
    "      .reset_index(name=\"score\")\n",
    "    )\n",
    "    return(new_df)\n",
    "\n",
    "# more compact version (that runs faster)\n",
    "def get_LLM_value_per_item(data):\n",
    "    grouped = data.groupby([\"experiment\", \"model\", \"item\"])\n",
    "    score = (grouped[\"human_number\"].apply(lambda x: (x * data.loc[x.index, \"prob_pred\"]).sum())\n",
    "             / grouped[\"prob_pred\"].sum())\n",
    "    return score.reset_index(name=\"score\")\n",
    "\n",
    "\n",
    "# Loading all data files of one task ------------------------------------------------------------\n",
    "def load_dataframes(task_name, path = \"LLM_data\"):\n",
    "\n",
    "    # Initialize empty list to store DataFrames\n",
    "    dataframe = []\n",
    "\n",
    "    path = \"LLM_data\"  # folder with CSVs of LLM answers\n",
    "\n",
    "    for file in glob.glob(os.path.join(path, f\"*_{task_name}_prompting_results.csv\")):\n",
    "        model_name = os.path.basename(file).replace(f\"*_{task_name}_prompting_results.csv\", \"\")\n",
    "        \n",
    "        # Read the CSV\n",
    "        df = pd.read_csv(file)\n",
    "        \n",
    "        # Append to list\n",
    "        dataframe.append(df)\n",
    "        \n",
    "    # Concatenate all DataFrames into one big DataFrame\n",
    "    merged_data = pd.concat(dataframe, ignore_index=True)\n",
    "\n",
    "    print(f\"Merged DataFrame shape: {merged_data.shape}\")\n",
    "    print(f\"Total models: {merged_data['model'].nunique()}\")\n",
    "\n",
    "    return(merged_data)\n",
    "\n",
    "\n",
    "# filter out probability LLM assigned to real item answer  ------------------------------------------\n",
    "def filter_pred_prob(data):\n",
    "    data[\"prob_pred\"] = data.apply(\n",
    "        lambda row: row[f\"prob_{row['human_number']}\"], axis=1\n",
    "    )\n",
    "    return(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eece353e",
   "metadata": {},
   "source": [
    "## AUDIT SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "65a51faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (712264, 11)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "AUDIT_data = load_dataframes(task_name=\"AUDIT\", path = \"LLM_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fd081b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one (tun so als hätten wir sehr guten Prompt, dann würde LLM nur zwischen möglichen Antwortalternativen aussuchen, da simulieren wir dadurch)\n",
    "mask = (AUDIT_data[\"item\"] == 1)\n",
    "AUDIT_data.loc[mask, \"prob_1\"] = np.exp(AUDIT_data.loc[mask, \"1\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]))\n",
    "AUDIT_data.loc[mask, \"prob_2\"] = np.exp(AUDIT_data.loc[mask, \"2\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]))\n",
    "\n",
    "mask = (AUDIT_data[\"item\"].isin([10, 11]))\n",
    "AUDIT_data.loc[mask, \"prob_1\"] = np.exp(AUDIT_data.loc[mask, \"1\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]))\n",
    "AUDIT_data.loc[mask, \"prob_2\"] = np.exp(AUDIT_data.loc[mask, \"2\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]))\n",
    "AUDIT_data.loc[mask, \"prob_3\"] = np.exp(AUDIT_data.loc[mask, \"3\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]))\n",
    "\n",
    "\n",
    "mask = (AUDIT_data[\"item\"].isin([2, 3, 4, 5, 6, 7, 8, 9]))\n",
    "AUDIT_data.loc[mask, \"prob_1\"] = np.exp(AUDIT_data.loc[mask, \"1\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]) + np.exp(AUDIT_data.loc[mask, \"4\"]) + np.exp(AUDIT_data.loc[mask, \"5\"]))\n",
    "AUDIT_data.loc[mask, \"prob_2\"] = np.exp(AUDIT_data.loc[mask, \"2\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]) + np.exp(AUDIT_data.loc[mask, \"4\"]) + np.exp(AUDIT_data.loc[mask, \"5\"]))\n",
    "AUDIT_data.loc[mask, \"prob_3\"] = np.exp(AUDIT_data.loc[mask, \"3\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]) + np.exp(AUDIT_data.loc[mask, \"4\"]) + np.exp(AUDIT_data.loc[mask, \"5\"]))\n",
    "AUDIT_data.loc[mask, \"prob_4\"] = np.exp(AUDIT_data.loc[mask, \"4\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]) + np.exp(AUDIT_data.loc[mask, \"4\"]) + np.exp(AUDIT_data.loc[mask, \"5\"]))\n",
    "AUDIT_data.loc[mask, \"prob_5\"] = np.exp(AUDIT_data.loc[mask, \"5\"])/(np.exp(AUDIT_data.loc[mask, \"1\"]) + np.exp(AUDIT_data.loc[mask, \"2\"]) + np.exp(AUDIT_data.loc[mask, \"3\"]) + np.exp(AUDIT_data.loc[mask, \"4\"]) + np.exp(AUDIT_data.loc[mask, \"5\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8b52a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "AUDIT_data=filter_pred_prob(AUDIT_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1421f934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (AUDIT_data[\"flipped\"] == \"yes\") & (AUDIT_data[\"item\"] == 1)\n",
    "AUDIT_data.loc[mask, \"human_number\"] = 3 - AUDIT_data.loc[mask, \"human_number\"]\n",
    "mask = (AUDIT_data[\"flipped\"] == \"yes\") & (AUDIT_data[\"item\"].isin([10, 11]))\n",
    "AUDIT_data.loc[mask, \"human_number\"] = 4 - AUDIT_data.loc[mask, \"human_number\"]\n",
    "mask = (AUDIT_data[\"flipped\"] == \"yes\") & (AUDIT_data[\"item\"].isin([2, 3, 4, 5, 6, 7, 8, 9]))\n",
    "AUDIT_data.loc[mask, \"human_number\"] = 6 - AUDIT_data.loc[mask, \"human_number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f0d05126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_AUDIT = get_LLM_value_per_item(AUDIT_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d65688",
   "metadata": {},
   "source": [
    "## BARRAT SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cc730c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (2082420, 10)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "BARRAT_data = load_dataframes(task_name=\"BARRAT\", path = \"LLM_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4b88e1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one\n",
    "BARRAT_data[\"prob_1\"] = np.exp(BARRAT_data[\"1\"])/(np.exp(BARRAT_data[\"1\"]) + np.exp(BARRAT_data[\"2\"]) + np.exp(BARRAT_data[\"3\"]) + np.exp(BARRAT_data[\"4\"]))\n",
    "BARRAT_data[\"prob_2\"] = np.exp(BARRAT_data[\"2\"])/(np.exp(BARRAT_data[\"1\"]) + np.exp(BARRAT_data[\"2\"]) + np.exp(BARRAT_data[\"3\"]) + np.exp(BARRAT_data[\"4\"]))\n",
    "BARRAT_data[\"prob_3\"] = np.exp(BARRAT_data[\"3\"])/(np.exp(BARRAT_data[\"1\"]) + np.exp(BARRAT_data[\"2\"]) + np.exp(BARRAT_data[\"3\"]) + np.exp(BARRAT_data[\"4\"]))\n",
    "BARRAT_data[\"prob_4\"] = np.exp(BARRAT_data[\"4\"])/(np.exp(BARRAT_data[\"1\"]) + np.exp(BARRAT_data[\"2\"]) + np.exp(BARRAT_data[\"3\"]) + np.exp(BARRAT_data[\"4\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9945c979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "BARRAT_data=filter_pred_prob(BARRAT_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "29d02886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (BARRAT_data[\"flipped\"] == True)\n",
    "BARRAT_data.loc[mask, \"human_number\"] = 5 - BARRAT_data.loc[mask, \"human_number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3100efef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_BARRAT = get_LLM_value_per_item(BARRAT_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "38eda3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding task specific categories to save in all data\n",
    "\n",
    "# add item categories\n",
    "item_to_category = {\n",
    "    1: \"BISn\", 2: \"BISm\", 3: \"BISm\",  4: \"BISm\", 5: \"BISa\",  6: \"BISa\",  7: \"BISn\",  8: \"BISn\",  9: \"BISa\",  10: \"BISn\",\n",
    "    11: \"BISa\", 12: \"BISn\", 13: \"BISn\",  14: \"BISn\", 15: \"BISn\",  16: \"BISm\",  17: \"BISm\",  18: \"BISn\",  19: \"BISm\",  20: \"BISa\",\n",
    "    21: \"BISm\", 22: \"BISm\", 23: \"BISm\",  24: \"BISa\", 25: \"BISm\",  26: \"BISa\",  27: \"BISn\",  28: \"BISa\",  29: \"BISn\",  30: \"BISm\"\n",
    "}\n",
    "# add whether item was reverse coded\n",
    "reverse_coded = {\n",
    "    1: True, 2: False, 3: False,  4: False, 5: False,  6: False,  7: True,  8: True,  9: True,  10: True,\n",
    "    11: False, 12: True, 13: True,  14: False, 15: True,  16: False,  17: False,  18: False,  19: False,  20: True,\n",
    "    21: False, 22: False, 23: False,  24: False, 25: False,  26: False,  27: False,  28: False,  29: True,  30: True\n",
    "    }\n",
    "\n",
    "model_item_scores_BARRAT[\"category\"] = model_item_scores_BARRAT[\"item\"].map(item_to_category)\n",
    "model_item_scores_BARRAT[\"reverse_coded\"] = model_item_scores_BARRAT[\"item\"].map(reverse_coded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7ddb9972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([model_item_scores_AUDIT, model_item_scores_BARRAT], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0226ac",
   "metadata": {},
   "source": [
    "## CARE TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f1491661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (1320614, 106)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "CARE_data = load_dataframes(task_name=\"CARE\", path = \"LLM_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d59c8fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probabilities out of log-probabilities\n",
    "\n",
    "cols = [str(i) for i in range(0, 100)]\n",
    "# Compute normalized probabilities\n",
    "exp_vals = np.exp(CARE_data[cols])\n",
    "prob_vals = exp_vals.div(exp_vals.sum(axis=1), axis=0)\n",
    "\n",
    "# Rename columns all at once\n",
    "prob_vals.columns = [f\"prob_{i}\" for i in range(0, 100)]\n",
    "\n",
    "# Join to original dataframe in one step\n",
    "CARE_data = pd.concat([CARE_data, prob_vals], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a389bebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "CARE_data=filter_pred_prob(CARE_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "914d1030",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_item_scores_CARE = get_LLM_value_per_item(CARE_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4a344c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding task specific categories to save in all data\n",
    "# add item categories\n",
    "item_to_category = {\n",
    "    1: \"CAREa\", 2: \"CAREa\", 3: \"CAREa\",  4: \"CAREa\", 5: \"CAREa\",  6: \"CAREa\",  7: \"CAREa\",  8: \"CAREa\",  9: \"CAREa\",  10: \"CAREs\",\n",
    "    11: \"CAREs\", 12: \"CAREs\", 13: \"CAREs\",  14: \"CAREs\", 15: \"CAREs\",  16: \"CAREw\",  17: \"CAREw\",  18: \"CAREw\",  19: \"CAREw\"\n",
    "}\n",
    "\n",
    "model_item_scores_CARE[\"category\"] = model_item_scores_CARE[\"item\"].map(item_to_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b8720af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([all_data, model_item_scores_CARE], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1623f7ae",
   "metadata": {},
   "source": [
    "## DAST SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a1e720e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (1391040, 8)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "DAST_data = load_dataframes(task_name=\"DAST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "acf31561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one \n",
    "DAST_data[\"prob_1\"] = np.exp(DAST_data[\"1\"])/(np.exp(DAST_data[\"1\"]) + np.exp(DAST_data[\"2\"]))\n",
    "DAST_data[\"prob_2\"] = np.exp(DAST_data[\"2\"])/(np.exp(DAST_data[\"1\"]) + np.exp(DAST_data[\"2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6833d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "DAST_data=filter_pred_prob(DAST_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4d9b749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (DAST_data[\"flipped\"] == True) \n",
    "DAST_data.loc[mask, \"human_number\"] = 3 - DAST_data.loc[mask, \"human_number\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "806cd5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_DAST = get_LLM_value_per_item(DAST_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "54525c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_DAST], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a376a9e9",
   "metadata": {},
   "source": [
    "## DM SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a50dd425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (1318866, 10)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "DM_data = load_dataframes(task_name=\"DM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f8a1b71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one\n",
    "DM_data[\"prob_1\"] = np.exp(DM_data[\"1\"])/(np.exp(DM_data[\"1\"]) + np.exp(DM_data[\"2\"]) + np.exp(DM_data[\"3\"]) + np.exp(DM_data[\"4\"]))\n",
    "DM_data[\"prob_2\"] = np.exp(DM_data[\"2\"])/(np.exp(DM_data[\"1\"]) + np.exp(DM_data[\"2\"]) + np.exp(DM_data[\"3\"]) + np.exp(DM_data[\"4\"]))\n",
    "DM_data[\"prob_3\"] = np.exp(DM_data[\"3\"])/(np.exp(DM_data[\"1\"]) + np.exp(DM_data[\"2\"]) + np.exp(DM_data[\"3\"]) + np.exp(DM_data[\"4\"]))\n",
    "DM_data[\"prob_4\"] = np.exp(DM_data[\"4\"])/(np.exp(DM_data[\"1\"]) + np.exp(DM_data[\"2\"]) + np.exp(DM_data[\"3\"]) + np.exp(DM_data[\"4\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4b778d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "DM_data=filter_pred_prob(DM_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "22d0cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (DM_data[\"flipped\"] == True) \n",
    "DM_data.loc[mask, \"human_number\"] = 3 - DM_data.loc[mask, \"human_number\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cb8e201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_DM = get_LLM_value_per_item(DM_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "125ae7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_DM], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf36e830",
   "metadata": {},
   "source": [
    "## DOSPERT SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4828b1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (2780240, 11)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "DOSPERT_data = load_dataframes(task_name=\"DOSPERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "df6de3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one\n",
    "DOSPERT_data[\"prob_1\"] = np.exp(DOSPERT_data[\"1\"])/(np.exp(DOSPERT_data[\"1\"]) + np.exp(DOSPERT_data[\"2\"]) + np.exp(DOSPERT_data[\"3\"]) + np.exp(DOSPERT_data[\"4\"]) + np.exp(DOSPERT_data[\"5\"]))\n",
    "DOSPERT_data[\"prob_2\"] = np.exp(DOSPERT_data[\"2\"])/(np.exp(DOSPERT_data[\"1\"]) + np.exp(DOSPERT_data[\"2\"]) + np.exp(DOSPERT_data[\"3\"]) + np.exp(DOSPERT_data[\"4\"]) + np.exp(DOSPERT_data[\"5\"]))\n",
    "DOSPERT_data[\"prob_3\"] = np.exp(DOSPERT_data[\"3\"])/(np.exp(DOSPERT_data[\"1\"]) + np.exp(DOSPERT_data[\"2\"]) + np.exp(DOSPERT_data[\"3\"]) + np.exp(DOSPERT_data[\"4\"]) + np.exp(DOSPERT_data[\"5\"]))\n",
    "DOSPERT_data[\"prob_4\"] = np.exp(DOSPERT_data[\"4\"])/(np.exp(DOSPERT_data[\"1\"]) + np.exp(DOSPERT_data[\"2\"]) + np.exp(DOSPERT_data[\"3\"]) + np.exp(DOSPERT_data[\"4\"]) + np.exp(DOSPERT_data[\"5\"]))\n",
    "DOSPERT_data[\"prob_5\"] = np.exp(DOSPERT_data[\"5\"])/(np.exp(DOSPERT_data[\"1\"]) + np.exp(DOSPERT_data[\"2\"]) + np.exp(DOSPERT_data[\"3\"]) + np.exp(DOSPERT_data[\"4\"]) + np.exp(DOSPERT_data[\"5\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c87c6117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "DOSPERT_data=filter_pred_prob(DOSPERT_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "270ff6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (DOSPERT_data[\"flipped\"] == 'yes') \n",
    "DOSPERT_data.loc[mask, \"human_number\"] = 6 - DOSPERT_data.loc[mask, \"human_number\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a15c7fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_DOSPERT = get_LLM_value_per_item(DOSPERT_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "005799af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding task specific categories to save in all data\n",
    "\n",
    "# add item categories\n",
    "item_to_category = {\n",
    "    1: \"Social\", 10: \"Social\", 16: \"Social\", 19: \"Social\", 23: \"Social\", 26: \"Social\", 34: \"Social\", 35: \"Social\",\n",
    "    2: \"Recreational\", 6: \"Recreational\", 15: \"Recreational\", 17: \"Recreational\", 21: \"Recreational\", 31: \"Recreational\", 37: \"Recreational\", 38: \"Recreational\",\n",
    "    3: \"Gambling\", 11: \"Gambling\", 22: \"Gambling\", 33: \"Gambling\",\n",
    "    4: \"Health\", 8: \"Health\", 27: \"Health\", 29: \"Health\", 32: \"Health\", 36: \"Health\", 39: \"Health\", 40: \"Health\",\n",
    "    5: \"Ethical\", 9: \"Ethical\", 12: \"Ethical\", 13: \"Ethical\", 14: \"Ethical\", 20: \"Ethical\", 25: \"Ethical\", 28: \"Ethical\",\n",
    "    7: \"Investment\", 18: \"Investment\", 24: \"Investment\", 30: \"Investment\"\n",
    "}\n",
    "\n",
    "model_item_scores_DOSPERT[\"category\"] = model_item_scores_DOSPERT[\"item\"].map(item_to_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "eae478ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_DOSPERT], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cbad99",
   "metadata": {},
   "source": [
    "## FTND SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b79895fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (163162, 10)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "FTND_data = load_dataframes(task_name=\"FTND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3d512cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one (tun so als hätten wir sehr guten Prompt, dann würde LLM nur zwischen möglichen Antwortalternativen aussuchen, da simulieren wir dadurch)\n",
    "mask = (FTND_data[\"item\"] == 1)\n",
    "FTND_data.loc[mask, \"prob_1\"] = np.exp(FTND_data.loc[mask, \"1\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]) + np.exp(FTND_data.loc[mask, \"3\"]))\n",
    "FTND_data.loc[mask, \"prob_2\"] = np.exp(FTND_data.loc[mask, \"2\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]) + np.exp(FTND_data.loc[mask, \"3\"]))\n",
    "FTND_data.loc[mask, \"prob_3\"] = np.exp(FTND_data.loc[mask, \"3\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]) + np.exp(FTND_data.loc[mask, \"3\"]))\n",
    "\n",
    "mask = (FTND_data[\"item\"].isin([3, 4, 6, 7]))\n",
    "FTND_data.loc[mask, \"prob_1\"] = np.exp(FTND_data.loc[mask, \"1\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]))\n",
    "FTND_data.loc[mask, \"prob_2\"] = np.exp(FTND_data.loc[mask, \"2\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]))\n",
    "\n",
    "mask = (FTND_data[\"item\"].isin([2, 5]))\n",
    "FTND_data.loc[mask, \"prob_1\"] = np.exp(FTND_data.loc[mask, \"1\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]) + np.exp(FTND_data.loc[mask, \"3\"]) + np.exp(FTND_data.loc[mask, \"4\"]))\n",
    "FTND_data.loc[mask, \"prob_2\"] = np.exp(FTND_data.loc[mask, \"2\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]) + np.exp(FTND_data.loc[mask, \"3\"]) + np.exp(FTND_data.loc[mask, \"4\"]))\n",
    "FTND_data.loc[mask, \"prob_3\"] = np.exp(FTND_data.loc[mask, \"3\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]) + np.exp(FTND_data.loc[mask, \"3\"]) + np.exp(FTND_data.loc[mask, \"4\"]))\n",
    "FTND_data.loc[mask, \"prob_4\"] = np.exp(FTND_data.loc[mask, \"4\"])/(np.exp(FTND_data.loc[mask, \"1\"]) + np.exp(FTND_data.loc[mask, \"2\"]) + np.exp(FTND_data.loc[mask, \"3\"]) + np.exp(FTND_data.loc[mask, \"4\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f407d56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "FTND_data=filter_pred_prob(FTND_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6c3668c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (FTND_data[\"flipped\"] == True) & (FTND_data[\"item\"] == 1)\n",
    "FTND_data.loc[mask, \"human_number\"] = 4 - FTND_data.loc[mask, \"human_number\"]\n",
    "mask = (FTND_data[\"flipped\"] == True) & (FTND_data[\"item\"].isin([3, 4, 6, 7]))\n",
    "FTND_data.loc[mask, \"human_number\"] = 3 - FTND_data.loc[mask, \"human_number\"]\n",
    "mask = (FTND_data[\"flipped\"] == True) & (FTND_data[\"item\"].isin([2, 5]))\n",
    "FTND_data.loc[mask, \"human_number\"] = 5 - FTND_data.loc[mask, \"human_number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0bf07e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_FTND = get_LLM_value_per_item(FTND_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ce78b07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_FTND], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54306e48",
   "metadata": {},
   "source": [
    "## GABS SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "dc20119a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (581210, 10)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "GABS_data = load_dataframes(task_name=\"GABS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8cf18026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one\n",
    "\n",
    "# columns representing log-probabilities\n",
    "answer_cols = [\"1\", \"2\", \"3\", \"4\"]\n",
    "\n",
    "# make a copy to avoid SettingWithCopy warnings\n",
    "GABS_data = GABS_data.copy()\n",
    "\n",
    "# case 1: item == 1 → only options 1 and 2\n",
    "mask_item1 = GABS_data[\"item\"] == 1\n",
    "exp_vals_item1 = np.exp(GABS_data.loc[mask_item1, [\"1\", \"2\"]])\n",
    "probs_item1 = exp_vals_item1.div(exp_vals_item1.sum(axis=1), axis=0)\n",
    "probs_item1.columns = [\"prob_1\", \"prob_2\"]\n",
    "\n",
    "# case 2: items 2–17 → options 1–4\n",
    "mask_item2plus = GABS_data[\"item\"].between(2, 17)\n",
    "exp_vals_item2plus = np.exp(GABS_data.loc[mask_item2plus, answer_cols])\n",
    "probs_item2plus = exp_vals_item2plus.div(exp_vals_item2plus.sum(axis=1), axis=0)\n",
    "probs_item2plus.columns = [f\"prob_{c}\" for c in answer_cols]\n",
    "\n",
    "# merge both parts back into original df\n",
    "GABS_data = GABS_data.join(pd.concat([probs_item1, probs_item2plus]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "45796a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "GABS_data=filter_pred_prob(GABS_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "29b40036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (GABS_data[\"flipped\"] == True) & (GABS_data[\"item\"] == 1)\n",
    "GABS_data.loc[mask, \"human_number\"] = 3 - GABS_data.loc[mask, \"human_number\"]\n",
    "mask = (GABS_data[\"flipped\"] == True) & (GABS_data[\"item\"].isin(range(2,17)))\n",
    "GABS_data.loc[mask, \"human_number\"] = 5 - GABS_data.loc[mask, \"human_number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6cb6a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_GABS = get_LLM_value_per_item(GABS_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "abcf63ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_GABS], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed59198",
   "metadata": {},
   "source": [
    "## PG SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e97aa4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (1127322, 13)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "PG_data = load_dataframes(task_name=\"PG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "66851dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one \n",
    "\n",
    "mask = (PG_data[\"item\"].isin([1, 26]))\n",
    "PG_data.loc[mask, \"prob_1\"] = np.exp(PG_data.loc[mask, \"1\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]))\n",
    "PG_data.loc[mask, \"prob_2\"] = np.exp(PG_data.loc[mask, \"2\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]))\n",
    "\n",
    "\n",
    "\n",
    "mask = (PG_data[\"item\"].isin(range(2, 21)))\n",
    "PG_data.loc[mask, \"prob_1\"] = np.exp(PG_data.loc[mask, \"1\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]))\n",
    "PG_data.loc[mask, \"prob_2\"] = np.exp(PG_data.loc[mask, \"2\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]))\n",
    "PG_data.loc[mask, \"prob_3\"] = np.exp(PG_data.loc[mask, \"3\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]))\n",
    "PG_data.loc[mask, \"prob_4\"] = np.exp(PG_data.loc[mask, \"4\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]))\n",
    "PG_data.loc[mask, \"prob_5\"] = np.exp(PG_data.loc[mask, \"5\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]))\n",
    "\n",
    "\n",
    "\n",
    "mask = (PG_data[\"item\"] == 25)\n",
    "PG_data.loc[mask, \"prob_1\"] = np.exp(PG_data.loc[mask, \"1\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]) + np.exp(PG_data.loc[mask, \"6\"]))\n",
    "PG_data.loc[mask, \"prob_2\"] = np.exp(PG_data.loc[mask, \"2\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]) + np.exp(PG_data.loc[mask, \"6\"]))\n",
    "PG_data.loc[mask, \"prob_3\"] = np.exp(PG_data.loc[mask, \"3\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]) + np.exp(PG_data.loc[mask, \"6\"]))\n",
    "PG_data.loc[mask, \"prob_4\"] = np.exp(PG_data.loc[mask, \"4\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]) + np.exp(PG_data.loc[mask, \"6\"]))\n",
    "PG_data.loc[mask, \"prob_5\"] = np.exp(PG_data.loc[mask, \"5\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]) + np.exp(PG_data.loc[mask, \"6\"]))\n",
    "PG_data.loc[mask, \"prob_6\"] = np.exp(PG_data.loc[mask, \"6\"])/(np.exp(PG_data.loc[mask, \"1\"]) + np.exp(PG_data.loc[mask, \"2\"]) + np.exp(PG_data.loc[mask, \"3\"]) + np.exp(PG_data.loc[mask, \"4\"]) + np.exp(PG_data.loc[mask, \"5\"]) + np.exp(PG_data.loc[mask, \"6\"]))\n",
    "\n",
    "\n",
    "mask = (PG_data[\"item\"].isin([21, 22, 23, 24, 27, 28, 29, 30, 31, 32]))\n",
    "PG_data.loc[mask, \"prob_0\"] = np.exp(PG_data.loc[mask, \"0\"])/(np.exp(PG_data.loc[mask, \"0\"]) + np.exp(PG_data.loc[mask, \"1\"]))\n",
    "PG_data.loc[mask, \"prob_1\"] = np.exp(PG_data.loc[mask, \"1\"])/(np.exp(PG_data.loc[mask, \"0\"]) + np.exp(PG_data.loc[mask, \"1\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "dfc61164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "PG_data=filter_pred_prob(PG_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "66d9d25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (PG_data[\"flipped\"] == True) & (PG_data[\"item\"].isin([1, 26]))\n",
    "PG_data.loc[mask, \"human_number\"] = 3 - PG_data.loc[mask, \"human_number\"]\n",
    "\n",
    "mask = (PG_data[\"flipped\"] == True) & (PG_data[\"item\"].isin(range(2, 21)))\n",
    "PG_data.loc[mask, \"human_number\"] = 6 - PG_data.loc[mask, \"human_number\"]\n",
    "\n",
    "mask = (PG_data[\"flipped\"] == True) & (PG_data[\"item\"] == 25)\n",
    "PG_data.loc[mask, \"human_number\"] = 7 - PG_data.loc[mask, \"human_number\"]\n",
    "\n",
    "mask = (PG_data[\"flipped\"] == True) & (PG_data[\"item\"].isin([21, 22, 23, 24, 27, 28, 29, 30, 31, 32]))\n",
    "PG_data.loc[mask, \"human_number\"] = 1 - PG_data.loc[mask, \"human_number\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c5f8e0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_PG = get_LLM_value_per_item(PG_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5e0c6aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_PG], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b01fef",
   "metadata": {},
   "source": [
    "## PRI SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "80602ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (1110624, 13)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "PRI_data = load_dataframes(task_name=\"PRI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "39ee7b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one \n",
    "\n",
    "mask = (PRI_data[\"item\"].isin([1, 3, 5, 7, 9, 11, 13, 15]))\n",
    "PRI_data.loc[mask, \"prob_1\"] = np.exp(PRI_data.loc[mask, \"1\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]))\n",
    "PRI_data.loc[mask, \"prob_2\"] = np.exp(PRI_data.loc[mask, \"2\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]))\n",
    "\n",
    "\n",
    "\n",
    "mask = (PRI_data[\"item\"].isin([2, 4, 6, 8, 10, 12, 14, 16]))\n",
    "PRI_data.loc[mask, \"prob_1\"] = np.exp(PRI_data.loc[mask, \"1\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]) + np.exp(PRI_data.loc[mask, \"3\"]) + np.exp(PRI_data.loc[mask, \"4\"]) + np.exp(PRI_data.loc[mask, \"5\"]) + np.exp(PRI_data.loc[mask, \"6\"]) + np.exp(PRI_data.loc[mask, \"7\"]))\n",
    "PRI_data.loc[mask, \"prob_2\"] = np.exp(PRI_data.loc[mask, \"2\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]) + np.exp(PRI_data.loc[mask, \"3\"]) + np.exp(PRI_data.loc[mask, \"4\"]) + np.exp(PRI_data.loc[mask, \"5\"]) + np.exp(PRI_data.loc[mask, \"6\"]) + np.exp(PRI_data.loc[mask, \"7\"]))\n",
    "PRI_data.loc[mask, \"prob_3\"] = np.exp(PRI_data.loc[mask, \"3\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]) + np.exp(PRI_data.loc[mask, \"3\"]) + np.exp(PRI_data.loc[mask, \"4\"]) + np.exp(PRI_data.loc[mask, \"5\"]) + np.exp(PRI_data.loc[mask, \"6\"]) + np.exp(PRI_data.loc[mask, \"7\"]))\n",
    "PRI_data.loc[mask, \"prob_4\"] = np.exp(PRI_data.loc[mask, \"4\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]) + np.exp(PRI_data.loc[mask, \"3\"]) + np.exp(PRI_data.loc[mask, \"4\"]) + np.exp(PRI_data.loc[mask, \"5\"]) + np.exp(PRI_data.loc[mask, \"6\"]) + np.exp(PRI_data.loc[mask, \"7\"]))\n",
    "PRI_data.loc[mask, \"prob_5\"] = np.exp(PRI_data.loc[mask, \"5\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]) + np.exp(PRI_data.loc[mask, \"3\"]) + np.exp(PRI_data.loc[mask, \"4\"]) + np.exp(PRI_data.loc[mask, \"5\"]) + np.exp(PRI_data.loc[mask, \"6\"]) + np.exp(PRI_data.loc[mask, \"7\"]))\n",
    "PRI_data.loc[mask, \"prob_6\"] = np.exp(PRI_data.loc[mask, \"6\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]) + np.exp(PRI_data.loc[mask, \"3\"]) + np.exp(PRI_data.loc[mask, \"4\"]) + np.exp(PRI_data.loc[mask, \"5\"]) + np.exp(PRI_data.loc[mask, \"6\"]) + np.exp(PRI_data.loc[mask, \"7\"]))\n",
    "PRI_data.loc[mask, \"prob_7\"] = np.exp(PRI_data.loc[mask, \"7\"])/(np.exp(PRI_data.loc[mask, \"1\"]) + np.exp(PRI_data.loc[mask, \"2\"]) + np.exp(PRI_data.loc[mask, \"3\"]) + np.exp(PRI_data.loc[mask, \"4\"]) + np.exp(PRI_data.loc[mask, \"5\"]) + np.exp(PRI_data.loc[mask, \"6\"]) + np.exp(PRI_data.loc[mask, \"7\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "fe6591f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "PRI_data=filter_pred_prob(PRI_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0ff04f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (PRI_data[\"flipped\"] == True) & (PRI_data[\"item\"].isin([1, 3, 5, 7, 9, 11, 13, 15]))\n",
    "PRI_data.loc[mask, \"human_number\"] = 3 - PRI_data.loc[mask, \"human_number\"]\n",
    "\n",
    "mask = (PRI_data[\"flipped\"] == True) & (PRI_data[\"item\"].isin([2, 4, 6, 8, 10, 12, 14, 16]))\n",
    "PRI_data.loc[mask, \"human_number\"] = 8 - PRI_data.loc[mask, \"human_number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7ae95ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_PRI = get_LLM_value_per_item(PRI_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "68281602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_PRI], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d1f8ec",
   "metadata": {},
   "source": [
    "## SOEP SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2db32d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (486542, 17)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "SOEP_data = load_dataframes(task_name=\"SOEP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "59969196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probabilities out of log-probabilities\n",
    "\n",
    "cols = [str(i) for i in range(1, 12)]\n",
    "# Compute normalized probabilities\n",
    "exp_vals = np.exp(SOEP_data[cols])\n",
    "prob_vals = exp_vals.div(exp_vals.sum(axis=1), axis=0)\n",
    "\n",
    "# Rename columns all at once\n",
    "prob_vals.columns = [f\"prob_{i}\" for i in range(1, 12)]\n",
    "\n",
    "# Join to original dataframe in one step\n",
    "SOEP_data = pd.concat([SOEP_data, prob_vals], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "aaea5af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "SOEP_data=filter_pred_prob(SOEP_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "829772eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (SOEP_data[\"flipped\"] == \"yes\") \n",
    "SOEP_data.loc[mask, \"human_number\"] = 12 - SOEP_data.loc[mask, \"human_number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2810bbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_SOEP = get_LLM_value_per_item(SOEP_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2d70fee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding task specific categories to save in all data\n",
    "\n",
    "# add item categories\n",
    "item_to_category = {\n",
    "     1: \"SOEP\", 2: \"SOEPdri\", 3: \"SOEPfin\",  4: \"SOEPrec\", 5: \"SOEPocc\",  6: \"SOEPhea\",  7: \"SOEPsoc\"\n",
    "}\n",
    "\n",
    "model_item_scores_SOEP[\"category\"] = model_item_scores_SOEP[\"item\"].map(item_to_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6ef74f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_SOEP], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919cb194",
   "metadata": {},
   "source": [
    "## SSSV SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4ee11e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (2776560, 8)\n",
      "Total models: 46\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "SSSV_data = load_dataframes(task_name=\"SSSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "dfaf361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise answer option sum to one\n",
    "SSSV_data[\"prob_1\"] = np.exp(SSSV_data[\"1\"])/(np.exp(SSSV_data[\"1\"]) + np.exp(SSSV_data[\"2\"]))\n",
    "SSSV_data[\"prob_2\"] = np.exp(SSSV_data[\"2\"])/(np.exp(SSSV_data[\"1\"]) + np.exp(SSSV_data[\"2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3c2a7fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out probability LLM assigned to real item answer \n",
    "SSSV_data=filter_pred_prob(SSSV_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "dd874639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip back human answers where they were flipped\n",
    "mask = (SSSV_data[\"flipped\"] == True) \n",
    "SSSV_data.loc[mask, \"human_number\"] = 3 - SSSV_data.loc[mask, \"human_number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4a4ec1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce df with one value per model per item \n",
    "model_item_scores_SSSV = get_LLM_value_per_item(SSSV_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2f7bb971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding task specific categories to save in all data\n",
    "\n",
    "# add item categories\n",
    "item_to_category = {\n",
    "     3: \"SStas\", 11: \"SStas\", 16: \"SStas\", 17: \"SStas\", 20: \"SStas\", 21: \"SStas\", 23: \"SStas\", 28: \"SStas\", 38: \"SStas\", 40: \"SStas\",\n",
    "     4: \"SSexp\", 6: \"SSexp\", 9: \"SSexp\", 10: \"SSexp\", 14: \"SSexp\", 18: \"SSexp\", 19: \"SSexp\", 22: \"SSexp\", 26: \"SSexp\", 37: \"SSexp\",\n",
    "     1: \"SSdis\", 12: \"SSdis\", 13: \"SSdis\", 25: \"SSdis\", 29: \"SSdis\", 30: \"SSdis\", 32: \"SSdis\", 33: \"SSdis\", 35: \"SSdis\", 36: \"SSdis\",\n",
    "     2: \"SSbor\", 5: \"SSbor\", 7: \"SSbor\", 8: \"SSbor\", 15: \"SSbor\", 24: \"SSbor\", 27: \"SSbor\", 31: \"SSbor\", 34: \"SSbor\", 39: \"SSbor\"\n",
    "}\n",
    "\n",
    "model_item_scores_SSSV[\"category\"] = model_item_scores_SSSV[\"item\"].map(item_to_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "55c256df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>model</th>\n",
       "      <th>item</th>\n",
       "      <th>score</th>\n",
       "      <th>category</th>\n",
       "      <th>reverse_coded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>1</td>\n",
       "      <td>1.072054</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>2</td>\n",
       "      <td>3.674954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>3</td>\n",
       "      <td>1.656189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>4</td>\n",
       "      <td>2.163460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUDIT scale</td>\n",
       "      <td>Apertus-70B-Instruct-2509</td>\n",
       "      <td>5</td>\n",
       "      <td>1.134567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11817</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>36</td>\n",
       "      <td>1.577790</td>\n",
       "      <td>SSdis</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>37</td>\n",
       "      <td>1.791699</td>\n",
       "      <td>SSexp</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>38</td>\n",
       "      <td>1.661893</td>\n",
       "      <td>SStas</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>39</td>\n",
       "      <td>1.429377</td>\n",
       "      <td>SSbor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>SSSV scale</td>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>40</td>\n",
       "      <td>1.577203</td>\n",
       "      <td>SStas</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11822 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        experiment                      model  item     score category  \\\n",
       "0      AUDIT scale  Apertus-70B-Instruct-2509     1  1.072054      NaN   \n",
       "1      AUDIT scale  Apertus-70B-Instruct-2509     2  3.674954      NaN   \n",
       "2      AUDIT scale  Apertus-70B-Instruct-2509     3  1.656189      NaN   \n",
       "3      AUDIT scale  Apertus-70B-Instruct-2509     4  2.163460      NaN   \n",
       "4      AUDIT scale  Apertus-70B-Instruct-2509     5  1.134567      NaN   \n",
       "...            ...                        ...   ...       ...      ...   \n",
       "11817   SSSV scale             zephyr-7b-beta    36  1.577790    SSdis   \n",
       "11818   SSSV scale             zephyr-7b-beta    37  1.791699    SSexp   \n",
       "11819   SSSV scale             zephyr-7b-beta    38  1.661893    SStas   \n",
       "11820   SSSV scale             zephyr-7b-beta    39  1.429377    SSbor   \n",
       "11821   SSSV scale             zephyr-7b-beta    40  1.577203    SStas   \n",
       "\n",
       "      reverse_coded  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  \n",
       "...             ...  \n",
       "11817           NaN  \n",
       "11818           NaN  \n",
       "11819           NaN  \n",
       "11820           NaN  \n",
       "11821           NaN  \n",
       "\n",
       "[11822 rows x 6 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge dfs\n",
    "all_data = pd.concat([all_data, model_item_scores_SSSV], ignore_index=True)\n",
    "all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b140480",
   "metadata": {},
   "source": [
    "# Saving new processed dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b3a81d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "all_data.to_csv('processed_data/items_per_LLM.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
