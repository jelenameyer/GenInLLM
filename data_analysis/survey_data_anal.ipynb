{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eca9d25f",
   "metadata": {},
   "source": [
    "# Analysing Reliability of DOSPERT answers 20 LLMs\n",
    "\n",
    "- We want to measure, for each LLM, how consistent it is in assigning probabilities across the 40-item answer patterns of a single human. Essentially: “Does the LLM consistently see the human’s answer pattern as more or less probable, or is it erratic?”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21a54c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import mixedlm\n",
    "import seaborn as sns\n",
    "import pingouin as pg\n",
    "\n",
    "\n",
    "# Initialize empty list to store DataFrames\n",
    "dospert_dataframes = []\n",
    "\n",
    "path = \"LLM_data\"  # folder with CSVs\n",
    "\n",
    "for file in glob.glob(os.path.join(path, \"*_DOSPERT_prompting_results.csv\")):\n",
    "    model_name = os.path.basename(file).replace(\"_DOSPERT_prompting_results.csv\", \"\")\n",
    "    \n",
    "    # Read the CSV\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Append to list\n",
    "    dospert_dataframes.append(df)\n",
    "    \n",
    "# Concatenate all DataFrames into one big DataFrame\n",
    "merged_dospert_data = pd.concat(dospert_dataframes, ignore_index=True)\n",
    "\n",
    "print(f\"\\nMerged DataFrame shape: {merged_dospert_data.shape}\")\n",
    "print(f\"Total models: {merged_dospert_data['model'].nunique()}\")\n",
    "print(f\"Models included: {sorted(merged_dospert_data['model'].unique())}\")\n",
    "\n",
    "# add column with predicted logprob for actual human answers\n",
    "merged_dospert_data['logprob_predicted'] = merged_dospert_data.apply(\n",
    "    lambda row: np.exp(row[str(row['human_number'])]), axis=1\n",
    ")\n",
    "# Define mapping dictionary\n",
    "item_to_category = {\n",
    "    1: \"Social\", 10: \"Social\", 16: \"Social\", 19: \"Social\", 23: \"Social\", 26: \"Social\", 34: \"Social\", 35: \"Social\",\n",
    "    2: \"Recreational\", 6: \"Recreational\", 15: \"Recreational\", 17: \"Recreational\", 21: \"Recreational\", 31: \"Recreational\", 37: \"Recreational\", 38: \"Recreational\",\n",
    "    3: \"Gambling\", 11: \"Gambling\", 22: \"Gambling\", 33: \"Gambling\",\n",
    "    4: \"Health\", 8: \"Health\", 27: \"Health\", 29: \"Health\", 32: \"Health\", 36: \"Health\", 39: \"Health\", 40: \"Health\",\n",
    "    5: \"Ethical\", 9: \"Ethical\", 12: \"Ethical\", 13: \"Ethical\", 14: \"Ethical\", 20: \"Ethical\", 25: \"Ethical\", 28: \"Ethical\",\n",
    "    7: \"Investment\", 18: \"Investment\", 24: \"Investment\", 30: \"Investment\"\n",
    "}\n",
    "\n",
    "# Add a new column \"domain\"\n",
    "merged_dospert_data[\"domain\"] = merged_dospert_data[\"item\"].map(item_to_category)\n",
    "\n",
    "# Check column names\n",
    "print(f\"\\nColumns: {list(merged_dospert_data.columns)}\")\n",
    "\n",
    "merged_dospert_data = merged_dospert_data[merged_dospert_data[\"flipped\"] == \"no\"]\n",
    "\n",
    "merged_dospert_data.groupby(\"model\")[\"logprob_predicted\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d8f66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise distribution (focus on variance) per model of logprobs\n",
    "\n",
    "model_names = merged_dospert_data['model'].unique()\n",
    "\n",
    "for model_name in model_names:\n",
    "    df_plot = merged_dospert_data[merged_dospert_data['model'] == model_name]\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.histplot(data=df_plot, x=\"logprob_predicted\", kde=True, bins=30)  # KDE optional\n",
    "    plt.title(f'Distribution of logprob_predicted for model: {model_name}')\n",
    "    plt.xlabel('logprob_predicted')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a09a3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Cronbach's alpha per domain ----\n",
    "\n",
    "# dictionary to store results\n",
    "results = []\n",
    "\n",
    "# loop through domains\n",
    "for domain, domain_data in merged_dospert_data.groupby(\"domain\"):\n",
    "    \n",
    "    # loop through models within this domain\n",
    "    for model, model_data in domain_data.groupby(\"model\"):\n",
    "        \n",
    "        # pivot wide format for Cronbach's alpha\n",
    "        df_wide_domains = model_data.pivot_table(\n",
    "            index=\"participant\",\n",
    "            columns=\"item\",\n",
    "            values=\"logprob_predicted\"\n",
    "        )\n",
    "        \n",
    "        # drop rows with missing data\n",
    "        df_wide_domains = df_wide_domains.dropna(axis=0)\n",
    "        \n",
    "        # calculate Cronbach's alpha\n",
    "        if df_wide_domains.shape[1] > 1:  # need at least 2 items\n",
    "            alpha, ci = pg.cronbach_alpha(df_wide_domains)\n",
    "        else:\n",
    "            alpha, ci = None, (None, None)  # not enough items to compute\n",
    "        \n",
    "        # store results\n",
    "        results.append({\n",
    "            \"domain\": domain,\n",
    "            \"model\": model,\n",
    "            \"alpha\": alpha,\n",
    "            \"alpha_CI\": ci\n",
    "        })\n",
    "\n",
    "# convert to DataFrame\n",
    "alpha_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647f7e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c2e193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_dospert_data: long format with columns ['participant', 'item', 'model', 'logprob_predicted']\n",
    "\n",
    "df_wide = merged_dospert_data.pivot_table(\n",
    "    index=['model', 'participant'],\n",
    "    columns='item',\n",
    "    values='logprob_predicted'\n",
    ").reset_index()\n",
    "\n",
    "#df_wide: columns = wide format data with columns ['model', 'participant', item1, 2, ..., 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6323f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Cronbach's alpha ----\n",
    "def cronbach_alpha(df):\n",
    "    k = df.shape[1]\n",
    "    item_vars = df.var(axis=0, ddof=1)\n",
    "    total_var = df.sum(axis=1).var(ddof=1)\n",
    "    return (k / (k - 1)) * (1 - item_vars.sum() / total_var)\n",
    "\n",
    "alphas = {}\n",
    "for m, sub in df_wide.groupby(\"model\"):\n",
    "    scores = sub.drop(columns=[\"model\", \"participant\"])\n",
    "    alpha = cronbach_alpha(scores)\n",
    "    #print(f\"Model {m}: alpha = {alpha:.3f}\")\n",
    "    alphas[m] = alpha\n",
    "\n",
    "alpha_df = pd.DataFrame(list(alphas.items()), columns=[\"model\", \"alpha\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec43c529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- split-half reliability -----\n",
    "\n",
    "def split_half_reliability(df_items, n_splits=100):\n",
    "    \"\"\"Compute average split-half reliability (Spearman-Brown corrected).\"\"\"\n",
    "    k = df_items.shape[1]\n",
    "    colnames = df_items.columns\n",
    "    results = []\n",
    "    \n",
    "    for _ in range(n_splits):\n",
    "        shuffled = list(colnames)\n",
    "        random.shuffle(shuffled)\n",
    "        half1, half2 = shuffled[:k//2], shuffled[k//2:]\n",
    "        \n",
    "        s1 = df_items[half1].sum(axis=1)\n",
    "        s2 = df_items[half2].sum(axis=1)\n",
    "        \n",
    "        r, _ = pearsonr(s1, s2)\n",
    "        if np.isfinite(r): \n",
    "            r_sb = (2 * r) / (1 + r)\n",
    "            results.append(r_sb)\n",
    "    \n",
    "    return np.mean(results), np.std(results)\n",
    "\n",
    "split_results = {}\n",
    "\n",
    "for m, sub in df_wide.groupby(\"model\"):\n",
    "    items = sub.drop(columns=[\"model\", \"participant\"])\n",
    "    mean_rsb, sd_rsb = split_half_reliability(items)\n",
    "    split_results[m] = (mean_rsb, sd_rsb)\n",
    "\n",
    "split_df = pd.DataFrame([\n",
    "    {\"model\": m, \"split_half_mean\": mean, \"split_half_sd\": sd}\n",
    "    for m, (mean, sd) in split_results.items()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c90eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- ICC -----\n",
    "\n",
    "df_long = merged_dospert_data.copy()\n",
    "\n",
    "def compute_icc(df_long, model):\n",
    "    \"\"\"Compute ICC for one model (participant random effect).\"\"\"\n",
    "    sub = df_long[df_long[\"model\"] == model]\n",
    "    # Random intercept model: logprob ~ 1 + (1|participant)\n",
    "    md = mixedlm(\"logprob_predicted ~ 1\", sub, groups=sub[\"participant\"])\n",
    "    mdf = md.fit(reml=True)\n",
    "    \n",
    "    var_participant = mdf.cov_re.iloc[0,0]\n",
    "    var_residual = mdf.scale\n",
    "    icc = var_participant / (var_participant + var_residual)\n",
    "    return icc\n",
    "\n",
    "icc_results = {}\n",
    "for m in df_long[\"model\"].unique():\n",
    "    icc_results[m] = compute_icc(df_long, m)\n",
    "\n",
    "icc_df = pd.DataFrame(list(icc_results.items()), columns=[\"model\", \"icc\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fe15aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = alpha_df.merge(split_df, on=\"model\").merge(icc_df, on=\"model\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ee190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort models by alpha for better readability\n",
    "df_sorted = results_df.sort_values(\"alpha\", ascending=False)\n",
    "\n",
    "x = np.arange(len(df_sorted))  # positions for models\n",
    "width = 0.35  # bar width\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(14,6))\n",
    "\n",
    "# Bars for alpha and split-half\n",
    "ax1.bar(x - width/2, df_sorted[\"alpha\"], width, label=\"Cronbach's alpha\")\n",
    "ax1.bar(x + width/2, df_sorted[\"split_half_mean\"], width, label=\"Split-half (mean)\")\n",
    "\n",
    "ax1.set_ylabel(\"Alpha / Split-half\")\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(df_sorted[\"model\"], rotation=45, ha=\"right\")\n",
    "ax1.set_ylim(0, 1.05)\n",
    "ax1.legend(loc=\"upper left\")\n",
    "ax1.set_title(\"Reliability metrics per model\")\n",
    "\n",
    "# Optional: plot ICC on secondary axis\n",
    "# ax2 = ax1.twinx()\n",
    "# ax2.plot(x, df_sorted[\"icc\"], color=\"red\", marker=\"o\", linestyle='-', label=\"ICC\")\n",
    "# ax2.set_ylabel(\"ICC\")\n",
    "# ax2.legend(loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2f3752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort models by ICC for easier visualization\n",
    "icc_sorted = results_df.sort_values(\"icc\", ascending=True)\n",
    "y = np.arange(len(icc_sorted))\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.barh(y, icc_sorted[\"icc\"], color=\"teal\")\n",
    "plt.yticks(y, icc_sorted[\"model\"])\n",
    "plt.xlabel(\"Intraclass Correlation (ICC)\")\n",
    "plt.title(\"ICC of LLM log-probabilities per model\")\n",
    "plt.xlim(0, icc_sorted[\"icc\"].max()*1.1)  # add 10% padding\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#ICC quantifies the proportion of variance in the LLM’s assigned log-probabilities that is attributable to differences between participants, as opposed to random variation across items or noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39b98ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is ICC so low because there is simply no variance between the logprobs assigned to different participants?\n",
    "\n",
    "df_long_Qwen3_4b = df_long[df_long[\"model\"] == \"Qwen3-4B\"]\n",
    "\n",
    "participant_var_per_item = df_long_Qwen3_4b.groupby(\"item\")[\"logprob_predicted\"].var()\n",
    "print(participant_var_per_item.describe())\n",
    "\n",
    "participant_means = df_long_Qwen3_4b.groupby(\"participant\")[\"logprob_predicted\"].mean()\n",
    "print(participant_means.describe())\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.boxplot(participant_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed63674c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot to participants × items\n",
    "heatmap_df = df_long_Qwen3_4b.pivot_table(\n",
    "    index=['participant'],\n",
    "    columns='item',\n",
    "    values='logprob_predicted'\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(heatmap_df, cmap=\"viridis\", cbar_kws={'label':'Log-prob'})\n",
    "plt.xlabel(\"Item\")\n",
    "plt.ylabel(\"Participant\")\n",
    "plt.title(\"Heatmap of LLM log-probs\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270bae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import mixedlm\n",
    "\n",
    "# Initialize empty list to store DataFrames\n",
    "dospert_dataframes = []\n",
    "path = \"LLM_data\"  # folder with CSVs\n",
    "\n",
    "for file in glob.glob(os.path.join(path, \"*_DOSPERT_prompting_results.csv\")):\n",
    "    model_name = os.path.basename(file).replace(\"_DOSPERT_prompting_results.csv\", \"\")\n",
    "    \n",
    "    # Read the CSV\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Append to list\n",
    "    dospert_dataframes.append(df)\n",
    "    \n",
    "# Concatenate all DataFrames into one big DataFrame\n",
    "merged_dospert_data = pd.concat(dospert_dataframes, ignore_index=True)\n",
    "print(f\"\\nMerged DataFrame shape: {merged_dospert_data.shape}\")\n",
    "print(f\"Total models: {merged_dospert_data['model'].nunique()}\")\n",
    "print(f\"Models included: {sorted(merged_dospert_data['model'].unique())}\")\n",
    "\n",
    "# add column with predicted logprob for actual human answers\n",
    "merged_dospert_data['logprob_predicted'] = merged_dospert_data.apply(\n",
    "    lambda row: row[str(row['human_number'])], axis=1\n",
    ")\n",
    "\n",
    "# Check column names\n",
    "print(f\"\\nColumns: {list(merged_dospert_data.columns)}\")\n",
    "\n",
    "# merged_dospert_data: long format with columns ['participant', 'item', 'model', 'logprob_predicted']\n",
    "df_wide = merged_dospert_data.pivot_table(\n",
    "    index=['model', 'participant'],\n",
    "    columns='item',\n",
    "    values='logprob_predicted'\n",
    ").reset_index()\n",
    "\n",
    "# ---- IMPROVED Cronbach's alpha ----\n",
    "def cronbach_alpha(df):\n",
    "    \"\"\"\n",
    "    Compute Cronbach's alpha with better numerical stability\n",
    "    \"\"\"\n",
    "    # Remove any rows with missing values\n",
    "    df_clean = df.dropna()\n",
    "    if df_clean.empty:\n",
    "        return np.nan\n",
    "    \n",
    "    k = df_clean.shape[1]  # number of items\n",
    "    if k < 2:\n",
    "        return np.nan\n",
    "    \n",
    "    # Calculate item variances\n",
    "    item_vars = df_clean.var(axis=0, ddof=1)\n",
    "    \n",
    "    # Calculate total score variance\n",
    "    total_scores = df_clean.sum(axis=1)\n",
    "    total_var = total_scores.var(ddof=1)\n",
    "    \n",
    "    # Handle edge cases\n",
    "    if total_var == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    # Cronbach's alpha formula\n",
    "    alpha = (k / (k - 1)) * (1 - item_vars.sum() / total_var)\n",
    "    return alpha\n",
    "\n",
    "alphas = {}\n",
    "for m, sub in df_wide.groupby(\"model\"):\n",
    "    scores = sub.drop(columns=[\"model\", \"participant\"])\n",
    "    alpha = cronbach_alpha(scores)\n",
    "    alphas[m] = alpha\n",
    "\n",
    "alpha_df = pd.DataFrame(list(alphas.items()), columns=[\"model\", \"alpha\"])\n",
    "\n",
    "# ---- FIXED split-half reliability -----\n",
    "def split_half_reliability(df_items, n_splits=100):\n",
    "    \"\"\"Compute average split-half reliability (Spearman–Brown corrected).\"\"\"\n",
    "    k = df_items.shape[1]\n",
    "    if k < 2:\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "    colnames = df_items.columns.tolist()\n",
    "    results = []\n",
    "    \n",
    "    for _ in range(n_splits):  # FIXED: was \"for * in range(n*splits)\"\n",
    "        shuffled = colnames.copy()\n",
    "        random.shuffle(shuffled)\n",
    "        \n",
    "        # Split into two halves\n",
    "        half1, half2 = shuffled[:k//2], shuffled[k//2:k//2*2]  # Ensure equal lengths\n",
    "        \n",
    "        if len(half1) == 0 or len(half2) == 0:\n",
    "            continue\n",
    "            \n",
    "        s1 = df_items[half1].sum(axis=1)\n",
    "        s2 = df_items[half2].sum(axis=1)\n",
    "        \n",
    "        # Check for zero variance\n",
    "        if s1.var() == 0 or s2.var() == 0:\n",
    "            continue\n",
    "            \n",
    "        r, p_value = pearsonr(s1, s2)\n",
    "        \n",
    "        if np.isfinite(r) and r > -1:  # Avoid invalid correlations\n",
    "            # Spearman-Brown correction\n",
    "            r_sb = (2 * r) / (1 + r) if (1 + r) != 0 else np.nan\n",
    "            if np.isfinite(r_sb):\n",
    "                results.append(r_sb)\n",
    "    \n",
    "    if len(results) == 0:\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "    return np.mean(results), np.std(results)\n",
    "\n",
    "split_results = {}\n",
    "for m, sub in df_wide.groupby(\"model\"):\n",
    "    items = sub.drop(columns=[\"model\", \"participant\"])\n",
    "    mean_rsb, sd_rsb = split_half_reliability(items)\n",
    "    split_results[m] = (mean_rsb, sd_rsb)\n",
    "\n",
    "split_df = pd.DataFrame([\n",
    "    {\"model\": m, \"split_half_mean\": mean, \"split_half_sd\": sd}\n",
    "    for m, (mean, sd) in split_results.items()\n",
    "])\n",
    "\n",
    "# ---- IMPROVED ICC -----\n",
    "def compute_icc(df_long, model):\n",
    "    \"\"\"Compute ICC for one model (participant random effect).\"\"\"\n",
    "    sub = df_long[df_long[\"model\"] == model].copy()\n",
    "    \n",
    "    # Check if we have enough data\n",
    "    if len(sub) == 0 or sub['participant'].nunique() < 2:\n",
    "        return np.nan\n",
    "    \n",
    "    try:\n",
    "        # Random intercept model: logprob ~ 1 + (1|participant)\n",
    "        md = mixedlm(\"logprob_predicted ~ 1\", sub, groups=sub[\"participant\"])\n",
    "        mdf = md.fit(reml=True, disp=False)  # Suppress convergence warnings\n",
    "        \n",
    "        # Extract variance components\n",
    "        var_participant = mdf.cov_re.iloc[0, 0]\n",
    "        var_residual = mdf.scale\n",
    "        \n",
    "        # Calculate ICC\n",
    "        icc = var_participant / (var_participant + var_residual)\n",
    "        return icc\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: ICC computation failed for model {model}: {e}\")\n",
    "        return np.nan\n",
    "\n",
    "icc_results = {}\n",
    "for m in df_long[\"model\"].unique():\n",
    "    icc_results[m] = compute_icc(df_long, m)\n",
    "\n",
    "icc_df = pd.DataFrame(list(icc_results.items()), columns=[\"model\", \"icc\"])\n",
    "\n",
    "# Merge all results\n",
    "results_df = alpha_df.merge(split_df, on=\"model\").merge(icc_df, on=\"model\")\n",
    "\n",
    "# Sort by alpha for better readability\n",
    "results_df = results_df.sort_values('alpha', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RELIABILITY ANALYSIS RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(results_df.round(4))\n",
    "\n",
    "# ---- INTERPRETATION HELPER ----\n",
    "def interpret_reliability(alpha, split_half, icc):\n",
    "    \"\"\"Provide interpretation guidelines for reliability measures\"\"\"\n",
    "    interpretations = []\n",
    "    \n",
    "    # Cronbach's Alpha interpretation\n",
    "    if alpha >= 0.9:\n",
    "        alpha_interp = \"Excellent\"\n",
    "    elif alpha >= 0.8:\n",
    "        alpha_interp = \"Good\"\n",
    "    elif alpha >= 0.7:\n",
    "        alpha_interp = \"Acceptable\"\n",
    "    elif alpha >= 0.6:\n",
    "        alpha_interp = \"Questionable\"\n",
    "    else:\n",
    "        alpha_interp = \"Poor\"\n",
    "    \n",
    "    # Split-half interpretation (similar scale)\n",
    "    if split_half >= 0.9:\n",
    "        split_interp = \"Excellent\"\n",
    "    elif split_half >= 0.8:\n",
    "        split_interp = \"Good\"\n",
    "    elif split_half >= 0.7:\n",
    "        split_interp = \"Acceptable\"\n",
    "    elif split_half >= 0.6:\n",
    "        split_interp = \"Questionable\"\n",
    "    else:\n",
    "        split_interp = \"Poor\"\n",
    "    \n",
    "    # ICC interpretation\n",
    "    if icc >= 0.75:\n",
    "        icc_interp = \"Excellent\"\n",
    "    elif icc >= 0.6:\n",
    "        icc_interp = \"Good\"\n",
    "    elif icc >= 0.4:\n",
    "        icc_interp = \"Fair\"\n",
    "    else:\n",
    "        icc_interp = \"Poor\"\n",
    "    \n",
    "    return alpha_interp, split_interp, icc_interp\n",
    "\n",
    "# Add interpretations to results\n",
    "results_df[['alpha_interp', 'split_half_interp', 'icc_interp']] = results_df.apply(\n",
    "    lambda row: interpret_reliability(row['alpha'], row['split_half_mean'], row['icc']), \n",
    "    axis=1, result_type='expand'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RELIABILITY INTERPRETATIONS\")\n",
    "print(\"=\"*60)\n",
    "results_df[['model', 'alpha', 'alpha_interp', 'split_half_mean', 'split_half_interp', 'icc', 'icc_interp']].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4e4f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic code to understand the ICC convergence warnings\n",
    "\n",
    "def detailed_icc_analysis(df_long, model):\n",
    "    \"\"\"\n",
    "    Compute ICC with detailed diagnostics to understand convergence issues\n",
    "    \"\"\"\n",
    "    sub = df_long[df_long[\"model\"] == model].copy()\n",
    "    \n",
    "    print(f\"\\n=== DIAGNOSTIC ANALYSIS FOR {model} ===\")\n",
    "    print(f\"Number of observations: {len(sub)}\")\n",
    "    print(f\"Number of participants: {sub['participant'].nunique()}\")\n",
    "    print(f\"Number of items: {sub['item'].nunique()}\")\n",
    "    \n",
    "    # Check logprob distribution\n",
    "    logprobs = sub['logprob_predicted']\n",
    "    print(f\"\\nLogprob statistics:\")\n",
    "    print(f\"  Mean: {logprobs.mean():.6f}\")\n",
    "    print(f\"  Std:  {logprobs.std():.6f}\")\n",
    "    print(f\"  Min:  {logprobs.min():.6f}\")\n",
    "    print(f\"  Max:  {logprobs.max():.6f}\")\n",
    "    print(f\"  Range: {logprobs.max() - logprobs.min():.6f}\")\n",
    "    \n",
    "    # Check participant-level variation\n",
    "    participant_means = sub.groupby('participant')['logprob_predicted'].mean()\n",
    "    print(f\"\\nParticipant-level variation:\")\n",
    "    print(f\"  Between-participant std: {participant_means.std():.6f}\")\n",
    "    print(f\"  Within-participant std:  {sub.groupby('participant')['logprob_predicted'].std().mean():.6f}\")\n",
    "    \n",
    "    # Check if there's any meaningful variation between participants\n",
    "    participant_range = participant_means.max() - participant_means.min()\n",
    "    print(f\"  Range of participant means: {participant_range:.6f}\")\n",
    "    \n",
    "    try:\n",
    "        # Fit the model with more detailed output\n",
    "        md = mixedlm(\"logprob_predicted ~ 1\", sub, groups=sub[\"participant\"])\n",
    "        mdf = md.fit(reml=True, disp=False)\n",
    "        \n",
    "        # Extract variance components\n",
    "        var_participant = mdf.cov_re.iloc[0, 0]\n",
    "        var_residual = mdf.scale\n",
    "        \n",
    "        print(f\"\\nVariance Components:\")\n",
    "        print(f\"  Participant variance: {var_participant:.8f}\")\n",
    "        print(f\"  Residual variance:    {var_residual:.8f}\")\n",
    "        print(f\"  Total variance:       {var_participant + var_residual:.8f}\")\n",
    "        \n",
    "        # Calculate ICC\n",
    "        icc = var_participant / (var_participant + var_residual)\n",
    "        print(f\"  ICC: {icc:.6f}\")\n",
    "        \n",
    "        # Check if we're at the boundary\n",
    "        if var_participant < 1e-6:\n",
    "            print(\"BOUNDARY ISSUE: Participant variance ≈ 0\")\n",
    "            print(\"     This means the model cannot detect meaningful individual differences\")\n",
    "        \n",
    "        # Alternative ICC calculation using ANOVA approach\n",
    "        from scipy import stats\n",
    "        \n",
    "        # One-way ANOVA to get between vs within group variance\n",
    "        participant_groups = [group['logprob_predicted'].values for name, group in sub.groupby('participant')]\n",
    "        f_stat, p_val = stats.f_oneway(*participant_groups)\n",
    "        \n",
    "        print(f\"\\nOne-way ANOVA check:\")\n",
    "        print(f\"  F-statistic: {f_stat:.6f}\")\n",
    "        print(f\"  p-value: {p_val:.6f}\")\n",
    "        \n",
    "        if p_val > 0.05:\n",
    "            print(\"No significant differences between participants detected\")\n",
    "        \n",
    "        return icc, var_participant, var_residual\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Model fitting failed: {e}\")\n",
    "        return np.nan, np.nan, np.nan\n",
    "\n",
    "# Run diagnostic for a few models\n",
    "test_models = ['Qwen3-4B', 'Mistral-7B-Instruct-v0.3', 'zephyr-7b-beta']\n",
    "\n",
    "for model in test_models:\n",
    "    if model in df_long['model'].unique():\n",
    "        detailed_icc_analysis(df_long, model)\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# ---- Alternative reliability measure ----\n",
    "def alternative_reliability_measure(df_long, model):\n",
    "    \"\"\"\n",
    "    Calculate an alternative reliability measure based on the correlation\n",
    "    between participant means across items\n",
    "    \"\"\"\n",
    "    sub = df_long[df_long[\"model\"] == model].copy()\n",
    "    \n",
    "    # Create participant × item matrix\n",
    "    pivot = sub.pivot_table(\n",
    "        index='participant', \n",
    "        columns='item', \n",
    "        values='logprob_predicted'\n",
    "    )\n",
    "    \n",
    "    if pivot.empty:\n",
    "        return np.nan\n",
    "    \n",
    "    # Calculate correlation between random splits of items\n",
    "    n_items = len(pivot.columns)\n",
    "    if n_items < 4:\n",
    "        return np.nan\n",
    "    \n",
    "    # Split items randomly multiple times and correlate participant means\n",
    "    correlations = []\n",
    "    for _ in range(100):\n",
    "        items = list(pivot.columns)\n",
    "        random.shuffle(items)\n",
    "        \n",
    "        half1 = items[:n_items//2]\n",
    "        half2 = items[n_items//2:n_items//2*2]\n",
    "        \n",
    "        if len(half1) == 0 or len(half2) == 0:\n",
    "            continue\n",
    "            \n",
    "        mean1 = pivot[half1].mean(axis=1)\n",
    "        mean2 = pivot[half2].mean(axis=1)\n",
    "        \n",
    "        # Remove participants with missing data\n",
    "        valid_mask = ~(mean1.isna() | mean2.isna())\n",
    "        if valid_mask.sum() < 2:\n",
    "            continue\n",
    "            \n",
    "        corr, _ = pearsonr(mean1[valid_mask], mean2[valid_mask])\n",
    "        if np.isfinite(corr):\n",
    "            correlations.append(corr)\n",
    "    \n",
    "    if len(correlations) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    return np.mean(correlations)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALTERNATIVE PARTICIPANT-LEVEL RELIABILITY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "alt_reliability = {}\n",
    "for model in df_long['model'].unique():\n",
    "    alt_rel = alternative_reliability_measure(df_long, model)\n",
    "    alt_reliability[model] = alt_rel\n",
    "    print(f\"{model}: {alt_rel:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
